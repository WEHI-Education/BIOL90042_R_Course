[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "BIOL90042 R Course",
    "section": "",
    "text": "Preface\nCode-based data analysis is an increasingly important skill for modern biomedical research. The R coding language enables user-friendly data tidying and transformation, and creation of publication-ready graphics. R is also core to bioinformatics research, supporting all types of ’omics data analysis, classical statistical analysis, and machine learning.\nDesigned for complete coding beginners, this book will introduce data wrangling, data visualisation, and bioinformatics analysis, and machine learning in R.",
    "crumbs": [
      "Preface"
    ]
  },
  {
    "objectID": "index.html#how-to-use-this-book",
    "href": "index.html#how-to-use-this-book",
    "title": "BIOL90042 R Course",
    "section": "How to use this book",
    "text": "How to use this book\nThis book is divided into 8 chapters sessions, focusing on the basics of R and the ‘tidyverse’ (Chapters 1-5), bioinformatics analysis of RNA sequencing data (Chapters 6-7) and machine learning (Chapter 8). Each chapter is divided into sections containing a mix of text, code and exercises, which are designed to be completed in order.\nThroughout the book, R code is displayed in code blocks as per the output below it in grey below. This appears similarly to code typed into the RStudio console.\n\n# This is an R code block\n# You can run this code by copying it into the R console\n1 + 1\n\n[1] 2\n\n\nYou can run the code yourself by copying it (using the copy button in the top right of the code block) and pasting it into R on your computer.",
    "crumbs": [
      "Preface"
    ]
  },
  {
    "objectID": "index.html#acknowledgements",
    "href": "index.html#acknowledgements",
    "title": "BIOL90042 R Course",
    "section": "Acknowledgements",
    "text": "Acknowledgements\nThis course material for Chapters 6 and 7 was originally produced by Lucy Liu and modified for this book.\nWe acknowledge that this course is prepared and delivered on the unceded land of the Wurundjeri people of the Kulin Nation. We pay our respects to their Elders past, present, and emerging. We also acknowledge that sovereignty was never ceded, and that this always was and always will be Aboriginal land.",
    "crumbs": [
      "Preface"
    ]
  },
  {
    "objectID": "setup.html",
    "href": "setup.html",
    "title": "Setup",
    "section": "",
    "text": "Installing Software",
    "crumbs": [
      "Setup"
    ]
  },
  {
    "objectID": "setup.html#installing-software",
    "href": "setup.html#installing-software",
    "title": "Setup",
    "section": "",
    "text": "R and RStudio\nYou can download and install R and RStudio through the posit.co website.\n\n\n\nInstall both R and RStudio\n\n\nThe Posit website should automatically detect your operating system and link to the correct download file.",
    "crumbs": [
      "Setup"
    ]
  },
  {
    "objectID": "setup.html#mac-users",
    "href": "setup.html#mac-users",
    "title": "Setup",
    "section": "Mac users",
    "text": "Mac users\nOn Mac iOS, the download file should be .tar.gz format",
    "crumbs": [
      "Setup"
    ]
  },
  {
    "objectID": "setup.html#pc-users",
    "href": "setup.html#pc-users",
    "title": "Setup",
    "section": "PC users",
    "text": "PC users\nOn windows operating system, the downloaded file should be .exe format\n\nLockdown Browser\nFor BIOL90042 Masters Students Only: Install Lockdown Browser using this link https://download.respondus.com/lockdown/download.php?id=113132090",
    "crumbs": [
      "Setup"
    ]
  },
  {
    "objectID": "setup.html#new-desktop-folder",
    "href": "setup.html#new-desktop-folder",
    "title": "Setup",
    "section": "New Desktop Folder",
    "text": "New Desktop Folder\nCreate a new folder on your Desktop named BIOL90042_workshops",
    "crumbs": [
      "Setup"
    ]
  },
  {
    "objectID": "setup.html#download-data-files",
    "href": "setup.html#download-data-files",
    "title": "Setup",
    "section": "Download data files",
    "text": "Download data files\nDownload the .zip file via this link, and save inside BIOL90042_workshops\n Download workshop data",
    "crumbs": [
      "Setup"
    ]
  },
  {
    "objectID": "setup.html#unzip-data-files",
    "href": "setup.html#unzip-data-files",
    "title": "Setup",
    "section": "Unzip data files",
    "text": "Unzip data files\nUnzip the data.zip directory. You should see 4 files. Do not unzip any other files at this stage.",
    "crumbs": [
      "Setup"
    ]
  },
  {
    "objectID": "setup.html#open-rstudio",
    "href": "setup.html#open-rstudio",
    "title": "Setup",
    "section": "Open RStudio",
    "text": "Open RStudio",
    "crumbs": [
      "Setup"
    ]
  },
  {
    "objectID": "setup.html#create-new-.r-file",
    "href": "setup.html#create-new-.r-file",
    "title": "Setup",
    "section": "Create new .R file",
    "text": "Create new .R file\nFile &gt; New File &gt; R Script\n\nCopy & Paste\nCopy the code block below and paste into the new file:\n\n\n\n\n\n\nCopy icon\n\n\n\nHint - Click the clipboard icon at top right in the code block below!\n\n\n\n## Setting up R for workshops \n\n## Install tidyverse \ninstall.packages(\"tidyverse\") \n\n## Install conflicted\ninstall.packages(\"conflicted\") \n\n## Install readxl & writexl\ninstall.packages(\"readxl\")\ninstall.packages(\"writexl\")\n\n## Install ggrepel  \ninstall.packages(\"ggrepel\") \n\n## Install tidyrstats \ninstall.packages(\"tidyrstats\") \n\n##Install patchwork\ninstall.packages(\"patchwork\") \n\n\n## Install and Load packages required for RNAseq \n\nif (!requireNamespace(\"BiocManager\", quietly = TRUE)) \n\n  install.packages(\"BiocManager\") \n\nBiocManager::install(\"RNAseq123\") \n\n\n## Install tidyheatmaps \ninstall.packages(\"tidyheatmaps\") \n\n## Install tidymodels\ninstall.packages(\"tidymodels\") \n\n## Install vip\ninstall.packages(\"vip\") \n\n## Install xgboost\ninstall.packages(\"xgboost\") \n\n## Install ggridges\ninstall.packages(\"ggridges\")\n\n## Load all libraries\n\nlibrary(tidyverse)\nlibrary(conflicted)\nlibrary(readxl)\nlibrary(writexl)\n\nlibrary(ggrepel) \nlibrary(tidyrstats) \nlibrary(patchwork) \n\nlibrary(edgeR) \nlibrary(limma) \n\nlibrary(tidyheatmaps) \n\nlibrary(tidymodels)\nlibrary(vip)\nlibrary(xgboost)\n\nlibrary(ggridges)",
    "crumbs": [
      "Setup"
    ]
  },
  {
    "objectID": "setup.html#save-the-new-file",
    "href": "setup.html#save-the-new-file",
    "title": "Setup",
    "section": "Save the new file",
    "text": "Save the new file\nFile &gt; Save the new file inside your BIOL90042_workshops folder, with name setup.R",
    "crumbs": [
      "Setup"
    ]
  },
  {
    "objectID": "setup.html#run-the-code",
    "href": "setup.html#run-the-code",
    "title": "Setup",
    "section": "Run the code",
    "text": "Run the code\nSelect all the code with mouse click & drag, or CMD A (mac) / CTRL A (pc), and clicking ‘Run’.\n\nNote this will take some time and there may be errors. Masters students can request further help in the first tutorial.",
    "crumbs": [
      "Setup"
    ]
  },
  {
    "objectID": "setup.html#restart-r",
    "href": "setup.html#restart-r",
    "title": "Setup",
    "section": "Restart R",
    "text": "Restart R\nOnce the code has run and all libraries can be loaded without errors, restart R by selecting Session &gt; Restart R. This will reset your R session ready for Chapter 1!",
    "crumbs": [
      "Setup"
    ]
  },
  {
    "objectID": "chapter_1.html",
    "href": "chapter_1.html",
    "title": "1  Introduction to R",
    "section": "",
    "text": "1.1 Using RStudio\nIn this chapter, we will get familiar with R.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Introduction to R</span>"
    ]
  },
  {
    "objectID": "chapter_1.html#sec-usingRstudio",
    "href": "chapter_1.html#sec-usingRstudio",
    "title": "1  Introduction to R",
    "section": "",
    "text": "1.1.1 What is R and RStudio?\nR is a free and popular statistical programming language, great for performing data analysis. RStudio is a free integrated development environment (IDE) that provides useful support features for writing code. During this course, we will learn how to use RStudio’s handy features like projects (which help us to keep track of different analyses) and the environment panel (which shows us all of our data/variables in one place).\n\n\n1.1.2 Creating a project\nRstudio Projects are a way we can organise our work in RStudio, so that we can resume where we left off and keep different analyses separate. Any time you start working on something new (like this course!) it is recommended that you start a new project. You can see the current project you’re working on, switch between projects or create a new project using the menu in the top right hand corner of RStudio:\n\n\n\nIn the top right hand corner of RStudio, you can see all of your projects\n\n\nTo begin this course, let’s make a new project. We’ll do this in a new directory (folder) so that everything stays organised:\n\n\n\nWe usually want to make a new project in its own directory (folder)\n\n\nNext, we need to tell R that we want to make a ‘New Project’ and not any of the other fancy things we could create:\n\n\n\nThere are many types of projects we can make in R, but for now we’ll stick with a regular project.\n\n\nFinally, we need to give our project an informative name:\n\n\n\nChoose a name that will help you remember what this project is about!\n\n\n\n\n\n\n\n\nName with underscores, not spaces\n\n\n\nYou’ll notice I named my project using an underscore (R_course) rather than a space (R course). In general, when coding we want to name things without spaces, so that it is clear to the computer that we are talking about a single entity (the ‘R_course’) as opposed to multiple things (‘R’ and ‘course’). We’ll revisit this idea later in the chapter in Section 1.4\n\n\n\n\n1.1.3 Creating an R script\nNow that our project is set up, we need to create a file to write our code in:\n\n\n\nHow to create a new R Script\n\n\nThis file is called an R Script. Don’t forget to save your R Script as you work so you don’t lose your progress! You can do this through the file menu or by using the keyboard shortcut Cmd-SCmd-S.\n\n\n1.1.4 Overview of the RStudio layout\nAt this point, your RStudio window should look like this, with four different panels visible:\n\n\n\nThe four panels of RStudio\n\n\nThis is what they’re used for:\n\nThe R Script panel. This is a text document where you can write code, and run it by highlighting the code or putting your cursor on that line, then either clicking the ‘Run’ button in the top-right corner, or using the Cmd-EnterCmd-Enter keyboard shortcut.\nThe console. This is where the output (results) of your code will appear. You can also run code in the console, by typing it next to the &gt; symbol and pressing EnterEnter but it’s better to use the R Script, as the code you write there is saved and acts as a record of your work.\nThe environment panel. This is where the data and variables you use in your analysis will be listed. More on this later.\nThe files/plot/help panel.\n\nUnder the ‘files’ tab you can see the files in your current folder\nUnder the ‘plots’ tab you can view the plots you have created\nUnder the ‘help’ tab you can read manual pages to learn how to use functions\n\n\nAlthough there are other tabs for some of these panels, they are used for more niche things out of scope of this course. You can read more about it in the RStudio documentation.\n\n\n1.1.5 Writing our first piece of code\nNow we are ready to write our bit of code! We’ll start with one of the most important concepts in programming: comments. Comments are lines of our script that begin with # and they are ignored by the computer: they are just notes that we write to ourselves. It’s really important to write ‘well-commented’ code, with plenty of comments that clearly explain what your code is doing, so that your script can easily be understood by whoever looks at it next (whether this is someone else or you revisiting an analysis many months later!)\n\n\n\n\n\n\nDon’t forget your #\n\n\n\nIf you forget the # at the start of your comment, R will try to interpret your notes as actual code, and you’ll get an error message:\n\noops I forgot the hashtag\n\nError in parse(text = input): &lt;text&gt;:1:6: unexpected symbol\n1: oops I\n         ^\n\n\n\n\nDuring this course, we will practice writing well-commented code, but here is an example of how we could write comments to explain the code for one plus one:\n\n# calculate one plus one\n1 + 1 # the + symbol means plus\n\nNote that comments can be written on their own line or at the end of a line after the code. Crucially, you cannot write any code after a # on the same line, as R will ignore it. This is sometimes useful for ‘commenting out’ code that you don’t want to run, but want to keep in your script for later use.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Introduction to R</span>"
    ]
  },
  {
    "objectID": "chapter_1.html#sec-maths",
    "href": "chapter_1.html#sec-maths",
    "title": "1  Introduction to R",
    "section": "1.2 Practicing R code with maths",
    "text": "1.2 Practicing R code with maths\nTo practice running R code, let’s do some maths. Here’s how to code some basic mathematical operations in R:\n\n\n\n\n\n\n\n\nOperation\nCode\nExample\n\n\n\n\nAddition\n+\none plus one: 1 + 1\n\n\nSubtraction\n-\ntwo minus ten: 2 - 10\n\n\nMultiplication\n*\neight times 4: 8 * 4\n\n\nDivision\n/\nten divided by 3: 10 / 3\n\n\nExponents\n^\nthree squared: 3 ^ 2\n\n\nBrackets\n()\nsixteen divided by the result of three minus one: 16 / (3 - 1)\n\n\n\nLike in regular maths, R follows the order of operations. Here, the 3 + 2 in the brackets will be evaluated first, and then result will be multiplied by 7.\n\n# brackets evaluate first\n(3 + 2) * 7\n\n[1] 35\n\n\nYou might notice when running this code that before the output (result), there is a number one that looks like this: [1]. This relates to the length of our output, which here is just one single number (hence the 1). Later in the chapter we will write code with longer output, and the purpose of this number will become clearer, but you can ignore it for now.\n\n\n\n\n\n\nUsing whitespace in code\n\n\n\nAbove we used spaces between the numbers and mathematical operators in our code. R understands code without spaces too, but this makes it easier to read. Note that this is different to when we are naming things, when spaces are bad!\n\n# spaces don't matter in code\n3 ^ 2\n\n[1] 9\n\n# so both of these should give the same result\n3^2\n\n[1] 9\n\n\n\n\n\n\n\n\n\n\nPractice exercises\n\n\n\nTry these practice questions to test your understanding\n\n1. Which R expression would give me a result of 10?\n\n\n\n\n ✔(2 * 3) + (2 ^ 2)\n\n\n ✗(5 - 3) * 4\n\n\n ✗1 + 1\n\n\n ✗20 - 1\n\n\n\n\n\n\n2. What would be the result of running this line of R code: # test 1+1\n\n\n\n\n ✗1\n\n\n ✗2\n\n\n ✗An error\n\n\n ✔Nothing\n\n\n\n\n\n\n\nSolutions\n\n\n\n(2 * 3) + (2 ^ 2) is equal to 10. If you’re not sure, try copy-pasting this code into the console and running it! The best way to learn is by doing.\nThe code # test 1+1 is a comment, because it starts with a #. This means R ignores it: if you run this code, you won’t see any output in the console.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Introduction to R</span>"
    ]
  },
  {
    "objectID": "chapter_1.html#sec-comparisons",
    "href": "chapter_1.html#sec-comparisons",
    "title": "1  Introduction to R",
    "section": "1.3 Comparisons",
    "text": "1.3 Comparisons\nR can perform comparisons, using the following notation:\n\n\n\nComparison\nCode\n\n\n\n\nEqual to\n==\n\n\nNot equal to\n!=\n\n\nGreater/less than\n&gt; or &lt;\n\n\nGreater/less than or equal to\n&gt;= or &lt;=\n\n\n\n\n\n\n\n\n\nMind your equal signs!\n\n\n\nBe careful to use double equal signs == when checking for equality. If you use only one, you’ll get an error:\n\n1 == 1 # this is TRUE\n\n[1] TRUE\n\n1 = 1 # this gives an error\n\nError in 1 = 1: invalid (do_set) left-hand side to assignment\n\n\n\n\nComparisons in R return either TRUE or FALSE:\n\n10 &gt; 10\n\n[1] FALSE\n\n10 &gt;= 10\n\n[1] TRUE\n\n\nYou can also negate the result of a comparison or any TRUE/FALSE value by using the ! operator before the expression.\n\n# gives FALSE (i.e. not TRUE)\n!TRUE\n\n[1] FALSE\n\n# gives TRUE: 1 is not equal to 2, but we've negated the result\n!(1 == 2)\n\n[1] TRUE\n\n\nThis is really useful for filtering data, which we will cover in Chapter 2\n\n\n\n\n\n\nPractice exercises\n\n\n\nTry these practice questions to test your understanding\n\n1. What would be the result of running this R code: 10 &gt;= 10\n\n\n\n\n ✗10\n\n\n ✗FALSE\n\n\n ✔TRUE\n\n\n ✗An error\n\n\n\n\n\n\n2. Which of the following R expressions would give me a result of FALSE?\n\n\n\n\n ✗1 == 1\n\n\n ✗1 != (3 - 4) * 1\n\n\n ✗1 = 10\n\n\n ✔1 == 2\n\n\n\n\n\n\n3. What would be the result of running this R code: !TRUE\n\n\n\n\n ✔FALSE\n\n\n ✗TRUE\n\n\n ✗An error\n\n\n ✗Nothing\n\n\n\n\n\n\n\nSolutions\n\n\n\n10 &gt;= 10 is TRUE because 10 is equal to 10, and we are using the greater than or equal to operator, &gt;=.\n1 == 2 is the only expression that would give a result of FALSE. Be mindful that 1 = 10 is not a valid expression in R, and would give an error (since we need to use the double equal sign == for comparisons).\n!TRUE is FALSE because we are negating the value using !.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Introduction to R</span>"
    ]
  },
  {
    "objectID": "chapter_1.html#sec-variables",
    "href": "chapter_1.html#sec-variables",
    "title": "1  Introduction to R",
    "section": "1.4 Variables",
    "text": "1.4 Variables\n\n1.4.1 What’s a variable?\nA variable (also known as an object) in R is like a label we can use to keep track of values. We assign (save) values to variables so that we can refer to them later.\nFor example, let’s say I use R to do some maths:\n\n(2 + 6) * 7\n\n[1] 56\n\n\nR outputs simply the result. To use this value later, I would need to assign the output to a variable.\nVariables are assigned with the assignment operator &lt;- (you can type this using the &lt;&lt; and -- keys, or use the shortcut alt-alt-).\n\n\n\n\n\n\nAssignment arrows\n\n\n\nYou might be familiar with assigning values to variables using the equal sign =, which is used in other programming languages and in maths. Although this does also work in R, it’s preferred to use the arrow &lt;- as this makes it really clear that a variable is being assigned. In this course we’ll be using &lt;-.\n\n\nReturning to our example, let’s save the result of the above calculation to a variable called my_number\n\n# assign the result to my_number\nmy_number &lt;- (2 + 6) * 7\n\nHere, R has performed the calculation to the right of the arrow ((2 + 6) * 7) and assigned the result of this to the my_number variable.\nYou’ll notice that this line of code doesn’t produce any output, because it has gone straight into our variable. If we want to know the value of my_number, we can either run it as a line of R code, like so:\n\nmy_number\n\n[1] 56\n\n\nOr, we can look at the environment panel in RStudio:\n\n\n\nWe can see our variables and their values in the environment panel\n\n\n\n\n1.4.2 Using variables in R code\nVariables can be used in place of values (e.g. numbers) in R code. For example, we can use the my_number variable in a calculation:\n\n# multiply my_number by 2\nmy_number * 2\n\n[1] 112\n\n\nAs the name suggests, variables can vary! We can assign a new value to a variable at any time:\n\n# change the value of my_number to 12\nmy_number &lt;- 12\nmy_number\n\n[1] 12\n\n\nBecause the right hand side of the arrow is evaluated first, you can also assign to a variable a calculation that involves itself:\n\n# add 5 to my_number\nmy_number &lt;- my_number + 5\nmy_number # value is now 17 since 12 + 5 = 17\n\n[1] 17\n\n\n\n\n\n\n\n\nCareful of cases!\n\n\n\nOne thing we need to be careful of when using variables is that R is case-sensitive. This means that MY_NUMBER is not the same as my_number:\n\n# create the my_number variable\nmy_number &lt;- (2 + 6) * 7\n\n# produces error because MY_NUMBER is not the same as my_number\nMY_NUMBER\n\nError: object 'MY_NUMBER' not found\n\n\n\n\nThere’s not really any harm in keeping variables around, but if you would like to remove them you can use the rm() function like so:\n\n# assign a variable\nmy_variable &lt;- 10\n\n# remove it\nrm(my_variable) # put the variable name inside the brackets\n\nWe’ll cover functions in more detail in Section 1.5.\nIf you want to remove ALL the variables you’ve assigned and start fresh, you can use the broom button in the environment panel:\n\n\n\nThe broom button removes all your variables\n\n\nTry using the broom to clean up your environment after completing the practice exercises at the end of this section.\n\n\n1.4.3 Choosing good variable names\nWhen naming variables, we need to follow these rules:\n\n\n\n\n\n\n\nRule\nExamples\n\n\n\n\nVariable names can only contain letters, numbers and underscores\n✅ Allowed: my_number, ID_2\n❌ Not allowed: my_number!, price$\n\n\nVariable names can’t start with a number\n✅ Allowed: my_number_2\n❌ Not allowed: 2_my_number\n\n\nVariable names can’t contain spaces\n✅ Allowed: my_number\n❌ Not allowed: my number\n\n\n\nIf we try to create a variable that breaks these rules, R will give an error:\n\n# gives an error because we use a non-allowed character\npercentage% &lt;- 100\n\nError in parse(text = input): &lt;text&gt;:2:11: unexpected input\n1: # gives an error because we use a non-allowed character\n2: percentage% &lt;- 100\n             ^\n\n\n\n# gives an error because we start with a number\n1place &lt;- 1\n\nError in parse(text = input): &lt;text&gt;:2:2: unexpected symbol\n1: # gives an error because we start with a number\n2: 1place\n    ^\n\n\n\n# gives an error because we have a space\nmy age &lt;- 5\n\nError in parse(text = input): &lt;text&gt;:2:4: unexpected symbol\n1: # gives an error because we have a space\n2: my age\n      ^\n\n\nRStudio will try to help you spot these mistakes in your script, by using underlining them in red:\n\n\n\nRStudio underlines errors in your code\n\n\nBeyond those three key rules, there are also some best practices we should try to keep in mind when naming our variables:\n\nTry not to use capital letters. Since R is case sensitive, Genes is a different variable to genes. It can be easy to forget to use a capital letter, so it’s generally better to avoid them if you can.\nUse descriptive names. It’s better to use a longer name that describes what the variable is for, rather than a short name that doesn’t give much information. For example, gene_counts is better than gc. You’ll thank yourself later when you come back to your code and can’t remember what gc stands for!\nAvoid using names that are already used in R. For example, mean is a function in R that calculates the average of a set of numbers. If you use mean as a variable name, this could lead to errors: how will R know if you are referring to the function mean or your variable mean?\n\n\n\n\n\n\n\nPractice exercises\n\n\n\nTry these practice questions to test your understanding\n\n1. How would I assign the value of 10 to a variable called my_variable?\n\n\n\n\n ✗10\n\n\n ✔my_variable &lt;- 10\n\n\n ✗my_variable = 10\n\n\n ✗my variable &lt;- 10\n\n\n\n\n\n\n2. I have assigned the value of 10 to a variable called my_variable as in Q1. What then would be the output from running this line of R code: my_variable + 5?\n\n\n\n\n ✗An error\n\n\n ✗Nothing\n\n\n ✗5\n\n\n ✔15\n\n\n\n\n\n\n3. I have assigned the value of 10 to a variable called my_variable as in Q1. If I run the code my_variable &lt;- my_variable + 10, what is the new value of my_variable?\n\n\n\n\n ✗10\n\n\n ✗25\n\n\n ✔20\n\n\n ✗my_variable\n\n\n\n\n\n\n4. Which of the following is a valid variable name?\n\n\n\n\n ✗10th_place\n\n\n ✗(n)_mice\n\n\n ✗disease status\n\n\n ✔expression_level\n\n\n\n\n\n\n\nSolutions\n\n\n\nmy_variable &lt;- 10 is the correct way to assign the value of 10 to a variable called my_variable. Remember the arrow &lt;- is used for assignment in R.\nThe output would be 15, since my_variable is 10 and we are adding 5 to it.\nThe new value of my_variable would be 20, since we are adding 10 to the current value of my_variable (which is 10). Note that even though we added 5 to my_variable earlier, this value is not saved anywhere (since we didn’t assign it), so we are starting from the original value of 10.\nexpression_level is the only valid variable name. 10th_place starts with a number, (n)_mice contains brackets, and disease status contains a space.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Introduction to R</span>"
    ]
  },
  {
    "objectID": "chapter_1.html#sec-functions",
    "href": "chapter_1.html#sec-functions",
    "title": "1  Introduction to R",
    "section": "1.5 Functions",
    "text": "1.5 Functions\n\n1.5.1 Functions and arguments\nFunctions are programs that take inputs (also known as arguments) and produce outputs. They have a name, followed by round brackets () which contain the arguments.\nFor example, when we used the code rm(my_variable) earlier, the function rm() was taking the input (argument) my_variable and producing the output of deleting that variable.\nSome functions have multiple arguments, which are specified by separating them with commas. Arguments have a set order in which they can be given, or they can be referred to specifically by their name (using a equal sign = to provide a value).\nAs an example, the round() function rounds a number to a specified number of decimal places. The first argument is the number to be rounded, and the second argument is the number of decimal places to round to.\n\n# we'll use this decimal to demonstrate the round function\ndecimal &lt;- 3.14159\n\n# round to 3 decimal places\nround(decimal, digits = 3)\n\n[1] 3.142\n\n# we don't have to specify the argument name if we provide the arguments in the correct order\nround(decimal, 3)\n\n[1] 3.142\n\n\nWe can see that both of our calls to the round() function produced the same result, but the first is easier to understand since we explicitly specified the argument.\nMany arguments have default values so you don’t need to specify every argument for every function. For example, the round() function has a default value of 0 for the digits argument, so if you don’t specify it, the number will be rounded to the nearest whole number.\n\nround(decimal)\n\n[1] 3\n\n\n\n\n\n\n\n\nCommon errors with functions\n\n\n\nHere are some common errors you might encounter when using functions. Have a look at the code below and read the error messages to see how the two relate. This will help you to fix typos/errors in your own code.\n\n# forgot to enclose the arguments in brackets\nround 3.14159\n\nError in parse(text = input): &lt;text&gt;:2:7: unexpected numeric constant\n1: # forgot to enclose the arguments in brackets\n2: round 3.14159\n         ^\n\n\n\n# forgot the comma between the arguments\nround(3.14159 digits = 3)\n\nError in parse(text = input): &lt;text&gt;:2:15: unexpected symbol\n1: # forgot the comma between the arguments\n2: round(3.14159 digits\n                 ^\n\n\n\n# spelt the argument name wrong\nround(3.14159, digts = 3)\n\nError in round(3.14159, digts = 3): unused argument (digts = 3)\n\n\n\n# forgot to close the brackets\nround(3.14159, digits = 3\n\nError in parse(text = input): &lt;text&gt;:3:0: unexpected end of input\n1: # forgot to close the brackets\n2: round(3.14159, digits = 3\n  ^\n\n\nRStudio will also flag some of these sorts of issues in the script panel, although it won’t catch everything:\n\n\n\nRStudio can help you to find errors in your function calls before you run the code\n\n\n\n\n\n\n1.5.2 Getting help with functions: within R\nWhen you’re using a function, you might not know what arguments it takes, what they do or what their default values are. Nobody can remember all of this information, so one of the most important skills in programming is learning how to access help.\nYou can access the help pages for a function by typing ? followed by the name of the function:\n\n?round\n\nOr searching for the function in the help tab in RStudio:\n\n\n\nYou can search for functions directly in the help panel\n\n\nHere’s what the help page looks like for the round function:\n\n\n\nThe help page for the round function\n\n\nHelp pages can sometimes be quite technical or complicated– for example the help page for round also describes various other similar functions for rounding numbers. Often the most important section to look at is the ‘arguments’ one:\n\n\n\nHelp pages have a section for describing arguments\n\n\nYou can also see help for functions in the script panel, as you are typing your code:\n\n\n\nRStudio will show you a preview of the help page as you type a function name\n\n\nIt will also suggest you the names of arguments:\n\n\n\nRStudio also suggests arguments for functions as you type\n\n\nSo, if you get stuck with how to use a function, wait a moment and see if RStudio will suggest what you need.\n\n\n1.5.3 Getting help with functions: beyond R\nSometimes, the R help pages can be pretty tricky to understand, and they can’t help you if you don’t know the name of the function you need! In this course, we’ll learn about lots of different functions, but even R experts need to look things up sometimes. Here are some good resources for getting help:\n\nGoogle. R is a pretty popular language, so if you google ‘how to do x in R’, you’ll probably find an answer\nPackage vignettes. Many R packages have vignettes, which are short guides to using the package. Once you find the name of a package you might want to use, you should go through their vignettes to see what functions are available and how to use them.\nChatGPT (or similar). AI tools can be really useful in helping you write code, although make sure you double-check the results because it can make mistakes. Tips and advice on how to effectively use AI tools is available in the “Further reading” section.\nAsk others! There are lots of R users, and working together is often the best way to solve problems. This could be through online forums, like StackOverflow or in-person\n\nNo matter where you get your help, try to make sure you understand the code you find. Reading the help pages for new functions, or asking an AI like ChatGPT to explain what code is doing is a great way to expand your R knowledge. We also list some recommended additional resources in the “Useful references” section of “Further reading”.\n\n\n\n\n\n\nPractice exercises\n\n\n\nTry these practice questions to test your understanding\n\n1. What would be the result of running this R code: round(3.14159, digits = 2)\n\n\n\n\n ✗3.14159\n\n\n ✗3.141\n\n\n ✔3.14\n\n\n ✗3\n\n\n\n\n\n2. Look up the help pages for the following functions, and describe what they do:\n\nmean()\nSys.Date()\nsin()\n\n\n3. What is wrong with this line of R code: round(3.14159, digits = 3\n\n\n\n\n ✗Digits is not a valid argument for the round function\n\n\n ✗You need to use a double equal sign == for the digits argument\n\n\n ✗You don’t need to specify the digits argument\n\n\n ✔You need to close the brackets at the end of the line\n\n\n\n\n\n\n4. Which of the following lines of R code will run without error?\n\n\n\n\n ✗rm(my_variable\n\n\n ✗round(3.14159, Digits = 3)\n\n\n ✗round(3.14159 digits = 3)\n\n\n ✔round(3.14159, 3)\n\n\n\n\n\n\n\nSolutions\n\n\n\nThe result of running round(3.14159, digits = 2) would be 3.14. Remember the round() function rounds the number 3.14159 to 2 decimal places, according to the digits argument.\nThe mean() function calculates the average of a set of numbers, Sys.Date() returns the current date, and sin() calculates the sine of an angle (in radians).\nThe line of R code round(3.14159, digits = 3 is missing a closing bracket at the end, which is why it would produce an error.\nThe line of R code round(3.14159, 3) will run without error. The other lines of code have errors: rm(my_variable is missing a closing bracket, round(3.14159, Digits = 3) has a typo in the argument name (argument names are case sensitive), and round(3.14159 digits = 3) is missing a comma between the arguments. Remember that we don’t always need to specify the argument names if we provide the arguments in the correct order, which is why we could omit the digits = part in the correct line of code.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Introduction to R</span>"
    ]
  },
  {
    "objectID": "chapter_1.html#sec-dataTypes",
    "href": "chapter_1.html#sec-dataTypes",
    "title": "1  Introduction to R",
    "section": "1.6 Data types",
    "text": "1.6 Data types\nEvery variable in R has a ‘type’. The type tells R what kind of data it is and consequently what it can and can’t do with the data. For example, it makes sense to perform mathematical functions like multiplication or division on numbers but not on words.\nThere are three basic types of data in R:\n\n\n\n\n\n\n\n\nType\nDescription\nExamples\n\n\n\n\nlogical\nalso known as ‘boolean’, true or false\nTRUE\nFALSE\n\n\nnumeric\nnumbers\n1\n0.523\n10000\n\n\ncharacter\ntext/numbers surrounded by quotation marks (double \"\" or single ''). Also known as a ‘string’\n'hello'\n\"cat\"\n\"my name is...\"\n\n\n\nThese are called ‘atomic’ data types as they are the most basic types of data from which other data types derive.\nYou can find the type of something using the class() function:\n\nclass(TRUE)\n\n[1] \"logical\"\n\nclass(1)\n\n[1] \"numeric\"\n\n# whatever you put in quotation marks is always a character\nclass(\"hello\")\n\n[1] \"character\"\n\nclass(\"TRUE\")\n\n[1] \"character\"\n\nclass(\"123\")\n\n[1] \"character\"\n\n\nIt is important to know the type of your data because, as mentioned earlier, R will not let you perform certain operations on data of the wrong type. For example, you can’t add two characters together:\n\n# this works\n1 + 1\n\n[1] 2\n\n# but this gives an error\n\"1\" + \"1\"\n\nError in \"1\" + \"1\": non-numeric argument to binary operator\n\n\nNor can you use the logical operator ! on a character:\n\n# this works\n!TRUE\n\n[1] FALSE\n\n# but this gives an error\n!\"TRUE\"\n\nError in !\"TRUE\": invalid argument type\n\n\nYou’ll notice that the error messages for these two examples explain that R can’t perform the operation you’re asking it to do on that data type.\nIf you want to change the type of a piece of data, you can use the as.x() functions like (e.g.as.logical(), as.numeric(), and as.character()):\n\n# convert a number to a character\nas.character(100)\n\n[1] \"100\"\n\n# convert a character to a number\nas.numeric(\"100\")\n\n[1] 100\n\n\nOf course, it doesn’t make sense to make some conversions. In the example below, we can’t convert the word “hello” to a number, so we get an NA:\n\n# if a conversion is not possible, you'll get an NA\nas.numeric(\"hello\")\n\nWarning: NAs introduced by coercion\n\n\n[1] NA\n\n\n\n\n\n\n\n\nPractice exercises\n\n\n\nTry these practice questions to test your understanding\n\n1. What are the three atomic data types in R?\n\n\n\n\n ✔logical, numeric, character\n\n\n ✗integer, float, string\n\n\n ✗dataset, vector, matrix\n\n\n ✗boolean, text, number\n\n\n\n\n\n\n2. How do you find the type of a piece of data in R?\n\n\n\n\n ✗You can’t\n\n\n ✗Using the type() function\n\n\n ✗Guess\n\n\n ✔Using the class() function\n\n\n\n\n\n\n3. How would you convert the character “TRUE” to a logical?\n\n\n\n\n ✗TRUE\n\n\n ✔as.logical(\"TRUE\")\n\n\n ✗You can’t convert a character to a logical\n\n\n ✗Using the logical() function\n\n\n\n\n\n4. What are the types of the following?\n\n11\n\"eleven\"\nTRUE\n!FALSE\n0.49826\n\"-0.53\"\nas.numeric(\"11\")\n\n\n\nSolutions\n\n\n\nThe three atomic data types in R are logical, numeric, and character.\nYou can find the type of a piece of data in R using the class() function.\nTo convert the character “TRUE” to a logical, you would use as.logical(\"TRUE\") (we always use ‘as…’ functions to convert between types).\nThe types are:\n\n11 is numeric\n\"eleven\" is character\nTRUE is logical\n!FALSE is logical\n0.49826 is numeric\n\"-0.53\" is character (even though it looks like a number, it is surrounded by quotation marks so it is a character)\nas.numeric(\"11\") is numeric (since we converted the character “11” to a number with the as.numeric() function)",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Introduction to R</span>"
    ]
  },
  {
    "objectID": "chapter_1.html#sec-datastructures",
    "href": "chapter_1.html#sec-datastructures",
    "title": "1  Introduction to R",
    "section": "1.7 Data structures",
    "text": "1.7 Data structures\nBeyond the atomic data types, R has more complex data structures that can store multiple values. These are the building blocks of data analysis in R. The most common data structures are vectors, matrices, and data frames.\nThis figure summarises their key differences:\n\n\n\nOverview of the three main data structures in R. 📷 credit: https://bookdown.org/introrbook/intro2r/\n\n\n\n1.7.1 Vectors\nA vector is a collection of values of the same atomic type. Values in a vector are laid out linearly, one after another.\nYou can create vectors with the c() function, like so:\n\n# a vector of numbers\nc(1, 2, 3)\n\n[1] 1 2 3\n\n# a vector of characters\nc(\"a\", \"vector\", \"of\", \"characters\")\n\n[1] \"a\"          \"vector\"     \"of\"         \"characters\"\n\n# a vector of logicals\nc(TRUE, FALSE, TRUE)\n\n[1]  TRUE FALSE  TRUE\n\n\nFun fact: the ‘c’ in c() stands for ‘combine’.\nThere are a few ways to see the contents of a vector. You can simply type the name of the vector into the console, which will print out the whole thing:\n\n# in these examples we will use the letters vector that is\n# pre-loaded in R. It contains the alphabet in lowercase\nletters\n\n [1] \"a\" \"b\" \"c\" \"d\" \"e\" \"f\" \"g\" \"h\" \"i\" \"j\" \"k\" \"l\" \"m\" \"n\" \"o\" \"p\" \"q\" \"r\" \"s\"\n[20] \"t\" \"u\" \"v\" \"w\" \"x\" \"y\" \"z\"\n\n\nYou’ll notice that, in addition to the [1] that we usually see printed next to the output, there is also a [20]. This number is telling us where we are up to in the vector (so [1] means that line of output starts with the first element, \"a\" and [20] means that line of output starts with the 20th element of the vector, \"t\").\nBut what if we don’t always want to print the whole thing? For long vectors, it’s handy to use the head() and tail() functions to inspect just a few values. By default, these print the first and last 6 elements of a vector (you can change that by setting the n argument).\n\n# use head() and tail() to take a quick look\nhead(letters)\n\n[1] \"a\" \"b\" \"c\" \"d\" \"e\" \"f\"\n\ntail(letters)\n\n[1] \"u\" \"v\" \"w\" \"x\" \"y\" \"z\"\n\n\nYou can also use functions to look at other features of a vector, like its type (using the class() function just as for single values) or its length (using the length() function):\n\n# find the class of a vector\nclass(letters)\n\n[1] \"character\"\n\n# find the length of a vector\nlength(letters)\n\n[1] 26\n\n\nJust like you can with single values, vectors can be assigned to variables:\n\npet_names &lt;- c(\"sprinkle\", \"lucky\", \"coco\")\n\nThese variables will show up in the ‘Environment’ tab in RStudio:\n\n\n\nThe environment panel shows vectors too\n\n\nYou’ll notice vector variables are displayed a little differently to those with single values. The type (chr, for character) is displayed first, followed by [1:3] which tells you that the pet_names vector has elements from 1 to 3 (in other words, it has a length of 3). This is particularly helpful when part of the vector is cut off, like in this picture!\n\n\n\n\n\n\nColon (:) notation for vectors\n\n\n\nIn programming, the colon : is typically used to create sequences of numbers. You can use it to create a sequence of numbers from a starting point to an ending point.\nFor example, 1:5 creates a vector of numbers from 1 to 5:\n\n1:5\n\n[1] 1 2 3 4 5\n\n\n\n\nR is a vectorised language, which means that many functions and operations (like *, + etc) work directly on vectors without you having to write extra code. For example, we can use the mean() function to calculate the average of a vector of numbers, or add a single number to each value in the vector:\n\n# create a vector of numbers\nnumbers &lt;- c(1, 2, 3, 4, 5)\n\n# calculate the mean\nmean(numbers)\n\n[1] 3\n\n# add 5 to each value\nnumbers + 5\n\n[1]  6  7  8  9 10\n\n\nBecause the other data structures we’ll cover are built on vectors, this concept will be useful for them as well.\n\n\n1.7.2 Matrices\nA matrix is the two-dimensional extension of the vector– it stores a collection of values of the same type that are laid out in a grid with rows and columns. An example of this is a gene count matrices where each row represents a gene, each column represents a sample and therefore each cell represents the count for a particular gene in a particular sample.\nYou can create a matrix using the matrix() function. The first argument is the vector of values to be put into the matrix, and the nrow and ncol arguments specify the number of rows and columns in the matrix:\n\n# create a 2x2 matrix and assign it to gene_counts\ngene_counts &lt;- matrix(c(1, 2, 3, 4), nrow = 2, ncol = 2)\n\n# print the matrix\ngene_counts\n\n     [,1] [,2]\n[1,]    1    3\n[2,]    2    4\n\n\nUsually though you would read in a matrix from a file (e.g. the gene count matrix from a sequencing experiment).\nMatrices are their own type of object in R:\n\nclass(gene_counts)\n\n[1] \"matrix\" \"array\" \n\n\nAnd they show up in the environment panel in RStudio under ‘Data’: \nThe rows and columns are usually labelled with names, although these names are considered metadata rather than being a part of the matrix. You can set them by assigning vectors of names to the rownames() and colnames() functions:\n\n# set row and column names\nrownames(gene_counts) &lt;- c(\"gene1\", \"gene2\")\ncolnames(gene_counts) &lt;- c(\"sample1\", \"sample2\")\n\n# print the matrix, now with names!\ngene_counts\n\n      sample1 sample2\ngene1       1       3\ngene2       2       4\n\n\n\n\n1.7.3 Data frames\nData frames are similar to matrices in that they store data in rows and columns. The difference is each column can have a different type: for example you could have a column of gene names (character), a column of gene counts (numeric) and another column telling you whether or not the gene is protein-coding (logical). For this reason, data frames are the most common data structure used in R.\nYou can create a data frame using the data.frame() function. The arguments are vectors of values to be put into the data frame, with the names of the vectors becoming the column names:\n\n# create a data frame\nmouse_facts &lt;- data.frame(\n  name = c(\"mickey\", \"minnie\", \"stuart\"),\n  age = c(12, 8, 16),\n  weight = c(39.7, 42.2, 46.3)\n)\n\n# print the data frame\nmouse_facts\n\n    name age weight\n1 mickey  12   39.7\n2 minnie   8   42.2\n3 stuart  16   46.3\n\n\nWhen creating a data frame, it’s important that all vectors are the same length. If they’re not, you’ll get an error:\n\nmouse_facts &lt;- data.frame(\n  name = c(\"mickey\", \"minnie\", \"stuart\"),\n  age = c(12, 8), # forgot to add stuart's age!\n  weight = c(39.7, 42.2, 46.3)\n)\n\nError in data.frame(name = c(\"mickey\", \"minnie\", \"stuart\"), age = c(12, : arguments imply differing number of rows: 3, 2\n\n\nFor the rest of this section, we’ll use the iris data set that comes pre-loaded in R. This is a bigger data set that contains measurements of different species of iris flowers, and will help us to learn how to work with data frames in R.\nFirst, let’s load in the dataset using the data() function:\n\ndata(iris)\n\niris has the class data.frame:\n\nclass(iris)\n\n[1] \"data.frame\"\n\n\nJust like for vectors, there are functions to look at the contents of a data frame. This is useful as printing the whole data frame can be overwhelming if it’s large (try printing iris and see for yourself!). The head() and tail() functions work the same way as for vectors:\n\nhead(iris)\n\n  Sepal.Length Sepal.Width Petal.Length Petal.Width Species\n1          5.1         3.5          1.4         0.2  setosa\n2          4.9         3.0          1.4         0.2  setosa\n3          4.7         3.2          1.3         0.2  setosa\n4          4.6         3.1          1.5         0.2  setosa\n5          5.0         3.6          1.4         0.2  setosa\n6          5.4         3.9          1.7         0.4  setosa\n\ntail(iris)\n\n    Sepal.Length Sepal.Width Petal.Length Petal.Width   Species\n145          6.7         3.3          5.7         2.5 virginica\n146          6.7         3.0          5.2         2.3 virginica\n147          6.3         2.5          5.0         1.9 virginica\n148          6.5         3.0          5.2         2.0 virginica\n149          6.2         3.4          5.4         2.3 virginica\n150          5.9         3.0          5.1         1.8 virginica\n\n\nYou can also use the View() function to open the data frame in a new tab in RStudio:\n\n# don't forget the capital V!\nView(iris)\n\nThis will open a new tab in RStudio with the data frame displayed in a spreadsheet-like format, where you can sort and filter the columns to get a better view of the data:\n\n\n\nThe View() function opens the data frame in a new tab in RStudio\n\n\nAnother way to view the data frame is by clicking on its name in the environment panel:\n\n\n\nClicking on the data frame’s name in the environment panel opens it in the viewer\n\n\nThis panel also shows you the names and types of the columns in the data frame. You might notice that the Species is described as a factor, which is a special type of data in R that we’ll return to in Chapter 6.\nBefore the column names, you’ll see the $ symbol. The dollar sign $ is a shortcut used in R to access columns of a data frame. For example, to access the Petal.Width column of the iris data frame, you can use iris$Petal.Width:\n\niris$Petal.Width\n\n  [1] 0.2 0.2 0.2 0.2 0.2 0.4 0.3 0.2 0.2 0.1 0.2 0.2 0.1 0.1 0.2 0.4 0.4 0.3\n [19] 0.3 0.3 0.2 0.4 0.2 0.5 0.2 0.2 0.4 0.2 0.2 0.2 0.2 0.4 0.1 0.2 0.2 0.2\n [37] 0.2 0.1 0.2 0.2 0.3 0.3 0.2 0.6 0.4 0.3 0.2 0.2 0.2 0.2 1.4 1.5 1.5 1.3\n [55] 1.5 1.3 1.6 1.0 1.3 1.4 1.0 1.5 1.0 1.4 1.3 1.4 1.5 1.0 1.5 1.1 1.8 1.3\n [73] 1.5 1.2 1.3 1.4 1.4 1.7 1.5 1.0 1.1 1.0 1.2 1.6 1.5 1.6 1.5 1.3 1.3 1.3\n [91] 1.2 1.4 1.2 1.0 1.3 1.2 1.3 1.3 1.1 1.3 2.5 1.9 2.1 1.8 2.2 2.1 1.7 1.8\n[109] 1.8 2.5 2.0 1.9 2.1 2.0 2.4 2.3 1.8 2.2 2.3 1.5 2.3 2.0 2.0 1.8 2.1 1.8\n[127] 1.8 1.8 2.1 1.6 1.9 2.0 2.2 1.5 1.4 2.3 2.4 1.8 1.8 2.1 2.4 2.3 1.9 2.3\n[145] 2.5 2.3 1.9 2.0 2.3 1.8\n\n\nTry typing this code into your R script. You’ll notice once you write iris$, RStudio will list out all of the columns like so:\n\n\n\nRStudio will suggest column names as you type\n\n\nYou can navigate through these suggestions using the up and down arrow keys, and press EnterEnter or TabTab to select the column you want.\nThese columns are vectors, so you can use the functions we’ve learned about so far to work with them:\n\n# find the class of the Petal.Width column\nclass(iris$Petal.Width)\n\n[1] \"numeric\"\n\n# find the average Petal.Width column\nmean(iris$Petal.Width)\n\n[1] 1.199333\n\n\n\n\n\n\n\n\nPractice exercises\n\n\n\nTry these practice questions to test your understanding\n\n1. Which of the following is NOT a valid vector in R?\n\n\n\n\n ✗c(TRUE, FALSE, FALSE)\n\n\n ✔(1, 2, 3, 4)\n\n\n ✗1:10\n\n\n ✗c(\"cat\", \"dog\", \"fish\")\n\n\n\n\n\n\n2. What is the result of running this R code: c(1, 2, 3) * 2?\n\n\n\n\n ✗2(1, 2, 3)\n\n\n ✗c(1, 2, 3, 1, 2, 3)\n\n\n ✗c(1, 2, 3, 2)\n\n\n ✔c(2, 4, 6)\n\n\n\n\n\n\n3. What is the difference between a matrix and a data frame?\n\n\n\n\n ✔A matrix has all elements of the same type, while a data frame can have different types in each column\n\n\n ✗They’re the same thing\n\n\n ✗A matrix can only contain numbers, while a data frame can contain numbers and text\n\n\n ✗A matrix is used for mathematical operations, while a data frame is used for data analysis\n\n\n\n\n\n\n4. I wrote this code to create a data frame, but it gave me an error. What is wrong with it?\n\nfavourite_fruits &lt;- data.frame(\n  fruit = c(\"apple\", \"banana\", \"cherry\"),\n  colour = c(\"red\", \"yellow\", \"red\"),\n  price = c(0.5, 0.3)\n)\n\n\n\n\n\n ✗The column names are not in quotation marks\n\n\n ✔The columns are not the same length: ‘fruit’ and ‘colour’ have 3 elements, but ‘price’ has 2\n\n\n ✗It’s not allowed to have character columns and numeric columns in the same data frame\n\n\n ✗You should use the tibble() function instead of data.frame()\n\n\n\n\n\n\n5. What is NOT a way that I could view the contents of a data frame in R?\n\n\n\n\n ✗Running the name of the data frame as code in the R script panel\n\n\n ✗Typing the name of the data frame into the console\n\n\n ✗Clicking on its name in the environment panel\n\n\n ✔Using the view() function\n\n\n\n\n\n\n6. I have created the mouse_facts data frame using the code below. How would I calculate the average age of the mice?\n\nmouse_facts &lt;- data.frame(\n  name = c(\"mickey\", \"minnie\", \"stuart\"),\n  age = c(12, 8, 16),\n  weight = c(39.7, 42.2, 46.3)\n)\n\n\n\n\n\n ✗mean(age)\n\n\n ✔mean(mouse_facts$age)\n\n\n ✗average(age)\n\n\n ✗average(mouse_facts$age)\n\n\n\n\n\n\n\nSolutions\n\n1. The vector (1, 2, 3, 4) is not a valid vector: you need to use the c() function to create a vector in R. The exception is the colon : notation, which creates a sequence of numbers.\n2. The result of running c(1, 2, 3) * 2 would be c(2, 4, 6). This is because R is a vectorised language, so the * operator multiplies each element of the vector by 2.\n3. The difference between a matrix and a data frame is that a matrix has all elements of the same type (could be character, logical or numeric), while a data frame can have different types in each column.\n4. The code to create the data frame favourite_fruits gave an error because the columns are not the same length: ‘fruit’ and ‘colour’ have 3 elements, but ‘price’ has 2. You can’t create a data frame with columns of different lengths. As for the other options, you can have character and numeric columns in the same data frame, the column names don’t need to be in quotation marks (although the code will work if they are), and the tibble() function is an alternative to data.frame() but either is fine.\n5. Using the view() function is not a way to view the contents of a data frame in R. The correct function is View() (with a capital ‘V’). All the other options are valid ways to view the contents of a data frame.\n6. To calculate the average age of the mice, you would use mean(mouse_facts$age). This is because the age column is part of the mouse_facts data frame, so you need to use the $ symbol to access it, and the function for calculating the average in R is mean().",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Introduction to R</span>"
    ]
  },
  {
    "objectID": "chapter_1.html#sec-readingin",
    "href": "chapter_1.html#sec-readingin",
    "title": "1  Introduction to R",
    "section": "1.8 Reading in data",
    "text": "1.8 Reading in data\nSo far, we’ve explored the basics of R by creating our own data, or using built-in data objects like letters or iris. However, in real life analyses, we almost always need to read in data from files on our computers.\nIn this section we will use the file named mousezempic_dosage_data.csv, which you downloaded from the Setup instructions at the start of this book.\nCheck in the Files tab (bottom right panel) that this file is in the project directory you have made for this course (it’s generally a good idea to keep all the data and code for a certain analysis together). It should be inside a folder named data.\n\n1.8.1 Paths\nPaths tell R where to find the file you want to read in. They are strings of characters that first include the directory or series of directories in which a file is located, followed by the name of the file itself. For example, the path to a file called my_data.csv in a folder called data would be data/my_data.csv.\nIn this course, we will use RStudio to help us find the paths to our files, without needing to type them out ourselves. If you’re interested in learning more about paths, codeacademy has a nice simple article on them.\nTo find a file path easily in RStudio, you can use the file explorer panel. First, open it by clicking on the ‘Files’ tab in the bottom right panel of RStudio:\n\n\n\nThe file explorer panel in RStudio\n\n\nBy default, it will put you in your project directory. If you have data files in a different directory, you can navigate to that directory by clicking on the folders. Here, I have navigated to a folder on my desktop called ‘data’, which is inside the ‘R_course’ folder. Once you’re in the right place, to get the path for that folder, click on More &gt; Copy Folder Path to Clipboard:\n\n\n\nCopying the folder path to the clipboard\n\n\nThis will copy the path to the folder to your clipboard, which you can then paste into your R script. Then, you just need to add a / followed by the name of the file to the end of the path.\nFor example, the path to the folder in the above image is ~/Desktop/BIOL90042_workshops/data, so the path to the mousezempic_dosage_data.csv file is ~/Desktop/BIOL90042_workshops/data/mousezempic_dosage_data.csv.\n\n\n1.8.2 Reading data with functions\nNow that we know how to find our data, we can read it in. We’ll do this using a handy package called readr, that is part of the tidyverse.\n\n\n\n\n\n\nPackages in R\n\n\n\nPackages are collections of functions that other people have written to help us do specific tasks, beyond what is built-in to R itself. The tidyverse is a collection of packages that help to streamline data analysis in R. Its a ‘universe of functions for tidy data analysis.’ To use the tidyverse, we first need to install it. This is done using the install.packages() function run in the Setup code. If you have run the Setup code, there is no need to run the code below again, but for reference:\n\n# install the tidyverse package\n# only do this once\ninstall.packages(\"tidyverse\")\n\nWe only need to install a package once, but you must load it each time you open R. This is done using the library() function:\n\n# load the tidyverse package\n# do this every time you open R\nlibrary(tidyverse)\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.4     ✔ readr     2.1.5\n✔ forcats   1.0.0     ✔ stringr   1.5.1\n✔ ggplot2   3.5.2     ✔ tibble    3.3.0\n✔ lubridate 1.9.4     ✔ tidyr     1.3.1\n✔ purrr     1.1.0     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\n\nYou’ll see some output from the tidyverse package when you load it, which is just telling you that some of the tidyverse functions have the same name as other functions in R.\nIf you forget to load a package, R will give you an error when you try to use that package’s functions, so it’s usually a good idea to load all the packages you’ll need at the start of your script to prevent you forgetting to load them the next time you open R. We’ll do this at the start of each chapter in this course.\n\n\nTo read in our data, we’ll use the read_delim() function from the readr package. This function takes in the path to the file you want to read in (in quotation marks \"\", as this is a character string) and returns as output a tibble.\n\nread_delim(\"~/Desktop/BIOL90042_workshops/data/mousezempic_dosage_data.csv\")\n\n\n\n\n\n\n\nDelimiters\n\n\n\nThe ‘delim’ in ‘read_delim’ stands for delimiter, and refers to the character used to separates columns of the data.\nThe most common types of delimiter are comma-separated values (.csv files) and tab-separated values (.tsv files). Here’s an example of what they look like:\n\n\nexample.csv\n\nName, Age\nAndy, 10\nBob, 8\n\n\n\n\n\nexample.tsv\n\nName  Age\nAndy  10\nBob   8\n\nBy default read_delim() will guess your delimiter, so it’s easiest to use that to read files, no matter their format. However, if you read other people’s code, you might also encounter the read_tsv() and read_csv() functions which are specifically for reading in tab-separated and comma-separated files, respectively. It’s up to you which you use, just make sure to get the delimiter right! If you try to read in a file with the wrong delimiter, it’ll look like a mess.\n\n\nWhat happens if we use the wrong delimiter?\n\nAs an example, let’s try reading in our comma-separated file with read_tsv(), which is specifically for tab-separated files:\n\nread_tsv(\"~/Desktop/BIOL90042_workshops/data/mousezempic_dosage_data.csv\")\n\n\n\nRows: 344 Columns: 1\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \"\\t\"\nchr (1): mouse_strain,cage_number,weight_lost_g,replicate,sex,drug_dose_g,ta...\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n\n# A tibble: 344 × 1\n   mouse_strain,cage_number,weight_lost_g,replicate,sex,drug_dose_g,tail_lengt…¹\n   &lt;chr&gt;                                                                        \n 1 CD-1,1A,3.75,rep1,male,0.00181,18.7,39.1,1                                   \n 2 CD-1,1A,3.8,rep1,female,0.0018600000000000001,17.4,39.5,2                    \n 3 CD-1,1A,3.25,rep1,female,0.00195,18,40.3,3                                   \n 4 CD-1,1A,NA,rep1,NA,NA,NA,NA,4                                                \n 5 CD-1,1A,3.45,rep1,female,0.00192999999999999,19.3,36.7,5                     \n 6 CD-1,1A,3.65,rep1,male,0.0019,20.6,39.3,6                                    \n 7 CD-1,1A,3.625,rep1,female,0.00181,17.8,38.9,7                                \n 8 CD-1,1A,4.675,rep1,male,0.00195,19.6,39.2,8                                  \n 9 CD-1,1A,3.475,rep1,NA,0.00192999999999999,18.1,34.1,9                        \n10 CD-1,1A,4.25,rep1,NA,0.0019,20.2,42,10                                       \n# ℹ 334 more rows\n# ℹ abbreviated name:\n#   ¹​`mouse_strain,cage_number,weight_lost_g,replicate,sex,drug_dose_g,tail_length_mm,initial_weight_g,id_num`\n\n\nWe can see that the data is all in one column, which is not what we want!\n\n\n\nDepending on where you have put your data, your path to the mousezempic_dosage_data.csv file may be different. You should be able to find the path by following the instructions in the ‘Paths’ section above.\n\n\n\n\n\n\nUsing RStudio to autocomplete paths\n\n\n\nAnother conveninent way to get the path of your file (so long as you are working within an R project) is to use a feature called ‘tab completion’. Within R projects, R can discover any files sitting in, or downstream of the project directory. So, assuming our mousezempic_dosage_data.csv file is located within a folder called ‘data’, if we start typing read_delim(\"data/mouse then press TabTab, R will auto-complete the full file path and close the quotes and bracket for us!\nEven better, we need only type read_delim('mouse and RStudio will find all files within the project beginning with that word, and automatically fill in the required file path!\n\n\nNow, let’s take a look at the output of read_delim():\n\n\nRows: 344 Columns: 9\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (4): mouse_strain, cage_number, replicate, sex\ndbl (5): weight_lost_g, drug_dose_g, tail_length_mm, initial_weight_g, id_num\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n\n# A tibble: 344 × 9\n   mouse_strain cage_number weight_lost_g replicate sex    drug_dose_g\n   &lt;chr&gt;        &lt;chr&gt;               &lt;dbl&gt; &lt;chr&gt;     &lt;chr&gt;        &lt;dbl&gt;\n 1 CD-1         1A                   3.75 rep1      male       0.00181\n 2 CD-1         1A                   3.8  rep1      female     0.00186\n 3 CD-1         1A                   3.25 rep1      female     0.00195\n 4 CD-1         1A                  NA    rep1      &lt;NA&gt;      NA      \n 5 CD-1         1A                   3.45 rep1      female     0.00193\n 6 CD-1         1A                   3.65 rep1      male       0.0019 \n 7 CD-1         1A                   3.62 rep1      female     0.00181\n 8 CD-1         1A                   4.68 rep1      male       0.00195\n 9 CD-1         1A                   3.48 rep1      &lt;NA&gt;       0.00193\n10 CD-1         1A                   4.25 rep1      &lt;NA&gt;       0.0019 \n# ℹ 334 more rows\n# ℹ 3 more variables: tail_length_mm &lt;dbl&gt;, initial_weight_g &lt;dbl&gt;,\n#   id_num &lt;dbl&gt;\n\n\nThe first line tells us how many rows and columns are in the data. Then, the Column specification section tells you:\n\nWhat delimiter was used to separate values.\nWhich columns belong to each type. read_delim() is quite clever and will guess this for us, but it’s useful to check and make sure it’s correct.\n\nThen, the data will be printed out as a tibble.\n\n\n\n\n\n\nTibbles and data frames\n\n\n\nTibbles are a more modern version of data frames introduced in the tidyverse. They are very similar to data frames, but have some additional features like printing more nicely in the console.\nLet’s use iris to highlight the advantages of tibbles:\n\n# need to load the tidyverse package to use tibbles\n# see below for more information on loading packages\nlibrary(tidyverse)\n\nWhen we print a data frame, it shows every single row and column, which can be overwhelming if the data frame is large:\n\n\nClick here to print iris as a data frame!\n\n\n# print iris\niris\n\n    Sepal.Length Sepal.Width Petal.Length Petal.Width    Species\n1            5.1         3.5          1.4         0.2     setosa\n2            4.9         3.0          1.4         0.2     setosa\n3            4.7         3.2          1.3         0.2     setosa\n4            4.6         3.1          1.5         0.2     setosa\n5            5.0         3.6          1.4         0.2     setosa\n6            5.4         3.9          1.7         0.4     setosa\n7            4.6         3.4          1.4         0.3     setosa\n8            5.0         3.4          1.5         0.2     setosa\n9            4.4         2.9          1.4         0.2     setosa\n10           4.9         3.1          1.5         0.1     setosa\n11           5.4         3.7          1.5         0.2     setosa\n12           4.8         3.4          1.6         0.2     setosa\n13           4.8         3.0          1.4         0.1     setosa\n14           4.3         3.0          1.1         0.1     setosa\n15           5.8         4.0          1.2         0.2     setosa\n16           5.7         4.4          1.5         0.4     setosa\n17           5.4         3.9          1.3         0.4     setosa\n18           5.1         3.5          1.4         0.3     setosa\n19           5.7         3.8          1.7         0.3     setosa\n20           5.1         3.8          1.5         0.3     setosa\n21           5.4         3.4          1.7         0.2     setosa\n22           5.1         3.7          1.5         0.4     setosa\n23           4.6         3.6          1.0         0.2     setosa\n24           5.1         3.3          1.7         0.5     setosa\n25           4.8         3.4          1.9         0.2     setosa\n26           5.0         3.0          1.6         0.2     setosa\n27           5.0         3.4          1.6         0.4     setosa\n28           5.2         3.5          1.5         0.2     setosa\n29           5.2         3.4          1.4         0.2     setosa\n30           4.7         3.2          1.6         0.2     setosa\n31           4.8         3.1          1.6         0.2     setosa\n32           5.4         3.4          1.5         0.4     setosa\n33           5.2         4.1          1.5         0.1     setosa\n34           5.5         4.2          1.4         0.2     setosa\n35           4.9         3.1          1.5         0.2     setosa\n36           5.0         3.2          1.2         0.2     setosa\n37           5.5         3.5          1.3         0.2     setosa\n38           4.9         3.6          1.4         0.1     setosa\n39           4.4         3.0          1.3         0.2     setosa\n40           5.1         3.4          1.5         0.2     setosa\n41           5.0         3.5          1.3         0.3     setosa\n42           4.5         2.3          1.3         0.3     setosa\n43           4.4         3.2          1.3         0.2     setosa\n44           5.0         3.5          1.6         0.6     setosa\n45           5.1         3.8          1.9         0.4     setosa\n46           4.8         3.0          1.4         0.3     setosa\n47           5.1         3.8          1.6         0.2     setosa\n48           4.6         3.2          1.4         0.2     setosa\n49           5.3         3.7          1.5         0.2     setosa\n50           5.0         3.3          1.4         0.2     setosa\n51           7.0         3.2          4.7         1.4 versicolor\n52           6.4         3.2          4.5         1.5 versicolor\n53           6.9         3.1          4.9         1.5 versicolor\n54           5.5         2.3          4.0         1.3 versicolor\n55           6.5         2.8          4.6         1.5 versicolor\n56           5.7         2.8          4.5         1.3 versicolor\n57           6.3         3.3          4.7         1.6 versicolor\n58           4.9         2.4          3.3         1.0 versicolor\n59           6.6         2.9          4.6         1.3 versicolor\n60           5.2         2.7          3.9         1.4 versicolor\n61           5.0         2.0          3.5         1.0 versicolor\n62           5.9         3.0          4.2         1.5 versicolor\n63           6.0         2.2          4.0         1.0 versicolor\n64           6.1         2.9          4.7         1.4 versicolor\n65           5.6         2.9          3.6         1.3 versicolor\n66           6.7         3.1          4.4         1.4 versicolor\n67           5.6         3.0          4.5         1.5 versicolor\n68           5.8         2.7          4.1         1.0 versicolor\n69           6.2         2.2          4.5         1.5 versicolor\n70           5.6         2.5          3.9         1.1 versicolor\n71           5.9         3.2          4.8         1.8 versicolor\n72           6.1         2.8          4.0         1.3 versicolor\n73           6.3         2.5          4.9         1.5 versicolor\n74           6.1         2.8          4.7         1.2 versicolor\n75           6.4         2.9          4.3         1.3 versicolor\n76           6.6         3.0          4.4         1.4 versicolor\n77           6.8         2.8          4.8         1.4 versicolor\n78           6.7         3.0          5.0         1.7 versicolor\n79           6.0         2.9          4.5         1.5 versicolor\n80           5.7         2.6          3.5         1.0 versicolor\n81           5.5         2.4          3.8         1.1 versicolor\n82           5.5         2.4          3.7         1.0 versicolor\n83           5.8         2.7          3.9         1.2 versicolor\n84           6.0         2.7          5.1         1.6 versicolor\n85           5.4         3.0          4.5         1.5 versicolor\n86           6.0         3.4          4.5         1.6 versicolor\n87           6.7         3.1          4.7         1.5 versicolor\n88           6.3         2.3          4.4         1.3 versicolor\n89           5.6         3.0          4.1         1.3 versicolor\n90           5.5         2.5          4.0         1.3 versicolor\n91           5.5         2.6          4.4         1.2 versicolor\n92           6.1         3.0          4.6         1.4 versicolor\n93           5.8         2.6          4.0         1.2 versicolor\n94           5.0         2.3          3.3         1.0 versicolor\n95           5.6         2.7          4.2         1.3 versicolor\n96           5.7         3.0          4.2         1.2 versicolor\n97           5.7         2.9          4.2         1.3 versicolor\n98           6.2         2.9          4.3         1.3 versicolor\n99           5.1         2.5          3.0         1.1 versicolor\n100          5.7         2.8          4.1         1.3 versicolor\n101          6.3         3.3          6.0         2.5  virginica\n102          5.8         2.7          5.1         1.9  virginica\n103          7.1         3.0          5.9         2.1  virginica\n104          6.3         2.9          5.6         1.8  virginica\n105          6.5         3.0          5.8         2.2  virginica\n106          7.6         3.0          6.6         2.1  virginica\n107          4.9         2.5          4.5         1.7  virginica\n108          7.3         2.9          6.3         1.8  virginica\n109          6.7         2.5          5.8         1.8  virginica\n110          7.2         3.6          6.1         2.5  virginica\n111          6.5         3.2          5.1         2.0  virginica\n112          6.4         2.7          5.3         1.9  virginica\n113          6.8         3.0          5.5         2.1  virginica\n114          5.7         2.5          5.0         2.0  virginica\n115          5.8         2.8          5.1         2.4  virginica\n116          6.4         3.2          5.3         2.3  virginica\n117          6.5         3.0          5.5         1.8  virginica\n118          7.7         3.8          6.7         2.2  virginica\n119          7.7         2.6          6.9         2.3  virginica\n120          6.0         2.2          5.0         1.5  virginica\n121          6.9         3.2          5.7         2.3  virginica\n122          5.6         2.8          4.9         2.0  virginica\n123          7.7         2.8          6.7         2.0  virginica\n124          6.3         2.7          4.9         1.8  virginica\n125          6.7         3.3          5.7         2.1  virginica\n126          7.2         3.2          6.0         1.8  virginica\n127          6.2         2.8          4.8         1.8  virginica\n128          6.1         3.0          4.9         1.8  virginica\n129          6.4         2.8          5.6         2.1  virginica\n130          7.2         3.0          5.8         1.6  virginica\n131          7.4         2.8          6.1         1.9  virginica\n132          7.9         3.8          6.4         2.0  virginica\n133          6.4         2.8          5.6         2.2  virginica\n134          6.3         2.8          5.1         1.5  virginica\n135          6.1         2.6          5.6         1.4  virginica\n136          7.7         3.0          6.1         2.3  virginica\n137          6.3         3.4          5.6         2.4  virginica\n138          6.4         3.1          5.5         1.8  virginica\n139          6.0         3.0          4.8         1.8  virginica\n140          6.9         3.1          5.4         2.1  virginica\n141          6.7         3.1          5.6         2.4  virginica\n142          6.9         3.1          5.1         2.3  virginica\n143          5.8         2.7          5.1         1.9  virginica\n144          6.8         3.2          5.9         2.3  virginica\n145          6.7         3.3          5.7         2.5  virginica\n146          6.7         3.0          5.2         2.3  virginica\n147          6.3         2.5          5.0         1.9  virginica\n148          6.5         3.0          5.2         2.0  virginica\n149          6.2         3.4          5.4         2.3  virginica\n150          5.9         3.0          5.1         1.8  virginica\n\n\n\nBut when we print a tibble, only a small preview is shown, which is much easier to read:\n\n# print iris as a tibble\nas_tibble(iris)\n\n# A tibble: 150 × 5\n   Sepal.Length Sepal.Width Petal.Length Petal.Width Species\n          &lt;dbl&gt;       &lt;dbl&gt;        &lt;dbl&gt;       &lt;dbl&gt; &lt;fct&gt;  \n 1          5.1         3.5          1.4         0.2 setosa \n 2          4.9         3            1.4         0.2 setosa \n 3          4.7         3.2          1.3         0.2 setosa \n 4          4.6         3.1          1.5         0.2 setosa \n 5          5           3.6          1.4         0.2 setosa \n 6          5.4         3.9          1.7         0.4 setosa \n 7          4.6         3.4          1.4         0.3 setosa \n 8          5           3.4          1.5         0.2 setosa \n 9          4.4         2.9          1.4         0.2 setosa \n10          4.9         3.1          1.5         0.1 setosa \n# ℹ 140 more rows\n\n\nIt also tells us the number of rows (150) and columns (5) in the data, as well as the types of each column (&lt;dbl&gt; is short for double, which is a type of numeric data). Unlike data frames, tibbles can not include row names that sit ‘outside’ the cells.\nFor the purpose of this course, we can treat tibbles and data frames as the same thing. However, if you’re interested in learning more about tibbles, you can read about them here.\n\n\nNo matter which function you use to read in your data, R simply prints the values out in the console. To actually work with data in R, we need assign our data frame to a variable:\n\nm_dose &lt;- read_delim(\"~/Desktop/R_course/data/mousezempic_dosage_data.csv\")\n\n\n\nRows: 344 Columns: 9\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (4): mouse_strain, cage_number, replicate, sex\ndbl (5): weight_lost_g, drug_dose_g, tail_length_mm, initial_weight_g, id_num\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n\n\n\n1.8.3 Reading data through RStudio’s graphical interface\nYou can also read in data through RStudio’s graphical interface. This is a good way to get the code to read in data if you’re not sure how to do it yourself.\nTo do this, click on the ‘Import Dataset’ button in the environment panel (for our data, we will use the ‘from Text (readr)’ option):\n\n\n\nThe import dataset button in the environment panel\n\n\nThis will open a window where you can select the file you want to read in, like so:\n\n\n\nThe import dataset window in RStudio\n\n\nR will then generate the code to read in the data for you, and you can use the preview to check that it has worked ok:\n\n\n\nRStudio will then read in the data, and give you the code that it used\n\n\nYou can then copy this code and paste it into your script. This step is really important because not only does it helps you to learn how to read in data yourself, it keeps a record in the script of how you read in the data so that you can reproduce your analysis later.\n\n\n\nDon’t forget to paste the code into the script!!!\n\n\n\n\n\n\n\n\nPractice exercises\n\n\n\nTry these practice questions to test your understanding\n\n1. What is a path?\n\n\n\n\n ✗A type of data in R\n\n\n ✗The data you want to analyse\n\n\n ✔A string of characters that tells R where to find a file\n\n\n ✗A function in R\n\n\n\n\n\n\n2. What is NOT a way to read in a file called my_data.tsv in R?\n\n\n\n\n ✗Using the read_delim() function\n\n\n ✗Using the ‘Import Dataset’ button in RStudio\n\n\n ✗Using the read_tsv() function\n\n\n ✔Using the read_csv() function\n\n\n\n\n\n\n3. What do we need to do before we can use functions from readr or any other R package?\n\n\n\n\n ✗Install it\n\n\n ✔Install it, then load it into our R session using the library() function\n\n\n ✗Download it\n\n\n ✗Look at the help page for the functions we want to use\n\n\n\n\n\n\n\nSolutions\n\n1. A path is a string of characters that tells R where to find a file. Note that it isn’t the data itself, but rather the location of the data.\n2. The read_csv() function is not a way to read in a file called my_data.tsv, because it is specifically for reading in comma-separated files, so it would not work for a tab-separated file like my_data.tsv.\n3. Before we can use functions from readr or any other R package, we need to install it, then load it into our R session using the library() function. Otherwise we will get an error message when we try to use the functions.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Introduction to R</span>"
    ]
  },
  {
    "objectID": "chapter_1.html#summary",
    "href": "chapter_1.html#summary",
    "title": "1  Introduction to R",
    "section": "1.9 Summary",
    "text": "1.9 Summary\n\nHere’s what we’ve learnt in this chapter:\n\nHow to create an R project (to keep our files organised) and how to write and run code from an R script (so that the code is saved as a record of our work)\nThe operators for basic maths (*, /, + and -) and comparisons (==, &lt;, &lt;= and !)\nHow to use functions and specify their arguments, as well as how to get help\nHow to assign variables using the &lt;- operator, and how to name them appropriately\nThe three basic atomic data types in R (character, numeric and logical)\nThree different data structures in R (vectors, matrices and data frames/tibbles)\nHow to find file paths using RStudio\nHow to load the readr package and use it to read in files\n\nTry the practice questions below to test your understanding!\n\n1.9.1 Practice questions\n\nWhat would be the result of evaluating the following expressions? You don’t need to know these off the top of your head, use R to help! (Hint: some expressions might give an error. Try to think about why)\n\n5 + 10\n100 &gt;= (5 + 2) ^ 2\n!(100 &gt; 1)\n500 = 5 * 100\n2fast &lt;- \"zoom\"\nround(428.195721, 2)\n?t.test\nclass(\"banana\")\nclass(as.numeric(\"500\"))\n\"1\" + \"10\"\nlength(1:100)\nsum(c(1, 2, 3, 4))\nhead(iris)\nmean(iris$Sepal.Width)\nread_tsv(\"gene_counts.csv\")\n\nWrite some R code to complete the right-hand side of this comparison: as.numeric(\"100\") * 3 ==\nI wrote the following R code, and got an error. How can I fix it?\n\n# the number of frogs I counted\nFrog_counts &lt;- c(11, 2, 4, 9, 10)\n\n# convert to a proportion: divide by the sum\nfrog_counts / sum(Frog_counts)\n\nError: object 'frog_counts' not found\n\n\nLoad the iris dataframe into your R session using data(iris). What is the median petal length? Show the code you used to calculate this.\nImagine I have a file called mouse_survival.tsv located in a folder with the path ~/Downloads/experimental_data/latest. Write a line of R code to read in this file and assign it to a variable called mouse_survival\n\n\n\nSolutions\n\n\nThe results of evaluating the expressions are:\n\n5 + 10 is 15\n100 &gt;= (5 + 2) ^ 2 is TRUE\n!(100 &gt; 1) is FALSE (although 100 is greater than 1, the ! operator negates this)\n500 = 5 * 100 gives an error because we need two equals signs == to check for equality in R. Actually this code is trying to assign the value of 5 * 100 to the variable 500, which is not allowed, because variable names can’t start with a number.\n2fast &lt;- \"zoom\" gives an error because variable names can’t start with a number\nround(428.195721, 2) is 428.2\n?t.test opens the help page for the t.test() function\nclass(\"banana\") is \"character\"\nclass(as.numeric(\"500\")) is \"numeric\"\n\"1\" + \"10\" gives an error because you can’t add two character strings together\nlength(1:100) is 100\nsum(c(1, 2, 3, 4)) is 10\nhead(iris) shows the first 6 rows of the iris data frame\nmean(iris$Sepal.Width) is the average of the Sepal.Width column in the iris data frame\nread_tsv(\"gene_counts.csv\") will try to read in gene_counts.csv as if it were tab-separated, which will result in all the data being in one column\n\nThe right-hand side of the comparison as.numeric(\"100\") * 3 == can be anything that results in 300 e.g. 300 or 299 + 1, for example\nThe error in the code is because the variable name Frog_counts is not the same as frog_counts. R is case-sensitive, so it thinks you are trying to divide a variable that doesn’t exist. To fix this, make sure all your variables have the same case (lowercase is better!):\n\n\n    # the number of frogs I counted\n    frog_counts &lt;- c(11, 2, 4, 9, 10)\n\n    # convert to a proportion: divide by the sum\n    frog_counts / sum(frog_counts)\n\n[1] 0.30555556 0.05555556 0.11111111 0.25000000 0.27777778\n\n\n\nTo calculate the median petal length in the iris data frame, you can use median(iris$Petal.Length)\nTo read in the mouse_survival.tsv file and assign it to a variable called mouse_survival, you could use red_delim(): mouse_survival &lt;- read_delim(\"~/Downloads/experimental_data/latest/mouse_survival.tsv\") or read_tsv(): mouse_survival &lt;- read_tsv(\"~/Downloads/experimental_data/latest/mouse_survival.tsv\").",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Introduction to R</span>"
    ]
  },
  {
    "objectID": "chapter_2.html",
    "href": "chapter_2.html",
    "title": "2  Working with data - Part 1",
    "section": "",
    "text": "2.1 Chaining functions together with pipes\nIn this chapter we will learn how to manipulate and summarise data using the dplyr package (with a little help from the tidyr package too).\nBoth dplyr and tidyr are contained within the tidyverse (along with readr) so we can load all of these packages at once using library(tidyverse):\nPipes are a powerful feature of the tidyverse that allow you to chain multiple functions together. Pipes are useful because they allow you to break down complex operations into smaller steps that are easier to read and understand.\nFor example, take the following code:\nmy_vector &lt;- c(1, 2, 3, 4, 5)\nas.character(round(mean(my_vector)))\n\n[1] \"3\"\nWhat do you think this code does? It calculates the mean of my_vector, rounds the result to the nearest whole number, and then converts the result to a character. But the code is a bit hard to read because you have to start from the inside of the brackets and work your way out.\nInstead, we can use the pipe operator (%&gt;%) to chain these functions together in a more readable way:\nmy_vector &lt;- 1:5\nmy_vector %&gt;% mean() %&gt;% round() %&gt;% as.character()\n\n[1] \"3\"\nSee how the code reads naturally from left to right? You can think of the pipe as being like the phrase “and then”. Here, we’re telling R: “Take my_vector, and then calculate the mean, and then round the result, and then convert it to a character.”\nYou’ll notice that we didn’t need to specify the input to each function. That’s because the pipe automatically passes the output of the previous function as the first input to the next function. We can still specify additional arguments to each function if we need to. For example, if we wanted to round the mean to 2 decimal places, we could do this:\nmy_vector %&gt;% mean() %&gt;% round(digits = 2) %&gt;% as.character()\n\n[1] \"3\"\nR is clever enough to know that the first argument to round() is still the output of mean(), even though we’ve now specified the digits argument.\nTo type the pipe operator more easily, you can use the keyboard shortcut Cmd-shift-MCmd-shift-M (although once you get used to it, you might find it easier to type %&gt;% manually).",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Working with data - Part 1</span>"
    ]
  },
  {
    "objectID": "chapter_2.html#sec-pipes",
    "href": "chapter_2.html#sec-pipes",
    "title": "2  Working with data - Part 1",
    "section": "",
    "text": "Plenty of pipes\n\n\n\nThere is another style of pipe in R, called the ‘base R pipe’ |&gt;, which is available in R version 4.1.0 and later. The base R pipe works in a similar way to the magrittr pipe (%&gt;%) that we use in this course, but it is not as flexible. We recommend using the magrittr pipe for now.\nFun fact: the magrittr package is named after the artist René Magritte, who made a famous painting of a pipe.\n\n\n\n\n\n\n\n\n\nPractice exercises\n\n\n\nTry these practice questions to test your understanding\n\n1. What is NOT a valid way to re-write the following code using the pipe operator: round(sqrt(sum(1:10)), 1). If you’re not sure, try running the different options in the console to see which one gives the same answer.\n\n\n\n\n ✗1:10 %&gt;% sum() %&gt;% sqrt() %&gt;% round(1)\n\n\n ✔sum(1:10) %&gt;% sqrt(1) %&gt;% round()\n\n\n ✗1:10 %&gt;% sum() %&gt;% sqrt() %&gt;% round(digits = 1)\n\n\n ✗sum(1:10) %&gt;% sqrt() %&gt;% round(digits = 1)\n\n\n\n\n\n\n2. What is the output of the following code? letters %&gt;% head() %&gt;% toupper() Try to guess it before copy-pasting into R.\n\n\n\n\n ✗\"A\" \"B\" \"C\" \"D\" \"E\" \"F\" \"G\" \"H\" \"I\" \"J\" \"K\" \"L\" \"M\" \"N\" \"O\" \"P\" \"Q\" \"R\" \"S\" \"T\" \"U\" \"V\" \"W\" \"X\" \"Y\" \"Z\"\n\n\n ✗\"a\" \"b\" \"c\" \"d\" \"e\" \"f\"\n\n\n ✗An error\n\n\n ✔\"A\" \"B\" \"C\" \"D\" \"E\" \"F\"\n\n\n\n\n\n\n\nSolutions\n\n\n\nThe invalid option is sum(1:10) %&gt;% sqrt(1) %&gt;% round(). This is because the sqrt() function only takes one argument, so you can’t specify 1 as an argument in addition to what is being piped in from sum(1:10). Note that some options used the pipe to send 1:10 to sum() (like 1:10 %&gt;% sum()), and others just used sum(1:10) directly. Both are valid ways to use the pipe, it’s just a matter of personal preference.\nThe output of the code letters %&gt;% head() %&gt;% toupper() is \"A\" \"B\" \"C\" \"D\" \"E\" \"F\". The letters vector contains the lowercase alphabet, and the head() function returns the first 6 elements of the vector. Finally, the toupper() function then converts these elements to uppercase.",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Working with data - Part 1</span>"
    ]
  },
  {
    "objectID": "chapter_2.html#sec-dataManip",
    "href": "chapter_2.html#sec-dataManip",
    "title": "2  Working with data - Part 1",
    "section": "2.2 Basic data manipulation",
    "text": "2.2 Basic data manipulation\nTo really see the power of the pipe, we will use it together with the dplyr package that provides a set of functions to easily filter, sort, select, modify and summarise data frames. These functions are designed to work well with the pipe, so you can chain them together to create complex data manipulations in a readable format.\nFor example, even though we haven’t covered the dplyr functions yet, you can probably guess what the following code does:\n\n# use the pipe to chain together our data manipulation steps\nm_dose %&gt;%\n  filter(cage_number == \"3E\") %&gt;%\n  drop_na(weight_lost_g) %&gt;% \n  pull(weight_lost_g) %&gt;%\n  mean()\n\nThis code filters the m_dose data frame to only include data from cage 3E, then pulls out the weight_lost_g column, and finally calculates the mean of the values in that column. The first argument to each function is the output of the previous function, and any additional arguments (like the column name in pull()) are specified in the brackets (like round(digits = 2) from the previous example).\nWe also used the enter key after each pipe %&gt;% to break up the code into multiple lines to make it easier to read. This isn’t required, but is a popular style in the R community, so all the code examples in this chapter will follow this format.\nWe will now introduce some of the most commonly used dplyr functions for manipulating data frames. To showcase these, we will use the m_dose that we practiced reading in last chapter. This imaginary dataset contains information on the weight lost by different strains of mice after being treated with different doses of MouseZempic®.\n\n# read in the data, like we did in chapter 1\nm_dose &lt;- read_delim(\"data/mousezempic_dosage_data.csv\")\n\n\n\nRows: 344 Columns: 9\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (4): mouse_strain, cage_number, replicate, sex\ndbl (5): weight_lost_g, drug_dose_g, tail_length_mm, initial_weight_g, id_num\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n\nBefore we start, let’s use what we learned in the previous chapter to take a look at m_dose:\n\n# it's a tibble, so prints nicely\nm_dose\n\n# A tibble: 344 × 9\n   mouse_strain cage_number weight_lost_g replicate sex    drug_dose_g\n   &lt;chr&gt;        &lt;chr&gt;               &lt;dbl&gt; &lt;chr&gt;     &lt;chr&gt;        &lt;dbl&gt;\n 1 CD-1         1A                   3.75 rep1      male       0.00181\n 2 CD-1         1A                   3.8  rep1      female     0.00186\n 3 CD-1         1A                   3.25 rep1      female     0.00195\n 4 CD-1         1A                  NA    rep1      &lt;NA&gt;      NA      \n 5 CD-1         1A                   3.45 rep1      female     0.00193\n 6 CD-1         1A                   3.65 rep1      male       0.0019 \n 7 CD-1         1A                   3.62 rep1      female     0.00181\n 8 CD-1         1A                   4.68 rep1      male       0.00195\n 9 CD-1         1A                   3.48 rep1      &lt;NA&gt;       0.00193\n10 CD-1         1A                   4.25 rep1      &lt;NA&gt;       0.0019 \n# ℹ 334 more rows\n# ℹ 3 more variables: tail_length_mm &lt;dbl&gt;, initial_weight_g &lt;dbl&gt;,\n#   id_num &lt;dbl&gt;\n\n\nYou might also like to use View() to open the data in a separate window and get a closer look.\n\n\n\n\n\n\nUsing RStudio autocomplete\n\n\n\nAlthough it’s great to give our data a descriptive name like m_dose, it can be a bit of a pain to type out every time. Luckily, RStudio has a handy autocomplete feature that can solve this problem. Just start typing the name of the object, and you’ll see it will popup:\n\n\n\nRStudio autocomplete\n\n\nYou can then press TabTab to autocomplete it. If there are multiple objects that start with the same letters, you can use the arrow keys to cycle through the options.\nTry using autocomplete in this chapter to save yourself some typing!\n\n\n\n2.2.1 Sorting data\nOften, one of the first things you might want to do with a dataset is sort it. In dplyr, this is called ‘arranging’ and is done with the arrange() function.\n\n\n\nArrange orders rows by their values in one or more columns\n\n\nBy default, arrange() sorts in ascending order (smallest values first). For example, let’s sort the m_dose data frame by the weight_lost_g column:\n\nm_dose %&gt;%\n  arrange(weight_lost_g)\n\n# A tibble: 344 × 9\n   mouse_strain cage_number weight_lost_g replicate sex    drug_dose_g\n   &lt;chr&gt;        &lt;chr&gt;               &lt;dbl&gt; &lt;chr&gt;     &lt;chr&gt;        &lt;dbl&gt;\n 1 BALB C       2B                   2.7  rep2      female     0.00192\n 2 CD-1         3E                   2.85 rep2      female     0.00181\n 3 CD-1         3E                   2.85 rep2      female     0.00184\n 4 CD-1         3E                   2.9  rep2      female     0.00187\n 5 CD-1         2B                   2.9  rep2      female     0.00178\n 6 CD-1         1A                   2.9  rep3      female     0.00188\n 7 BALB C       2B                   2.9  rep1      female     0.00187\n 8 CD-1         3E                   2.92 rep3      female     0.00193\n 9 CD-1         2B                   2.98 rep1      &lt;NA&gt;       0.00179\n10 CD-1         2B                   3    rep1      female     0.00185\n# ℹ 334 more rows\n# ℹ 3 more variables: tail_length_mm &lt;dbl&gt;, initial_weight_g &lt;dbl&gt;,\n#   id_num &lt;dbl&gt;\n\n\nIf we compare this to when we just printed our data above, we can see that the rows are now sorted so that the mice that lost the least weight are at the top.\nSometimes you might want to sort in descending order instead (largest values first). You can do this by putting the desc() function around your column name, inside arrange():\n\nm_dose %&gt;%\n  # put desc() around the column name to sort in descending order\n  arrange(desc(weight_lost_g))\n\n# A tibble: 344 × 9\n   mouse_strain cage_number weight_lost_g replicate sex   drug_dose_g\n   &lt;chr&gt;        &lt;chr&gt;               &lt;dbl&gt; &lt;chr&gt;     &lt;chr&gt;       &lt;dbl&gt;\n 1 Black 6      3E                   6.3  rep1      male      0.00221\n 2 Black 6      3E                   6.05 rep1      male      0.0023 \n 3 Black 6      3E                   6    rep2      male      0.0022 \n 4 Black 6      3E                   6    rep3      male      0.00222\n 5 Black 6      3E                   5.95 rep2      male      0.00223\n 6 Black 6      3E                   5.95 rep3      male      0.00229\n 7 Black 6      3E                   5.85 rep1      male      0.00213\n 8 Black 6      3E                   5.85 rep1      male      0.00217\n 9 Black 6      3E                   5.85 rep3      male      0.0023 \n10 Black 6      3E                   5.8  rep2      male      0.00229\n# ℹ 334 more rows\n# ℹ 3 more variables: tail_length_mm &lt;dbl&gt;, initial_weight_g &lt;dbl&gt;,\n#   id_num &lt;dbl&gt;\n\n\nNow we can see the mice that lost the most weight are at the top.\n\n\n\n\n\n\nComments and pipes\n\n\n\nNotice how in the previous example we have written a comment in the middle of the pipe chain. This is a good practice to help you remember what each step is doing, especially when you have a long chain of functions, and won’t cause any errors as long as you make sure that the comment is on its own line.\nYou can also write comments at the end of the line, just make sure it’s after the pipe operator %&gt;%.\nFor example, these comments are allowed:\n\nm_dose %&gt;% # a comment here is fine\n  # a comment here is fine\n  arrange(desc(weight_lost_g))\n\n# A tibble: 344 × 9\n   mouse_strain cage_number weight_lost_g replicate sex   drug_dose_g\n   &lt;chr&gt;        &lt;chr&gt;               &lt;dbl&gt; &lt;chr&gt;     &lt;chr&gt;       &lt;dbl&gt;\n 1 Black 6      3E                   6.3  rep1      male      0.00221\n 2 Black 6      3E                   6.05 rep1      male      0.0023 \n 3 Black 6      3E                   6    rep2      male      0.0022 \n 4 Black 6      3E                   6    rep3      male      0.00222\n 5 Black 6      3E                   5.95 rep2      male      0.00223\n 6 Black 6      3E                   5.95 rep3      male      0.00229\n 7 Black 6      3E                   5.85 rep1      male      0.00213\n 8 Black 6      3E                   5.85 rep1      male      0.00217\n 9 Black 6      3E                   5.85 rep3      male      0.0023 \n10 Black 6      3E                   5.8  rep2      male      0.00229\n# ℹ 334 more rows\n# ℹ 3 more variables: tail_length_mm &lt;dbl&gt;, initial_weight_g &lt;dbl&gt;,\n#   id_num &lt;dbl&gt;\n\n\nBut this will cause an error, because the # is before the pipe, so R treats it as part of the comment (notice how the %&gt;% has changed colour?) and doesn’t know how the two lines relate to each other. It tries to run them separately, which for the first line is ok (it will just print m_dose):\n\nm_dose # this comment will cause an error %&gt;%\n\n# A tibble: 344 × 9\n   mouse_strain cage_number weight_lost_g replicate sex    drug_dose_g\n   &lt;chr&gt;        &lt;chr&gt;               &lt;dbl&gt; &lt;chr&gt;     &lt;chr&gt;        &lt;dbl&gt;\n 1 CD-1         1A                   3.75 rep1      male       0.00181\n 2 CD-1         1A                   3.8  rep1      female     0.00186\n 3 CD-1         1A                   3.25 rep1      female     0.00195\n 4 CD-1         1A                  NA    rep1      &lt;NA&gt;      NA      \n 5 CD-1         1A                   3.45 rep1      female     0.00193\n 6 CD-1         1A                   3.65 rep1      male       0.0019 \n 7 CD-1         1A                   3.62 rep1      female     0.00181\n 8 CD-1         1A                   4.68 rep1      male       0.00195\n 9 CD-1         1A                   3.48 rep1      &lt;NA&gt;       0.00193\n10 CD-1         1A                   4.25 rep1      &lt;NA&gt;       0.0019 \n# ℹ 334 more rows\n# ℹ 3 more variables: tail_length_mm &lt;dbl&gt;, initial_weight_g &lt;dbl&gt;,\n#   id_num &lt;dbl&gt;\n\n  arrange(desc(weight_lost_g))\n\nError: object 'weight_lost_g' not found\n\n\nBut for the second line, there is an error that R doesn’t know what the weight_lost_g object is. That’s because it’s a column in the m_dose data frame, so R only knows what it is in the context of the pipe chain containing that data frame.\n\n\nYou can also sort by multiple columns by passing multiple column names to arrange(). For example, to sort by the strain first and then by the amount of weight lost:\n\n# sort by strain first, then by weight lost\nm_dose %&gt;%\n  arrange(mouse_strain, weight_lost_g)\n\n# A tibble: 344 × 9\n   mouse_strain cage_number weight_lost_g replicate sex    drug_dose_g\n   &lt;chr&gt;        &lt;chr&gt;               &lt;dbl&gt; &lt;chr&gt;     &lt;chr&gt;        &lt;dbl&gt;\n 1 BALB C       2B                   2.7  rep2      female     0.00192\n 2 BALB C       2B                   2.9  rep1      female     0.00187\n 3 BALB C       2B                   3.2  rep2      female     0.00187\n 4 BALB C       2B                   3.25 rep1      female     0.00178\n 5 BALB C       2B                   3.25 rep3      male       0.00187\n 6 BALB C       2B                   3.25 rep3      female     0.00191\n 7 BALB C       2B                   3.3  rep1      male       0.00197\n 8 BALB C       2B                   3.3  rep1      female     0.00195\n 9 BALB C       2B                   3.32 rep3      female     0.00199\n10 BALB C       2B                   3.35 rep2      female     0.00187\n# ℹ 334 more rows\n# ℹ 3 more variables: tail_length_mm &lt;dbl&gt;, initial_weight_g &lt;dbl&gt;,\n#   id_num &lt;dbl&gt;\n\n\nThis will sort the data frame by strain (according to alphabetical order, as it is a character column), and within each strain, they are then sorted by the amount of weight lost.\n\n\n\n\n\n\nPiping into View()\n\n\n\nIn the above example, we sorted the data by strain and then by weight lost, but because there are so many mice in each strain, the preview shown in our console doesn’t allow us to see the full effect of the sorting.\nOne handy trick you can use with pipes is to add View() at the end of your chain to open the data in a separate window. Try running this code, and you’ll be able to scroll through the full dataset to check that the other mouse strains have also been sorted correctly:\n\n# sort by strain first, then by weight lost\nm_dose %&gt;%\n  arrange(mouse_strain, weight_lost_g) %&gt;%\n  View()\n\nThis is a great way to check that your code has actually done what you intended!\n\n\n\n2.2.1.1 Extracting rows with the smallest or largest values\nSlice functions are used to select rows based on their position in the data frame. The slice_min() and slice_max() functions are particularly useful, because they allow you to select the rows with the smallest or largest values in a particular column.\nThis is equivalent to using arrange() followed by head(), but is more concise:\n\n# get the 10 mice with the lowest drug dose\nm_dose %&gt;%\n  # slice_min() requires the column to sort by, and n = the number of rows to keep\n  slice_min(drug_dose_g, n = 10)\n\n# A tibble: 13 × 9\n   mouse_strain cage_number weight_lost_g replicate sex    drug_dose_g\n   &lt;chr&gt;        &lt;chr&gt;               &lt;dbl&gt; &lt;chr&gt;     &lt;chr&gt;        &lt;dbl&gt;\n 1 CD-1         3E                   3.15 rep1      female     0.00172\n 2 CD-1         3E                   3.4  rep1      female     0.00174\n 3 CD-1         1A                   3.45 rep3      female     0.00176\n 4 CD-1         2B                   3.25 rep1      female     0.00178\n 5 CD-1         2B                   3.9  rep1      male       0.00178\n 6 CD-1         2B                   2.9  rep2      female     0.00178\n 7 BALB C       2B                   3.25 rep1      female     0.00178\n 8 CD-1         2B                   2.98 rep1      &lt;NA&gt;       0.00179\n 9 CD-1         1A                   3.7  rep1      &lt;NA&gt;       0.0018 \n10 CD-1         3E                   3.6  rep1      male       0.0018 \n11 CD-1         3E                   3.8  rep1      male       0.0018 \n12 CD-1         3E                   3.95 rep1      male       0.0018 \n13 CD-1         2B                   3.55 rep1      female     0.0018 \n# ℹ 3 more variables: tail_length_mm &lt;dbl&gt;, initial_weight_g &lt;dbl&gt;,\n#   id_num &lt;dbl&gt;\n\n# get the top 5 mice that lost the most weight\nm_dose %&gt;%\n  # slice_max() has the same arguments as slice_min()\n  slice_max(weight_lost_g, n = 5)\n\n# A tibble: 6 × 9\n  mouse_strain cage_number weight_lost_g replicate sex   drug_dose_g\n  &lt;chr&gt;        &lt;chr&gt;               &lt;dbl&gt; &lt;chr&gt;     &lt;chr&gt;       &lt;dbl&gt;\n1 Black 6      3E                   6.3  rep1      male      0.00221\n2 Black 6      3E                   6.05 rep1      male      0.0023 \n3 Black 6      3E                   6    rep2      male      0.0022 \n4 Black 6      3E                   6    rep3      male      0.00222\n5 Black 6      3E                   5.95 rep2      male      0.00223\n6 Black 6      3E                   5.95 rep3      male      0.00229\n# ℹ 3 more variables: tail_length_mm &lt;dbl&gt;, initial_weight_g &lt;dbl&gt;,\n#   id_num &lt;dbl&gt;\n\n\nBut wait— neither of those pieces of code actually gave the number of rows we asked for! In the first example, we asked for the 10 mice with the lowest drug dose, but we got 13. And in the second example, we asked for the top 5 mice that lost the most weight, but we got 6. Why aren’t the slice_ functions behaving as expected?\nIf we take a look at the help page (type ?slice_min in the console), we learn that slice_min() and slice_max() have an argument called with_ties that is set to TRUE by default. If we want to make sure we only get the number of rows we asked for, we would have to set it to FALSE, like so:\n\n# get the top 5 mice that lost the most weight\nm_dose %&gt;%\n  # no ties allowed!\n  slice_max(weight_lost_g, n = 5, with_ties = FALSE)\n\n# A tibble: 5 × 9\n  mouse_strain cage_number weight_lost_g replicate sex   drug_dose_g\n  &lt;chr&gt;        &lt;chr&gt;               &lt;dbl&gt; &lt;chr&gt;     &lt;chr&gt;       &lt;dbl&gt;\n1 Black 6      3E                   6.3  rep1      male      0.00221\n2 Black 6      3E                   6.05 rep1      male      0.0023 \n3 Black 6      3E                   6    rep2      male      0.0022 \n4 Black 6      3E                   6    rep3      male      0.00222\n5 Black 6      3E                   5.95 rep2      male      0.00223\n# ℹ 3 more variables: tail_length_mm &lt;dbl&gt;, initial_weight_g &lt;dbl&gt;,\n#   id_num &lt;dbl&gt;\n\n\nThis is an important lesson: sometimes functions will behave in a way that is unexpected, and you might need to read their help page or use other guides/google/AI to understand why.\n\n\n\n\n\n\nPractice exercises\n\n\n\nTry these practice questions to test your understanding\n\n1. Which code would you use to sort the m_dose data frame from biggest to smallest initial weight?\n\n\n\n\n ✗m_dose %&gt;% sort(initial_weight_g)\n\n\n ✗m_dose %&gt;% arrange(initial_weight_g)\n\n\n ✗m_dose %&gt;% sort(descending(initial_weight_g))\n\n\n ✔m_dose %&gt;% arrange(desc(initial_weight_g))\n\n\n\n\n\n\n2. Which code would you use to extract the 3 mice with the highest initial weight from the m_dose data frame?\n\n\n\n\n ✔m_dose %&gt;% slice_max(initial_weight_g, n = 3)\n\n\n ✗m_dose %&gt;% arrange(desc(initial_weight_g))\n\n\n ✗m_dose %&gt;% slice_min(initial_weight_g, n = 3)\n\n\n ✗m_dose %&gt;% arrange(initial_weight_g)\n\n\n\n\n\n\n3. I’ve written the below code, but one of the comments is messing it up! Which one?\n\n# comment A\nm_dose # comment B %&gt;%\n  # comment C\n  slice_max(weight_lost_g, n = 5, with_ties = FALSE) # comment D\n\n\n\n\n\n ✗Comment A\n\n\n ✔Comment B\n\n\n ✗Comment C\n\n\n ✗Comment D\n\n\n\n\n\n\n\nSolutions\n\n\nThe correct code to sort the m_dose data frame from biggest to smallest initial weight is m_dose %&gt;% arrange(desc(initial_weight_g)). The arrange() function is used to sort the data frame (although there is a sort() function in R, that’s not part of dplyr and won’t work the same way), and the desc() function is used to sort in descending order.\nThe correct code to extract the 3 mice with the highest initial weight from the m_dose data frame is m_dose %&gt;% slice_max(initial_weight_g, n = 3). The slice_max() function is used to select the rows with the largest values in the initial_weight_g column, and the n = 3 argument specifies that we want to keep 3 rows. The arrange() function is not needed in this case, because slice_max() will automatically sort the data frame by the specified column.\nThe comment that is messing up the code is Comment B. The # symbol is before the pipe operator %&gt;%, so R treats it as part of the comment and this breaks our chain of pipes. The other comments are fine, because they are either at the end of the line or on their own line. Basically, if a comment is changing the colour of the pipe operator (or any other bits of your code), it’s in the wrong place!\n\n\n\n\n\n\n\n2.2.2 Filtering data (rows)\n\n\n\nFilter allows you to filter rows using a logical test\n\n\nIn dplyr, the filter() function is used to subset rows based on their values. You provide a logical test, and filter() will keep the rows where the test is TRUE. We can write these tests using the comparison operators we learned in the previous chapter (e.g. ==, &lt; and !=, see Section 1.3).\nFor example, to filter the m_dose data frame to only include mice that lost more than 6g:\n\nm_dose %&gt;%\n  filter(weight_lost_g &gt; 6)\n\n# A tibble: 2 × 9\n  mouse_strain cage_number weight_lost_g replicate sex   drug_dose_g\n  &lt;chr&gt;        &lt;chr&gt;               &lt;dbl&gt; &lt;chr&gt;     &lt;chr&gt;       &lt;dbl&gt;\n1 Black 6      3E                   6.3  rep1      male      0.00221\n2 Black 6      3E                   6.05 rep1      male      0.0023 \n# ℹ 3 more variables: tail_length_mm &lt;dbl&gt;, initial_weight_g &lt;dbl&gt;,\n#   id_num &lt;dbl&gt;\n\n\nOr to only include mice from cage 3E:\n\nm_dose %&gt;%\n  # remember that == is used for testing equality\n  filter(cage_number == \"3E\") # don't forget the quotes either!\n\n# A tibble: 168 × 9\n   mouse_strain cage_number weight_lost_g replicate sex    drug_dose_g\n   &lt;chr&gt;        &lt;chr&gt;               &lt;dbl&gt; &lt;chr&gt;     &lt;chr&gt;        &lt;dbl&gt;\n 1 CD-1         3E                   3.4  rep1      female     0.00174\n 2 CD-1         3E                   3.6  rep1      male       0.0018 \n 3 CD-1         3E                   3.8  rep1      female     0.00189\n 4 CD-1         3E                   3.95 rep1      male       0.00185\n 5 CD-1         3E                   3.8  rep1      male       0.0018 \n 6 CD-1         3E                   3.8  rep1      female     0.00187\n 7 CD-1         3E                   3.55 rep1      male       0.00183\n 8 CD-1         3E                   3.2  rep1      female     0.00187\n 9 CD-1         3E                   3.15 rep1      female     0.00172\n10 CD-1         3E                   3.95 rep1      male       0.0018 \n# ℹ 158 more rows\n# ℹ 3 more variables: tail_length_mm &lt;dbl&gt;, initial_weight_g &lt;dbl&gt;,\n#   id_num &lt;dbl&gt;\n\n\n\n2.2.2.1 Combining logical tests\nSometimes we want to filter based on multiple conditions. Here we will show some more advanced operators that can be used to combine logical tests.\nThe & operator is used to combine two logical tests with an ‘and’ condition. For example, to filter the data frame to only include mice that have a tail length greater than 19mm and are female:\n\nm_dose %&gt;%\n  filter(tail_length_mm &gt; 19 & sex == \"female\")\n\n# A tibble: 5 × 9\n  mouse_strain cage_number weight_lost_g replicate sex    drug_dose_g\n  &lt;chr&gt;        &lt;chr&gt;               &lt;dbl&gt; &lt;chr&gt;     &lt;chr&gt;        &lt;dbl&gt;\n1 CD-1         1A                   3.45 rep1      female     0.00193\n2 CD-1         3E                   3.8  rep1      female     0.00189\n3 CD-1         2B                   3.3  rep1      female     0.00181\n4 CD-1         3E                   3.9  rep3      female     0.00191\n5 BALB C       2B                   3.52 rep3      female     0.00194\n# ℹ 3 more variables: tail_length_mm &lt;dbl&gt;, initial_weight_g &lt;dbl&gt;,\n#   id_num &lt;dbl&gt;\n\n\nThe | operator is used to combine two logical tests with an ‘or’ condition. For example, to filter the data frame to only include mice that have an initial weight less than 35g or a tail length less than 14mm:\n\nm_dose %&gt;%\n  filter(initial_weight_g &lt; 35 | tail_length_mm &lt; 14)\n\n# A tibble: 30 × 9\n   mouse_strain cage_number weight_lost_g replicate sex    drug_dose_g\n   &lt;chr&gt;        &lt;chr&gt;               &lt;dbl&gt; &lt;chr&gt;     &lt;chr&gt;        &lt;dbl&gt;\n 1 CD-1         1A                   3.48 rep1      &lt;NA&gt;       0.00193\n 2 CD-1         1A                   4.4  rep1      male       0.00198\n 3 CD-1         1A                   3.32 rep1      female     0.00184\n 4 CD-1         3E                   2.9  rep2      female     0.00187\n 5 CD-1         1A                   3.6  rep2      female     0.0019 \n 6 CD-1         1A                   3.2  rep2      female     0.00189\n 7 CD-1         2B                   3.4  rep2      female     0.00185\n 8 CD-1         2B                   2.9  rep2      female     0.00178\n 9 CD-1         2B                   3.05 rep3      female     0.00188\n10 Black 6      3E                   4.5  rep1      female     0.00211\n# ℹ 20 more rows\n# ℹ 3 more variables: tail_length_mm &lt;dbl&gt;, initial_weight_g &lt;dbl&gt;,\n#   id_num &lt;dbl&gt;\n\n\nThe %in% operator can be used to filter based on a vector of multiple values (c(x, y)). It’s particularly useful when you have a few character values you want to filter on, as it is shorter to type than | (or).\nFor example, to filter the data frame to only include mice from cages 3E or 1A, we could use | like this:\n\nm_dose %&gt;%\n  filter(cage_number == \"3E\" | cage_number == \"1A\")\n\n# A tibble: 220 × 9\n   mouse_strain cage_number weight_lost_g replicate sex    drug_dose_g\n   &lt;chr&gt;        &lt;chr&gt;               &lt;dbl&gt; &lt;chr&gt;     &lt;chr&gt;        &lt;dbl&gt;\n 1 CD-1         1A                   3.75 rep1      male       0.00181\n 2 CD-1         1A                   3.8  rep1      female     0.00186\n 3 CD-1         1A                   3.25 rep1      female     0.00195\n 4 CD-1         1A                  NA    rep1      &lt;NA&gt;      NA      \n 5 CD-1         1A                   3.45 rep1      female     0.00193\n 6 CD-1         1A                   3.65 rep1      male       0.0019 \n 7 CD-1         1A                   3.62 rep1      female     0.00181\n 8 CD-1         1A                   4.68 rep1      male       0.00195\n 9 CD-1         1A                   3.48 rep1      &lt;NA&gt;       0.00193\n10 CD-1         1A                   4.25 rep1      &lt;NA&gt;       0.0019 \n# ℹ 210 more rows\n# ℹ 3 more variables: tail_length_mm &lt;dbl&gt;, initial_weight_g &lt;dbl&gt;,\n#   id_num &lt;dbl&gt;\n\n\nOr we could use %in% like this:\n\nm_dose %&gt;%\n  filter(cage_number %in% c(\"3E\", \"1A\"))\n\n# A tibble: 220 × 9\n   mouse_strain cage_number weight_lost_g replicate sex    drug_dose_g\n   &lt;chr&gt;        &lt;chr&gt;               &lt;dbl&gt; &lt;chr&gt;     &lt;chr&gt;        &lt;dbl&gt;\n 1 CD-1         1A                   3.75 rep1      male       0.00181\n 2 CD-1         1A                   3.8  rep1      female     0.00186\n 3 CD-1         1A                   3.25 rep1      female     0.00195\n 4 CD-1         1A                  NA    rep1      &lt;NA&gt;      NA      \n 5 CD-1         1A                   3.45 rep1      female     0.00193\n 6 CD-1         1A                   3.65 rep1      male       0.0019 \n 7 CD-1         1A                   3.62 rep1      female     0.00181\n 8 CD-1         1A                   4.68 rep1      male       0.00195\n 9 CD-1         1A                   3.48 rep1      &lt;NA&gt;       0.00193\n10 CD-1         1A                   4.25 rep1      &lt;NA&gt;       0.0019 \n# ℹ 210 more rows\n# ℹ 3 more variables: tail_length_mm &lt;dbl&gt;, initial_weight_g &lt;dbl&gt;,\n#   id_num &lt;dbl&gt;\n\n\n\n\n\n\n\n\nPractice exercises\n\n\n\nTry these practice questions to test your understanding\n\n1. Which code would you use to filter the m_dose data frame to only include mice from replicate 2?\n\n\n\n\n ✗m_dose %&gt;% filter(replicate == 2)\n\n\n ✗m_dose %&gt;% filter(replicate == rep2)\n\n\n ✔m_dose %&gt;% filter(replicate == \"rep2\")\n\n\n ✗m_dose %&gt;% filter(replicate = \"rep2\")\n\n\n\n\n\n\n2. What is NOT a valid way to filter the m_dose data frame to only include mice that lost more than 4g, and have an initial weight less than 40g?\n\n\n\n\n ✗m_dose %&gt;% filter(weight_lost_g &gt; 4) %&gt;% filter(initial_weight_g &lt; 40)\n\n\n ✔m_dose %&gt;% filter(weight_lost_g &gt; 4) %&gt;% (initial_weight_g &lt; 40)\n\n\n ✗m_dose %&gt;% filter(weight_lost_g &gt; 4 & initial_weight_g &lt; 40)\n\n\n ✗m_dose %&gt;% filter(initial_weight_g &lt; 40) %&gt;% filter(weight_lost_g &gt; 4)\n\n\n\n\n\n\n3. Which option correctly describes what the following code is doing?\n\nm_dose %&gt;%\n  filter(mouse_strain %in% c(\"BALB C\", \"Black 6\")) %&gt;%\n  filter(weight_lost_g &gt; 3 & weight_lost_g &lt; 5) %&gt;%\n  arrange(desc(drug_dose_g))\n\n\n\n\n\n ✗Filters the data frame to remove mice from the “BALB C” and “Black 6” strains, who only lost between 3 and 5g of weight, and then sorts the data frame by drug dose.\n\n\n ✗Filters the data frame to remove mice from the “BALB C” and “Black 6” strains, that lost between 3 and 5g of weight, and then sorts the data frame by drug dose in descending order.\n\n\n ✗Filters the data frame to only include mice from the “BALB C” and “Black 6” strains, that lost between 3 and 5g of weight, and then sorts the data frame by drug dose.\n\n\n ✔Filters the data frame to only include mice from the “BALB C” and “Black 6” strains, that lost between 3 and 5g of weight, and then sorts the data frame by drug dose in descending order.\n\n\n\n\n\n\n\nSolutions\n\n\nThe correct code to filter the m_dose data frame to only include mice from replicate 2 is m_dose %&gt;% filter(replicate == \"rep2\"). Option A is incorrect because 2 is not a value of replicate (when filtering you need to know what values are actually in your columns! So make sure to View() your data first). Option B is incorrect because the replicate column is a character column, so you need to use quotes around the value you are filtering on. Option D is incorrect because = is not the correct way to test for equality, you need to use ==.\nThe invalid option is m_dose %&gt;% filter(weight_lost_g &gt; 4) %&gt;% (initial_weight_g &lt; 40). This is because the second filtering step is missing the name of the filter function, so R doesn’t know what to do with (initial_weight_g &lt; 40). The other options are valid ways to filter the data frame based on the specified conditions; note that we can use multiple filter() functions in a row to apply multiple conditions, or the & operator to combine them into a single filter() function. It’s just a matter of personal preference.\nThe correct description of the code is that it filters the data frame to only include mice from the “BALB C” and “Black 6” strains, then filters those further to only those that lost between 3 and 5g of weight, and finally sorts the data frame by drug dose in descending order.\n\n\n\n\n\n\n\n2.2.3 Dealing with missing values\nMissing values are a common problem in real-world datasets. In R, missing values are represented by NA. In fact, if you look at the m_dose data frame we’ve been using, you’ll see that some of the cells contain NA: try spotting them with the View() function.\nYou can also find missing values in a data frame using the is.na() function in combination with filter(). For example, to find all the rows in the m_dose data frame that have a missing value for the drug_dose_g column:\n\nm_dose %&gt;%\n  filter(is.na(drug_dose_g))\n\n# A tibble: 2 × 9\n  mouse_strain cage_number weight_lost_g replicate sex   drug_dose_g\n  &lt;chr&gt;        &lt;chr&gt;               &lt;dbl&gt; &lt;chr&gt;     &lt;chr&gt;       &lt;dbl&gt;\n1 CD-1         1A                     NA rep1      &lt;NA&gt;           NA\n2 Black 6      3E                     NA rep3      &lt;NA&gt;           NA\n# ℹ 3 more variables: tail_length_mm &lt;dbl&gt;, initial_weight_g &lt;dbl&gt;,\n#   id_num &lt;dbl&gt;\n\n\nThe problem with missing values is that they can cause problems when you try to perform calculations on your data. For example, if you try to calculate the mean of a column that contains even a single missing value, the result will also be NA:\n\n# try to calculate the mean of the drug_dose_g column\n# remember from chapter 1 that we can use $ to access columns in a data frame\nm_dose$drug_dose_g %&gt;% mean()\n\n[1] NA\n\n\nNA values in R are therefore referred to as ‘contagious’: if you put an NA in you usually get an NA out. If you think about it, that makes sense— when we don’t know the value of a particular mouse’s drug dose, how can we calculate the average? That missing value could be anything.\nFor this reason, it’s important to deal with missing values before performing calculations. Many functions in R will have an argument called na.rm that you can set to TRUE to remove missing values before performing the calculation. For example, to calculate the mean of the drug_dose_g column with the missing values excluded:\n\n# try to calculate the mean of the drug_dose_g column\n# remember from chapter 1 that we can use $ to access columns in a data frame\nm_dose$drug_dose_g %&gt;% mean(na.rm = TRUE)\n\n[1] 0.002009152\n\n\nThis time, the result is a number, because the missing values have been removed before the calculation.\nBut not all functions have an na.rm argument. In these cases, you can remove rows with missing values. This can be done for a single column, using the filter() function together with is.na():\n\n# remove rows with missing values in the drug_dose_g column\nm_dose %&gt;%\n  # remember the ! means 'not', it negates the result of is.na()\n  filter(!is.na(drug_dose_g))\n\n# A tibble: 342 × 9\n   mouse_strain cage_number weight_lost_g replicate sex    drug_dose_g\n   &lt;chr&gt;        &lt;chr&gt;               &lt;dbl&gt; &lt;chr&gt;     &lt;chr&gt;        &lt;dbl&gt;\n 1 CD-1         1A                   3.75 rep1      male       0.00181\n 2 CD-1         1A                   3.8  rep1      female     0.00186\n 3 CD-1         1A                   3.25 rep1      female     0.00195\n 4 CD-1         1A                   3.45 rep1      female     0.00193\n 5 CD-1         1A                   3.65 rep1      male       0.0019 \n 6 CD-1         1A                   3.62 rep1      female     0.00181\n 7 CD-1         1A                   4.68 rep1      male       0.00195\n 8 CD-1         1A                   3.48 rep1      &lt;NA&gt;       0.00193\n 9 CD-1         1A                   4.25 rep1      &lt;NA&gt;       0.0019 \n10 CD-1         1A                   3.3  rep1      &lt;NA&gt;       0.00186\n# ℹ 332 more rows\n# ℹ 3 more variables: tail_length_mm &lt;dbl&gt;, initial_weight_g &lt;dbl&gt;,\n#   id_num &lt;dbl&gt;\n\n\nOr, you can remove rows with missing values in any column using the na.omit() or drop_na() function:\n\n# remove rows with missing values in any column\nm_dose %&gt;%\n  na.omit()\n\n# A tibble: 333 × 9\n   mouse_strain cage_number weight_lost_g replicate sex    drug_dose_g\n   &lt;chr&gt;        &lt;chr&gt;               &lt;dbl&gt; &lt;chr&gt;     &lt;chr&gt;        &lt;dbl&gt;\n 1 CD-1         1A                   3.75 rep1      male       0.00181\n 2 CD-1         1A                   3.8  rep1      female     0.00186\n 3 CD-1         1A                   3.25 rep1      female     0.00195\n 4 CD-1         1A                   3.45 rep1      female     0.00193\n 5 CD-1         1A                   3.65 rep1      male       0.0019 \n 6 CD-1         1A                   3.62 rep1      female     0.00181\n 7 CD-1         1A                   4.68 rep1      male       0.00195\n 8 CD-1         1A                   3.2  rep1      female     0.00182\n 9 CD-1         1A                   3.8  rep1      male       0.00191\n10 CD-1         1A                   4.4  rep1      male       0.00198\n# ℹ 323 more rows\n# ℹ 3 more variables: tail_length_mm &lt;dbl&gt;, initial_weight_g &lt;dbl&gt;,\n#   id_num &lt;dbl&gt;\n\nm_dose %&gt;%\n  drop_na()\n\n# A tibble: 333 × 9\n   mouse_strain cage_number weight_lost_g replicate sex    drug_dose_g\n   &lt;chr&gt;        &lt;chr&gt;               &lt;dbl&gt; &lt;chr&gt;     &lt;chr&gt;        &lt;dbl&gt;\n 1 CD-1         1A                   3.75 rep1      male       0.00181\n 2 CD-1         1A                   3.8  rep1      female     0.00186\n 3 CD-1         1A                   3.25 rep1      female     0.00195\n 4 CD-1         1A                   3.45 rep1      female     0.00193\n 5 CD-1         1A                   3.65 rep1      male       0.0019 \n 6 CD-1         1A                   3.62 rep1      female     0.00181\n 7 CD-1         1A                   4.68 rep1      male       0.00195\n 8 CD-1         1A                   3.2  rep1      female     0.00182\n 9 CD-1         1A                   3.8  rep1      male       0.00191\n10 CD-1         1A                   4.4  rep1      male       0.00198\n# ℹ 323 more rows\n# ℹ 3 more variables: tail_length_mm &lt;dbl&gt;, initial_weight_g &lt;dbl&gt;,\n#   id_num &lt;dbl&gt;\n\n\nSometimes, instead of removing rows with missing values, you might want to replace them with a specific value. This can be done using the replace_na() function from the tidyr package. replace_na() takes a list() which contains each of the column names you want to edit, and the value that should be used.\nFor example, to replace missing values in the weight_lost_g columns with 0, replace missing values in the sex column with ‘unknown’ and leave the rest of the data frame unchanged:\n\n# replace missing values in the drug_dose_g column with 0\nm_dose %&gt;%\n  # here we need to provide the column_names = values_to_replace\n  # this needs to be contained within a list()\n  replace_na(list(weight_lost_g = 0, sex = \"unknown\"))\n\n# A tibble: 344 × 9\n   mouse_strain cage_number weight_lost_g replicate sex     drug_dose_g\n   &lt;chr&gt;        &lt;chr&gt;               &lt;dbl&gt; &lt;chr&gt;     &lt;chr&gt;         &lt;dbl&gt;\n 1 CD-1         1A                   3.75 rep1      male        0.00181\n 2 CD-1         1A                   3.8  rep1      female      0.00186\n 3 CD-1         1A                   3.25 rep1      female      0.00195\n 4 CD-1         1A                   0    rep1      unknown    NA      \n 5 CD-1         1A                   3.45 rep1      female      0.00193\n 6 CD-1         1A                   3.65 rep1      male        0.0019 \n 7 CD-1         1A                   3.62 rep1      female      0.00181\n 8 CD-1         1A                   4.68 rep1      male        0.00195\n 9 CD-1         1A                   3.48 rep1      unknown     0.00193\n10 CD-1         1A                   4.25 rep1      unknown     0.0019 \n# ℹ 334 more rows\n# ℹ 3 more variables: tail_length_mm &lt;dbl&gt;, initial_weight_g &lt;dbl&gt;,\n#   id_num &lt;dbl&gt;\n\n\nWhen deciding how to handle missing values, you might have prior knowledge that NA should be replaced with a specific value, or you might decide that removing rows with NA is the best approach for your analysis.\nFor example, maybe we knew that the mice were given a weight_lost_g of NA if they didn’t lose any weight, it would then make sense to replace those with 0 (as we did in the code above). However, if the drug_dose_g column was missing simply because the data was lost, we might choose to remove those rows entirely.\nIt’s important to think carefully about how missing values should be handled in your analysis.\n\n\n\n\n\n\nPractice exercises\n\n\n\nTry these practice questions to test your understanding\n\n1. What would be the result of running this R code: mean(c(1, 2, 4, NA))\n\n\n\n\n ✗2.333333\n\n\n ✗0\n\n\n ✔NA\n\n\n ✗An error\n\n\n\n\n\n\n2. Which line of code would you use to filter the m_dose data frame to remove mice that have a missing value in the tail_length_mm column?\n\n\n\n\n ✗m_dose %&gt;% filter(tail_length_mm != NA)\n\n\n ✗m_dose %&gt;% filter(is.na(tail_length_mm))\n\n\n ✗m_dose %&gt;% na.omit()\n\n\n ✔m_dose %&gt;% filter(!is.na(tail_length_mm))\n\n\n\n\n\n\n3. How would you replace missing values in the initial_weight_g column with the value 35?\n\n\n\n\n ✔m_dose %&gt;% replace_na(list(initial_weight_g = 35))\n\n\n ✗m_dose %&gt;% replace_na(initial_weight_g = 35)\n\n\n ✗m_dose %&gt;% replace_na(list(initial_weight_g == 35))\n\n\n ✗m_dose %&gt;% replace_na(35)\n\n\n\n\n\n\n\nSolutions\n\n\n\nThe result of running the code mean(c(1, 2, 4, NA)) is NA. This is because the NA value is ‘contagious’, so when you try to calculate the mean of a vector that contains an NA, the result will also be NA. If we wanted to calculate the mean of the vector without the NA, we would need to use the na.rm = TRUE argument.\nThe correct line of code to filter the m_dose data frame to remove mice that have a missing value in the tail_length_mm column is m_dose %&gt;% filter(!is.na(tail_length_mm)). The ! symbol is used to negate the result of is.na(), so we are filtering to keep the rows where tail_length_mm is not NA. We can’t use the first option with the != NA because NA is a special value in R that represents missing data, and it can’t be compared to anything, and the third option is incorrect because na.omit() removes entire rows with missing values, rather than just filtering based on a single column.\nThe correct line of code to replace missing values in the initial_weight_g column with the value 35 is m_dose %&gt;% replace_na(list(initial_weight_g = 35)). The replace_na() function takes a list() that contains the column names you want to replace and the values you want to replace them with. We only need to use a single equal sign here as we’re not testing for equality, we’re assigning a value.\n\n\n\n\n\n\n\n2.2.4 Selecting columns\n\n\n\nSelect allows you to select only certain columns\n\n\nWhile filter() is used to subset rows, select() is used to subset columns. You can use select() to keep only the columns you’re interested in, or to drop columns you don’t need.\nThe select() function takes the names of the columns that you want to keep/remove (no vector notation c() or quotation marks \"\" necessary). For example, to select only the mouse_strain, initial_weight_g, and weight_lost_g columns from the m_dose data frame:\n\nm_dose %&gt;%\n  select(mouse_strain, initial_weight_g, weight_lost_g)\n\n# A tibble: 344 × 3\n   mouse_strain initial_weight_g weight_lost_g\n   &lt;chr&gt;                   &lt;dbl&gt;         &lt;dbl&gt;\n 1 CD-1                     39.1          3.75\n 2 CD-1                     39.5          3.8 \n 3 CD-1                     40.3          3.25\n 4 CD-1                     NA           NA   \n 5 CD-1                     36.7          3.45\n 6 CD-1                     39.3          3.65\n 7 CD-1                     38.9          3.62\n 8 CD-1                     39.2          4.68\n 9 CD-1                     34.1          3.48\n10 CD-1                     42            4.25\n# ℹ 334 more rows\n\n\nWe can see that all the other columns have been removed from the data frame.\nIf you want to keep all columns except for a few, you can use - to drop columns. For example, to keep all columns except for cage_number and sex:\n\nm_dose %&gt;%\n  select(-cage_number, -sex)\n\n# A tibble: 344 × 7\n   mouse_strain weight_lost_g replicate drug_dose_g tail_length_mm\n   &lt;chr&gt;                &lt;dbl&gt; &lt;chr&gt;           &lt;dbl&gt;          &lt;dbl&gt;\n 1 CD-1                  3.75 rep1          0.00181           18.7\n 2 CD-1                  3.8  rep1          0.00186           17.4\n 3 CD-1                  3.25 rep1          0.00195           18  \n 4 CD-1                 NA    rep1         NA                 NA  \n 5 CD-1                  3.45 rep1          0.00193           19.3\n 6 CD-1                  3.65 rep1          0.0019            20.6\n 7 CD-1                  3.62 rep1          0.00181           17.8\n 8 CD-1                  4.68 rep1          0.00195           19.6\n 9 CD-1                  3.48 rep1          0.00193           18.1\n10 CD-1                  4.25 rep1          0.0019            20.2\n# ℹ 334 more rows\n# ℹ 2 more variables: initial_weight_g &lt;dbl&gt;, id_num &lt;dbl&gt;\n\n\nThere are also some helper functions that can be used to select columns based on their names :\n\nThere are several helper functions that can be used with the select function\n\n\n\n\n\n\n\nFunction\nDescription\nExample\n\n\n\n\nstarts_with()\nselect column(s) that start with a certain string\nselect all columns starting with the letter i\nselect(starts_with(\"i\"))\n\n\nends_with()\nselect column(s) that end with a certain string\nselect all columns ending with _g\nselect(ends_with(\"_g\"))\n\n\ncontains()\nselect column(s) that contain a certain string\nselect all columns containing the word ‘weight’\nselect(contains(\"weight\"))\n\n\n\nYou need to use quotation marks around the arguments in these helper functions, as they aren’t full column names, just strings of characters.\nTry using these helper functions to select columns from the m_dose data frame!\n\n\n\n\n\n\nReordering columns\n\n\n\n\n\n\nRelocate allows you to move columns around\n\n\nWe can reorder columns using the relocate() function, which works similarly to select() (except it just moves columns around rather than dropping/keeping them). For example, to move the sex column to before the cage_number column:\n\nm_dose %&gt;%\n  # first the name of the column to move, then where it should go\n  relocate(sex, .before = cage_number)\n\n# A tibble: 344 × 9\n   mouse_strain sex    cage_number weight_lost_g replicate drug_dose_g\n   &lt;chr&gt;        &lt;chr&gt;  &lt;chr&gt;               &lt;dbl&gt; &lt;chr&gt;           &lt;dbl&gt;\n 1 CD-1         male   1A                   3.75 rep1          0.00181\n 2 CD-1         female 1A                   3.8  rep1          0.00186\n 3 CD-1         female 1A                   3.25 rep1          0.00195\n 4 CD-1         &lt;NA&gt;   1A                  NA    rep1         NA      \n 5 CD-1         female 1A                   3.45 rep1          0.00193\n 6 CD-1         male   1A                   3.65 rep1          0.0019 \n 7 CD-1         female 1A                   3.62 rep1          0.00181\n 8 CD-1         male   1A                   4.68 rep1          0.00195\n 9 CD-1         &lt;NA&gt;   1A                   3.48 rep1          0.00193\n10 CD-1         &lt;NA&gt;   1A                   4.25 rep1          0.0019 \n# ℹ 334 more rows\n# ℹ 3 more variables: tail_length_mm &lt;dbl&gt;, initial_weight_g &lt;dbl&gt;,\n#   id_num &lt;dbl&gt;\n\n\nWithout a specific position ( .before / .after), this function will place the chosen column(s) as the first / left-most columns.\nTwo further useful helper functions for relocate() are the everything() and last_col() functions, which can be used to move columns to the start/end of the data frame.\n\n# move id_num to the front\nm_dose %&gt;%\n  relocate(id_num, .before = everything()) # don't forget the brackets\n\n# A tibble: 344 × 9\n   id_num mouse_strain cage_number weight_lost_g replicate sex    drug_dose_g\n    &lt;dbl&gt; &lt;chr&gt;        &lt;chr&gt;               &lt;dbl&gt; &lt;chr&gt;     &lt;chr&gt;        &lt;dbl&gt;\n 1      1 CD-1         1A                   3.75 rep1      male       0.00181\n 2      2 CD-1         1A                   3.8  rep1      female     0.00186\n 3      3 CD-1         1A                   3.25 rep1      female     0.00195\n 4      4 CD-1         1A                  NA    rep1      &lt;NA&gt;      NA      \n 5      5 CD-1         1A                   3.45 rep1      female     0.00193\n 6      6 CD-1         1A                   3.65 rep1      male       0.0019 \n 7      7 CD-1         1A                   3.62 rep1      female     0.00181\n 8      8 CD-1         1A                   4.68 rep1      male       0.00195\n 9      9 CD-1         1A                   3.48 rep1      &lt;NA&gt;       0.00193\n10     10 CD-1         1A                   4.25 rep1      &lt;NA&gt;       0.0019 \n# ℹ 334 more rows\n# ℹ 2 more variables: tail_length_mm &lt;dbl&gt;, initial_weight_g &lt;dbl&gt;\n\n# move mouse_strain to the end\nm_dose %&gt;%\n  relocate(mouse_strain, .after = last_col())\n\n# A tibble: 344 × 9\n   cage_number weight_lost_g replicate sex    drug_dose_g tail_length_mm\n   &lt;chr&gt;               &lt;dbl&gt; &lt;chr&gt;     &lt;chr&gt;        &lt;dbl&gt;          &lt;dbl&gt;\n 1 1A                   3.75 rep1      male       0.00181           18.7\n 2 1A                   3.8  rep1      female     0.00186           17.4\n 3 1A                   3.25 rep1      female     0.00195           18  \n 4 1A                  NA    rep1      &lt;NA&gt;      NA                 NA  \n 5 1A                   3.45 rep1      female     0.00193           19.3\n 6 1A                   3.65 rep1      male       0.0019            20.6\n 7 1A                   3.62 rep1      female     0.00181           17.8\n 8 1A                   4.68 rep1      male       0.00195           19.6\n 9 1A                   3.48 rep1      &lt;NA&gt;       0.00193           18.1\n10 1A                   4.25 rep1      &lt;NA&gt;       0.0019            20.2\n# ℹ 334 more rows\n# ℹ 3 more variables: initial_weight_g &lt;dbl&gt;, id_num &lt;dbl&gt;, mouse_strain &lt;chr&gt;\n\n\nRe-ordering columns isn’t necessary, but it makes it easier to see the data you’re most interested in within the console (since often not all of the columns will fit on the screen at once). For example, if we are doing a lot of computation on the initial_weight_g column, we’d probably like to have that near the start so we can easily check it.\n\n\nNote that the output of the select() function is a new data frame, even if you only select a single column:\n\n# select the mouse_strain column\nm_dose %&gt;%\n  select(mouse_strain) %&gt;%\n  # recall from chapter 1 that class() tells us the type of an object\n  class()\n\n[1] \"tbl_df\"     \"tbl\"        \"data.frame\"\n\n\nSometimes, we instead want to get the values of a column as a vector.\n\n\n\nPull allows you to pull a column out of a data frame as a vector\n\n\nWe can do this by using the pull() function, which extracts a single column from a data frame as a vector:\n\n# get the mouse_strain column as a vector\nm_dose %&gt;%\n  pull(mouse_strain) %&gt;%\n  class()\n\n[1] \"character\"\n\n\nWe can see that the class of the output is now a vector, rather than a data frame. This is important because some functions only accept vectors, not data frames, like mean() for example:\n\n# this will give an error\nm_dose %&gt;% select(initial_weight_g) %&gt;% mean(na.rm = TRUE)\n\nWarning in mean.default(., na.rm = TRUE): argument is not numeric or logical:\nreturning NA\n\n\n[1] NA\n\n# this will work\nm_dose %&gt;% pull(initial_weight_g) %&gt;% mean(na.rm = TRUE)\n\n[1] 43.92193\n\n\nNote how both times we used na.rm = TRUE to remove missing values before calculating the mean.\nYou might remember that we used the $ operator in the previous chapter to extract a single column from a data frame, so why use pull() instead? The main reason is that pull() works within a chain of pipes, whereas $ doesn’t.\nFor example, let’s say we want to know the average initial weight of mice that lost at least 4g. We can do this by chaining filter() and pull() together:\n\nm_dose %&gt;%\n  # filter to mice that lost at least 4g\n  filter(weight_lost_g &gt;= 4) %&gt;%\n  # get the initial_weight_g column as a vector\n  pull(initial_weight_g) %&gt;%\n  # calculate mean, removing NA values\n  mean(na.rm = TRUE)\n\n[1] 46.48023\n\n\n\n\n\n\n\n\nPractice exercises\n\n\n\nTry these practice questions to test your understanding\n\n1. Which line of code would NOT be a valid way to select only the drug_dose_g, initial_weight_g, and weight_lost_g columns from the m_dose data frame?\n\n\n\n\n ✗m_dose %&gt;% select(drug_dose_g, initial_weight_g, weight_lost_g)\n\n\n ✔m_dose %&gt;% select(contains(\"g\"))\n\n\n ✗m_dose %&gt;% select(ends_with(\"_g\"))\n\n\n ✗m_dose %&gt;% select(-cage_number, -tail_length_mm, -id_num, -mouse_strain, -sex, -replicate)\n\n\n\n\n\n\n2. How would I extract the initial_weight_g column from the m_dose data frame as a vector?\n\n\n\n\n ✗m_dose %&gt;% filter(initial_weight_g)\n\n\n ✗m_dose %&gt;% $initial_weight_g\n\n\n ✗m_dose %&gt;% select(initial_weight_g)\n\n\n ✔m_dose %&gt;% pull(initial_weight_g)\n\n\n\n\n\n\n3. How would you move the sex column to the end of the m_dose data frame?\n\n\n\n\n ✗m_dose %&gt;% relocate(sex)\n\n\n ✗m_dose %&gt;% relocate(sex, .after = last_col)\n\n\n ✔m_dose %&gt;% relocate(sex, .after = last_col())\n\n\n ✗m_dose %&gt;% reorder(sex, .after = last_col())\n\n\n\n\n\n\n\nSolutions\n\n\n\nThe line of code that would NOT be a valid way to select the drug_dose_g, initial_weight_g, and weight_lost_g columns from the m_dose data frame is m_dose %&gt;% select(contains(\"g\")). This line of code would select all columns that contain the letter ‘g’, which would include columns like cage_number and tail_length_mm. We need to specify either ends_with(\"g\") or contains(\"_g\") to only get those with _g at the end. The other options are valid ways to select the specified columns, although some are more efficient than others!\nThe correct way to extract the initial_weight_g column from the m_dose data frame as a vector is m_dose %&gt;% pull(initial_weight_g). The pull() function is used to extract a single column from a data frame as a vector. The other options are incorrect because filter() is used to subset rows, $ is not used in a pipe chain, and select() is outputs a data frame, not extract them as vectors.\nThe correct way to move the sex column to the end of the m_dose data frame is using the relocate() function like this: m_dose %&gt;% relocate(sex, .after = last_col()). The last_col() function is used to refer to the last column in the data frame. The other options are incorrect because reorder() is not a valid function, and you need to remember to include the brackets () when using last_col().",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Working with data - Part 1</span>"
    ]
  },
  {
    "objectID": "chapter_2.html#summary",
    "href": "chapter_2.html#summary",
    "title": "2  Working with data - Part 1",
    "section": "2.3 Summary",
    "text": "2.3 Summary\nHere’s what we’ve covered in this chapter:\n\nThe pipe operator %&gt;% and how we can use it to chain together multiple function calls, making our code more readable and easier to understand.\nThe basic dplyr verbs arrange(), filter() and select()\n\n\n\n\n\n\n\nWhy does data need to be tidy anyway?\n\n\n\nIn this chapter, we’ve been focusing on making our data ‘tidy’: that is, structured in a consistent way that makes it easy to work with. A nice visual illustration of tidy data and its importance can be found here.\n\n\n\n2.3.1 Practice questions\n\nWhat is the purpose of the pipe operator %&gt;%? Keeping this in mind, re-write the following code to use the pipe.\n\nround(mean(c(1, 2, 3, 4, 5)))\nprint(as.character(1 + 10))\n\nWhat would be the result of evaluating the following expressions? You don’t need to know these off the top of your head, use R to help! (Hint: some expressions might give an error. Try to think about why)\n\nm_dose %&gt;% filter(weight_lost_g &gt; 10)\nm_dose %&gt;% select(tail_length_mm, weight_lost_g)\nm_dose %&gt;% arrange(tail_length_mm)\nm_dose %&gt;% filter(initial_Weight_g &gt; 10) %&gt;% arrange(mouse_strain)\nm_dose %&gt;% relocate(mouse_strain, .after = cage_number)\nm_dose %&gt;% pull(weight_lost_g)\nm_dose %&gt;% filter(!is.na(weight_lost_g))\nm_dose %&gt;% replace_na(list(weight_lost_g = 0))\n\nWhat is a missing value in R? What are two ways to deal with missing values in a data frame?\n\n\n\nSolutions\n\n\nThe pipe operator %&gt;% is used to chain together multiple function calls, passing the result of one function to the next. Here’s how you could re-write the code to use the pipe:\n\nc(1, 2, 3, 4, 5) %&gt;% mean() %&gt;% round()\nas.character(1 + 10) %&gt;% print()\n\nThe result of evaluating the expressions would be:\n\nA data frame containing only the rows where weight_lost_g is greater than 10.\nA data frame containing only the tail_length_mm and weight_lost_g columns.\nA data frame sorted by tail_length_mm, in ascending order.\nAn error because initial_Weight_g is not a column in the data frame.\nA data frame with the mouse_strain column moved to be after the cage_number column.\nA vector containing the values of the weight_lost_g column.\nA data frame containing only the rows where weight_lost_g is not NA.\nA data frame with missing values in the weight_lost_g column replaced with 0.\n\nA missing value in R is represented by NA. Two ways to deal with missing values in a data frame are to remove them using filter(!is.na(column_name)) or to replace them with a specific value using replace_na(list(column_name = value)).",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Working with data - Part 1</span>"
    ]
  },
  {
    "objectID": "chapter_3.html",
    "href": "chapter_3.html",
    "title": "3  Working with data - Part 2",
    "section": "",
    "text": "3.1 Modifying data\nIn this chapter we will continue learning how to manipulate and summarise data using the dplyr package (with a little help from the tidyr package too).\nLet’s first load the tidyverse\n…and read in the MouseZempic® dosage data\nSo far, we’ve learned how to filter rows and select columns from a data frame. But what if we want to change the data itself? This is where the mutate() function comes in.\nThe mutate() function is used to add new columns to a data frame, or modify existing columns, often by performing some sort of calculation. For example, we can add a new column to m_dose that contains the drug dose in mg (rather than g):\nm_dose %&gt;%\n  # add a new column called drug_dose_mg\n  # convert drug_dose_g to mg by multiplying by 1000\n  mutate(drug_dose_mg = drug_dose_g * 1000) %&gt;%\n  # just select the drug dose columns so we can compare them\n  select(drug_dose_g, drug_dose_mg)\n\n# A tibble: 344 × 2\n   drug_dose_g drug_dose_mg\n         &lt;dbl&gt;        &lt;dbl&gt;\n 1     0.00181         1.81\n 2     0.00186         1.86\n 3     0.00195         1.95\n 4    NA              NA   \n 5     0.00193         1.93\n 6     0.0019          1.9 \n 7     0.00181         1.81\n 8     0.00195         1.95\n 9     0.00193         1.93\n10     0.0019          1.9 \n# ℹ 334 more rows\nYou can see that the drug_dose_mg column has been added to the data frame, and it contains, for each row, the value of the drug_dose_g column multiplied by 1000 (NA values are preserved).\nThese calculations can be as complex as you like, and involve multiple different columns. For example, to add a new column to the m_dose data frame that calculates the weight lost as a percentage of the initial weight:\nm_dose %&gt;%\n  # calculate the % of initial weight that was lost\n  mutate(weight_lost_percent = (weight_lost_g / initial_weight_g) * 100)\n\n# A tibble: 344 × 10\n   mouse_strain cage_number weight_lost_g replicate sex    drug_dose_g\n   &lt;chr&gt;        &lt;chr&gt;               &lt;dbl&gt; &lt;chr&gt;     &lt;chr&gt;        &lt;dbl&gt;\n 1 CD-1         1A                   3.75 rep1      male       0.00181\n 2 CD-1         1A                   3.8  rep1      female     0.00186\n 3 CD-1         1A                   3.25 rep1      female     0.00195\n 4 CD-1         1A                  NA    rep1      &lt;NA&gt;      NA      \n 5 CD-1         1A                   3.45 rep1      female     0.00193\n 6 CD-1         1A                   3.65 rep1      male       0.0019 \n 7 CD-1         1A                   3.62 rep1      female     0.00181\n 8 CD-1         1A                   4.68 rep1      male       0.00195\n 9 CD-1         1A                   3.48 rep1      &lt;NA&gt;       0.00193\n10 CD-1         1A                   4.25 rep1      &lt;NA&gt;       0.0019 \n# ℹ 334 more rows\n# ℹ 4 more variables: tail_length_mm &lt;dbl&gt;, initial_weight_g &lt;dbl&gt;,\n#   id_num &lt;dbl&gt;, weight_lost_percent &lt;dbl&gt;\nA useful helper function for mutate() is the case_when() function, which allows you to create new columns based on multiple conditions. We do this with the notation case_when(condition1 ~ value1, condition2 ~ value2, ...).\nFor example, to add a new column to the m_dose data frame that categorises the mice based on how much weight they lost:\nm_dose %&gt;%\n  # create a new column called weight_loss_category\n  mutate(weight_loss_category = case_when(\n    weight_lost_g &lt; 4 ~ \"Low\", # separate conditions with a comma\n    weight_lost_g &lt;= 5 ~ \"Medium\",\n    weight_lost_g &gt; 5 ~ \"High\"\n  )) %&gt;%\n  select(weight_lost_g, weight_loss_category)\n\n# A tibble: 344 × 2\n   weight_lost_g weight_loss_category\n           &lt;dbl&gt; &lt;chr&gt;               \n 1          3.75 Low                 \n 2          3.8  Low                 \n 3          3.25 Low                 \n 4         NA    &lt;NA&gt;                \n 5          3.45 Low                 \n 6          3.65 Low                 \n 7          3.62 Low                 \n 8          4.68 Medium              \n 9          3.48 Low                 \n10          4.25 Medium              \n# ℹ 334 more rows\nNote that the conditions are evaluated in order, and the first condition that is TRUE is the one that is used. So if a mouse lost 4.5g, it case_when() would first test if it fits the ‘Low’ category (by checking if 4.5 is less than 4, which it isn’t), and then if it fits the ‘Medium’ category (by checking if 4.5 is less than or equal to 5). Since it is, the mouse would be categorised as ‘Medium’.\nOne final thing to note is that mutate() can be used to modify existing columns as well as add new ones. To do this, just use the name of the existing column as the ‘new’ one.\nFor example, let’s use mutate() together with case_when() to modify the sex column so that it uses M and F instead male and female:\nm_dose %&gt;%\n  # modify sex column\n  mutate(sex = case_when(\n    sex == \"female\" ~ \"F\",\n    sex == \"male\" ~ \"M\",\n    # if neither, code it as 'X'\n    .default = \"X\"))\n\n# A tibble: 344 × 9\n   mouse_strain cage_number weight_lost_g replicate sex   drug_dose_g\n   &lt;chr&gt;        &lt;chr&gt;               &lt;dbl&gt; &lt;chr&gt;     &lt;chr&gt;       &lt;dbl&gt;\n 1 CD-1         1A                   3.75 rep1      M         0.00181\n 2 CD-1         1A                   3.8  rep1      F         0.00186\n 3 CD-1         1A                   3.25 rep1      F         0.00195\n 4 CD-1         1A                  NA    rep1      X        NA      \n 5 CD-1         1A                   3.45 rep1      F         0.00193\n 6 CD-1         1A                   3.65 rep1      M         0.0019 \n 7 CD-1         1A                   3.62 rep1      F         0.00181\n 8 CD-1         1A                   4.68 rep1      M         0.00195\n 9 CD-1         1A                   3.48 rep1      X         0.00193\n10 CD-1         1A                   4.25 rep1      X         0.0019 \n# ℹ 334 more rows\n# ℹ 3 more variables: tail_length_mm &lt;dbl&gt;, initial_weight_g &lt;dbl&gt;,\n#   id_num &lt;dbl&gt;",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Working with data - Part 2</span>"
    ]
  },
  {
    "objectID": "chapter_3.html#sec-mutate",
    "href": "chapter_3.html#sec-mutate",
    "title": "3  Working with data - Part 2",
    "section": "",
    "text": "Mutate allows you to add new columns to a data frame\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nFallback with default value(s)\n\n\n\nIn the above example, what would happen if a mouse lost -1g (gained weight)? It wouldn’t fit any of the conditions, so it would get an NA in the weight_loss_category column. Sometimes you might want this behaviour, but other times you would prefer to specify a ‘fallback’ category that will be assigned to everything that doesn’t fit in the other categories. You can do this by including a .default = argument at the end of the case_when() function. For example:\n\nm_dose %&gt;%\n  # create a new column called weight_loss_category\n  mutate(weight_loss_category = case_when(\n    weight_lost_g &lt; 4 ~ \"Low\", # separate conditions with a comma\n    weight_lost_g &lt;= 5 ~ \"Medium\",\n    weight_lost_g &gt; 5 ~ \"High\",\n    .default = \"Unknown\"\n  )) %&gt;%\n  select(weight_lost_g, weight_loss_category)\n\n# A tibble: 344 × 2\n   weight_lost_g weight_loss_category\n           &lt;dbl&gt; &lt;chr&gt;               \n 1          3.75 Low                 \n 2          3.8  Low                 \n 3          3.25 Low                 \n 4         NA    Unknown             \n 5          3.45 Low                 \n 6          3.65 Low                 \n 7          3.62 Low                 \n 8          4.68 Medium              \n 9          3.48 Low                 \n10          4.25 Medium              \n# ℹ 334 more rows\n\n\nNotice how the NA value in the fourth row is now categorised as ‘Unknown’.\n\n\n\n\n\n\n\n\n\n\n\nPractice exercises\n\n\n\nTry these practice questions to test your understanding\n\n1. What line of code would you use to add a new column to the m_dose data frame that converts the tail_length_mm column to cm?\n\n\n\n\n ✗m_dose %&gt;% create(tail_length_cm = tail_length_mm / 10)\n\n\n ✗m_dose %&gt;% mutate(tail_length_cm == tail_length_mm / 10)\n\n\n ✔m_dose %&gt;% mutate(tail_length_cm = tail_length_mm / 10)\n\n\n ✗m_dose %&gt;% tail_length_cm = tail_length_mm / 10\n\n\n\n\n\n\n2. Explain in words what the following code does:\n\nm_dose %&gt;%\n  arrange(desc(weight_lost_g)) %&gt;%\n  mutate(weight_lost_rank = row_number())\n\nHint: the row_number() function returns the number of each row in the data frame (1 being the first row and so on).\n\n\n\n\n ✗Adds a new column to the data frame that ranks the mice based on how much weight they lost, with 1 being the mouse that lost the least weight.\n\n\n ✔Adds a new column to the data frame that ranks the mice based on how much weight they lost, with 1 being the mouse that lost the most weight.\n\n\n ✗Adds a new column to the data frame that ranks the mice\n\n\n ✗Does nothing, because the row_number() function has no arguments\n\n\n\n\n\n\n3. What is wrong with this R code?\n\nm_dose %&gt;%\n  mutate(weight_lost_category = case_when(\n    weight_lost_g &lt; 4 ~ \"Low\"\n    weight_lost_g &lt;= 5 ~ \"Medium\"\n    weight_lost_g &gt; 5 ~ \"High\"\n  ))\n\nError: &lt;text&gt;:4:5: unexpected symbol\n3:     weight_lost_g &lt; 4 ~ \"Low\"\n4:     weight_lost_g\n       ^\n\n\n\n\n\n\n ✗You didn’t include a .default = condition at the end of the case_when() function to act as a fallback\n\n\n ✗You can’t use the case_when() function with the mutate() function\n\n\n ✗weight_lost_g is not a valid column name\n\n\n ✔You need to separate the conditions in the case_when() function with a comma\n\n\n\n\n\n\n4. Explain in words what the following code does:\n\nm_dose %&gt;%\n  mutate(mouse_strain = case_when(\n    mouse_strain == \"Black 6\" ~ \"B6\",\n    .default = mouse_strain\n  ))\n\nHint: if you’re not sure, try running the code, but pipe it into View() so that you can take a good look at what’s happening in the mouse_strain column.\n\n\n\n\n ✗Renames the strains of all the mice to “B6”, regardless of their original strain\n\n\n ✗This code will produce an error\n\n\n ✗Adds a new column that categorises the mice based on their strain, so that any mice from the “Black 6” strain are now called “B6”, and all other strains are left unchanged.\n\n\n ✔Modifies the mouse_strain column so that any mice from the “Black 6” strain are now called “B6”, and all other strains are left unchanged.\n\n\n\n\n\n\n\nSolutions\n\n\n\nThe correct line of code to add a new column to the m_dose data frame that converts the tail_length_mm column to cm is m_dose %&gt;% mutate(tail_length_cm = tail_length_mm / 10).\nThe code m_dose %&gt;% arrange(desc(weight_lost_g)) %&gt;% mutate(weight_lost_rank = row_number()) adds a new column to the data frame that ranks the mice based on how much weight they lost, with 1 being the mouse that lost the most weight. First, the arrange(desc(weight_lost_g)) function sorts the data frame by the weight_lost_g column in descending order, and then the mutate(weight_lost_rank = row_number()) function adds a new column that assigns a rank to each row based on its position (row number) in the sorted data frame.\nThe error is that the conditions in the case_when() function are not separated by commas. Each condition should be followed by a comma because these are like the arguments in a function. Remeber that it’s optional to include the .default = condition at the end of the case_when() function.\nThe code m_dose %&gt;% mutate(mouse_strain = case_when(mouse_strain == \"Black 6\" ~ \"B6\", .default = mouse_strain)) modifies the mouse_strain column so that any mice from the “Black 6” strain are now called “B6”, and all other strains are left unchanged. As we are calling our column mouse_strain, no new column is being created (we are modifying the existing one) and the .default = mouse_strain condition acts as a fallback to keep the original values (that already exist in the mouse_strain column) for any rows that don’t match our first condition (strain being “Black 6”).",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Working with data - Part 2</span>"
    ]
  },
  {
    "objectID": "chapter_3.html#sec-summarise",
    "href": "chapter_3.html#sec-summarise",
    "title": "3  Working with data - Part 2",
    "section": "3.2 Summarising data",
    "text": "3.2 Summarising data\n\n\n\nSummarise allows you to calculate summary statistics that collapse many rows into one\n\n\nThe summarise() (or summarize(), if you prefer US spelling) function is used to calculate summary statistics on your data. It takes similar arguments to mutate(), but instead of adding a new column to the data frame, it returns a new data frame with a single row and one column for each summary statistic you calculate.\nFor example, to calculate the mean weight lost by the mice in the m_dose data frame:\n\nm_dose %&gt;%\n  summarise(mean_weight_lost = mean(weight_lost_g, na.rm = TRUE))\n\n# A tibble: 1 × 1\n  mean_weight_lost\n             &lt;dbl&gt;\n1             4.20\n\n\nWe can also calculate multiple summary statistics at once. For example, to calculate the mean, median, and standard deviation of the weight lost by the mice:\n\nm_dose %&gt;%\n  summarise(\n    mean_weight_lost = mean(weight_lost_g, na.rm = TRUE),\n    median_weight_lost = median(weight_lost_g, na.rm = TRUE),\n    sd_weight_lost = sd(weight_lost_g, na.rm = TRUE)\n  )\n\n# A tibble: 1 × 3\n  mean_weight_lost median_weight_lost sd_weight_lost\n             &lt;dbl&gt;              &lt;dbl&gt;          &lt;dbl&gt;\n1             4.20               4.05          0.802\n\n\nThe power of summarising data is really seen when combined with grouping, which we will cover in the next section.\n\n\n\n\n\n\nPractice exercises\n\n\n\nTry these practice questions to test your understanding\n\n1. Explain in words what the following code does:\n\nm_dose %&gt;%\n  summarise(average_tail = mean(tail_length_mm, na.rm = TRUE),\n            min_tail = min(tail_length_mm, na.rm = TRUE),\n            max_tail = max(tail_length_mm, na.rm = TRUE))\n\n\n\n\n\n ✗Calculates the average, minimum, and maximum tail length of the mice in the m_dose data frame.\n\n\n ✔Produces a data frame containing one column for each of the average, minimum, and maximum tail length of the mice in the m_dose data frame.\n\n\n ✗Finds the average tail length of the mice in the m_dose data frame.\n\n\n ✗Produces a vector containing the average, minimum, and maximum tail length of the mice in the m_dose data frame.\n\n\n\n\n\n\n2. What is NOT a valid way to calculate the mean weight lost by the mice in the m_dose data frame?\n\n\n\n\n ✗m_dose %&gt;% summarise(mean_weight_lost = mean(weight_lost_g, na.rm = TRUE))\n\n\n ✗m_dose %&gt;% pull(weight_lost_g) %&gt;% mean(na.rm = TRUE)\n\n\n ✗m_dose %&gt;% summarize(mean_weight_lost = mean(weight_lost_g, na.rm = TRUE))\n\n\n ✔m_dose %&gt;% mean(weight_lost_g, na.rm = TRUE)\n\n\n\n\n\n\n\nSolutions\n\n1. The code produces a data frame containing one column for each of the average, minimum, and maximum tail length of the mice in the m_dose data frame.\n2. The line of code that is NOT a valid way to calculate the mean weight lost by the mice in the m_dose data frame is m_dose %&gt;% mean(weight_lost_g, na.rm = TRUE). This line of code is incorrect because the mean() function is being used directly on the data frame, rather than within a summarise() function. The other options are valid ways to calculate the mean weight lost by the mice in the m_dose data frame (although note that the second option uses pull() to extract the weight_lost_g column as a vector before calculating the mean, so the mean value is stored in a vector rather than in a data frame).",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Working with data - Part 2</span>"
    ]
  },
  {
    "objectID": "chapter_3.html#sec-grouping",
    "href": "chapter_3.html#sec-grouping",
    "title": "3  Working with data - Part 2",
    "section": "3.3 Grouping",
    "text": "3.3 Grouping\n\n\n\nUsing summarise with the .by option allows you to create separate summaries for different ‘groups’ of data\n\n\nGrouping is a powerful concept in in dplyr that allows you to perform operations on subsets of your data. For example, you might want to calculate the mean weight lost by mice in each cage, or find the mouse with the longest tail in each strain.\nWe can group data using the .by argument that exists in many dplyr functions, like summarise() and mutate(), and passing it the name(s) of column(s) to group by. For example, to calculate the mean weight lost by mice in each cage:\n\nm_dose %&gt;%\n  summarise(\n    mean_weight_lost = mean(weight_lost_g, na.rm = TRUE),\n    # don't forget it's .by, not by!\n    .by = cage_number)\n\n# A tibble: 3 × 2\n  cage_number mean_weight_lost\n  &lt;chr&gt;                  &lt;dbl&gt;\n1 1A                      3.71\n2 3E                      4.72\n3 2B                      3.71\n\n\nLike when we first learned the summarise function above, we give our new column a name (mean_weight_lost), and then we assign its value to be the mean of the weight_lost_g column (with NAs removed). But this time, we also added the .by argument to specify the column we want to group by (cage_number, in this case). This will return a data frame with the mean weight lost by mice in each cage.\nGrouping is a powerful tool for exploring your data and can help you identify patterns that might not be obvious when looking at the data as a whole. For example, notice how this grouped summary reveals that mice in cage 3E lost more weight than those in the other two cages.\nIt’s also possible to group by multiple columns by passing a vector of column names to the .by argument. For example, to calculate the mean weight lost by mice in each cage and strain:\n\nm_dose %&gt;%\n  summarise(mean_weight_lost = mean(weight_lost_g, na.rm = TRUE),\n  # group by both cage_number and mouse_strain\n    .by = c(cage_number, mouse_strain))\n\n# A tibble: 5 × 3\n  cage_number mouse_strain mean_weight_lost\n  &lt;chr&gt;       &lt;chr&gt;                   &lt;dbl&gt;\n1 1A          CD-1                     3.71\n2 3E          CD-1                     3.71\n3 2B          CD-1                     3.69\n4 3E          Black 6                  5.08\n5 2B          BALB C                   3.73\n\n\nOf course, mean() is not the only function that we can use within summarise(). We can use any function that takes a vector of values and returns a single value, like median(), sd(), or max(). We can also use multiple functions at once, by giving each column a name and specifying the function we want to use:\n\nm_dose %&gt;%\n  summarise(\n    n = n(),\n    mean_weight_lost = mean(weight_lost_g, na.rm = TRUE),\n    median_weight_lost = median(weight_lost_g, na.rm = TRUE),\n    sd_weight_lost = sd(weight_lost_g, na.rm = TRUE),\n    max_weight_lost = max(weight_lost_g, na.rm = TRUE),\n    min_weight_lost = min(weight_lost_g, na.rm = TRUE),\n    .by = cage_number)\n\n# A tibble: 3 × 7\n  cage_number     n mean_weight_lost median_weight_lost sd_weight_lost\n  &lt;chr&gt;       &lt;int&gt;            &lt;dbl&gt;              &lt;dbl&gt;          &lt;dbl&gt;\n1 1A             52             3.71               3.7           0.445\n2 3E            168             4.72               4.78          0.783\n3 2B            124             3.71               3.69          0.417\n# ℹ 2 more variables: max_weight_lost &lt;dbl&gt;, min_weight_lost &lt;dbl&gt;\n\n\nHere, we also used the n() function to calculate the number of mice in each cage. This is a special helper function that works within summarise to count the number of rows in each group.\n\n\n\n\n\n\nTo .by or not to .by?\n\n\n\nIn the dplyr package, there are two ways to group data: using the .by argument within various functions (as we have covered so far), or using the group_by() function, then performing your operations and ungrouping with ungroup().\nFor example, we’ve seen above how to calculate the mean weight lost by mice in each cage using the .by argument:\n\nm_dose %&gt;%\n  summarise(mean_weight_lost = mean(weight_lost_g, na.rm = TRUE), .by = cage_number)\n\n# A tibble: 3 × 2\n  cage_number mean_weight_lost\n  &lt;chr&gt;                  &lt;dbl&gt;\n1 1A                      3.71\n2 3E                      4.72\n3 2B                      3.71\n\n\nBut we can also do the same using group_by() and ungroup():\n\nm_dose %&gt;%\n  group_by(cage_number) %&gt;%\n  summarise(mean_weight_lost = mean(weight_lost_g, na.rm = TRUE)) %&gt;%\n  ungroup()\n\n# A tibble: 3 × 2\n  cage_number mean_weight_lost\n  &lt;chr&gt;                  &lt;dbl&gt;\n1 1A                      3.71\n2 2B                      3.71\n3 3E                      4.72\n\n\nThe two methods are equivalent, but using the .by argument within functions can be more concise and easier to read. Still, it’s good to be aware of group_by() and ungroup() as they are widely used, particularly in older code.\n\n\nAlthough grouping is most often used with summarise(), it can be used with dplyr functions too. For example mutate() function can also be used with grouping to add new columns to the data frame based on group-specific calculations. Let’s say we wanted to calculate the Z-score (also known as the standard score) to standardise the weight lost by each mouse within each strain.\nAs a reminder, the formula for calculating the Z-score is \\(\\frac{x - \\mu}{\\sigma}\\), where \\(x\\) is the value (in our case the weight_lost_g column), \\(\\mu\\) is the mean, and \\(\\sigma\\) is the standard deviation.\nWe can calculate this for each mouse in each strain using the following code:\n\nm_dose %&gt;%\n  # remove NAs before calculating the mean and SD\n  filter(!is.na(weight_lost_g)) %&gt;%\n  mutate(weight_lost_z = (weight_lost_g - mean(weight_lost_g)) / sd(weight_lost_g), .by = mouse_strain) %&gt;%\n  # select the relevant columns\n  select(mouse_strain, weight_lost_g, weight_lost_z)\n\n# A tibble: 342 × 3\n   mouse_strain weight_lost_g weight_lost_z\n   &lt;chr&gt;                &lt;dbl&gt;         &lt;dbl&gt;\n 1 CD-1                  3.75         0.108\n 2 CD-1                  3.8          0.217\n 3 CD-1                  3.25        -0.983\n 4 CD-1                  3.45        -0.547\n 5 CD-1                  3.65        -0.110\n 6 CD-1                  3.62        -0.165\n 7 CD-1                  4.68         2.12 \n 8 CD-1                  3.48        -0.492\n 9 CD-1                  4.25         1.20 \n10 CD-1                  3.3         -0.874\n# ℹ 332 more rows\n\n\nUnlike when we used .by with summarise(), we still get the same number of rows as the original data frame, but now we have a new column weight_lost_z that contains the Z-score for each mouse within each strain. This could be useful for identifying outliers or comparing the weight lost by each mouse to the average for its strain.\n\n\n\n\n\n\nPractice exercises\n\n\n\nTry these practice questions to test your understanding\n\n1. Which line of code would you use to calculate the median tail length of mice belonging to each strain in the m_dose data frame?\n\n\n\n\n ✗m_dose %&gt;% summarise(median_tail_length = median(tail_length_mm), .by = mouse_strain)\n\n\n ✔m_dose %&gt;% summarise(median_tail_length = median(tail_length_mm, na.rm = TRUE), .by = mouse_strain)\n\n\n ✗m_dose %&gt;% summarise(median_tail_length = median(tail_length_mm, na.rm = TRUE), by = mouse_strain)\n\n\n ✗m_dose %&gt;% mutate(median_tail_length = median(tail_length_mm, na.rm = TRUE), .by = mouse_strain)\n\n\n\n\n\n\n2. Explain in words what the following code does:\n\nm_dose %&gt;%\n  summarise(max_tail_len = max(tail_length_mm, na.rm = TRUE), .by = c(mouse_strain, replicate))\n\n\n\n\n\n ✗Calculates the maximum tail length of all mice for each strain in the m_dose data frame\n\n\n ✗Calculates the maximum tail length of all mice for each replicate in the m_dose data frame\n\n\n ✗Calculates the maximum tail length of all mice in the m_dose data frame\n\n\n ✔Calculates the maximum tail length of mice in each unique combination of strain and replicate in the m_dose data frame.\n\n\n\n\n\n\n3. I want to count how many male and how many female mice there are for each strain in the m_dose data frame. Which line of code would I use?\n\n\n\n\n ✗m_dose %&gt;% summarise(count = n(), .by = sex)\n\n\n ✗m_dose %&gt;% summarise(count = n(), .by = mouse_strain)\n\n\n ✔m_dose %&gt;% summarise(count = n(), .by = c(mouse_strain, sex))\n\n\n ✗m_dose %&gt;% summarise(count = n(), .by = mouse_strain, sex)\n\n\n\n\n\n\n4. I want to find the proportion of weight lost by each mouse in each cage in the m_dose data frame. Which line of code would I use?\n\n\n\n\n ✗m_dose %&gt;% summarise(weight_lost_proportion = weight_lost_g / sum(weight_lost_g, na.rm = TRUE), .by = cage_number)\n\n\n ✔m_dose %&gt;% mutate(weight_lost_proportion = weight_lost_g / sum(weight_lost_g, na.rm = TRUE), .by = cage_number)\n\n\n ✗m_dose %&gt;% mutate(weight_lost_proportion = weight_lost_g / sum(weight_lost_g, na.rm = TRUE, .by = cage_number))\n\n\n ✗m_dose %&gt;% mutate(weight_lost_proportion = weight_lost_g / sum(weight_lost_g, na.rm = TRUE))\n\n\n\n\n\n\n\nSolutions\n\n\n\nThe correct line of code to calculate the median tail length of mice belonging to each strain in the m_dose data frame is m_dose %&gt;% summarise(median_tail_length = median(tail_length_mm, na.rm = TRUE), .by = mouse_strain). Remember to use na.rm = TRUE to remove any missing values before calculating the median, and to use .by to specify the column to group by (not by). Seeing as we want to calculate the median (collapse down to a single value per group), we need to use summarise() rather than mutate().\nThe code m_dose %&gt;% summarise(max_tail_len = max(tail_length_mm, na.rm = TRUE), .by = c(mouse_strain, replicate)) calculates the maximum tail length of mice in each unique combination of strain and replicate in the m_dose data frame.\nThe correct line of code to count how many male and how many female mice there are for each strain in the m_dose data frame is m_dose %&gt;% summarise(count = n(), .by = c(mouse_strain, sex)). We need to group by both mouse_strain and sex to get the count for each unique combination of strain and sex. Don’t forget that we specify the column names as a vector when grouping by multiple columns.\nThe correct line of code to find the proportion of weight lost by each mouse in each cage in the m_dose data frame is m_dose %&gt;% mutate(weight_lost_proportion = weight_lost_g / sum(weight_lost_g, na.rm = TRUE), .by = cage_number). We use mutate() because we want a value for each mouse (each row in our data), rather than to collapse down to a single value for each group (cage number in this case). Be careful that you use the .by argument within the mutate() function call, not within the sum() function by mistake (this is what is wrong with the third option).",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Working with data - Part 2</span>"
    ]
  },
  {
    "objectID": "chapter_3.html#sec-saving",
    "href": "chapter_3.html#sec-saving",
    "title": "3  Working with data - Part 2",
    "section": "3.4 Saving data to a file",
    "text": "3.4 Saving data to a file\nOnce you’ve cleaned and transformed your data, you’ll often want to save it to a file so that you can use it in other programs or share it with others. The write_csv() and write_tsv() functions from the readr package are a great way to do this. They take two arguments - the data frame you want to save and the file path where you want to save it.\nFor example, let’s say I want to save my summary table of the weight lost by mice in each cage to a CSV file called cage_summary_table.csv:\n\n# create the summary table\n# and assign it to a variable\ncage_summary_table &lt;- m_dose %&gt;%\n  summarise(\n    n = n(),\n    mean_weight_lost = mean(weight_lost_g, na.rm = TRUE),\n    median_weight_lost = median(weight_lost_g, na.rm = TRUE),\n    sd_weight_lost = sd(weight_lost_g, na.rm = TRUE),\n    .by = cage_number)\n\n# save the data to a CSV file\nwrite_csv(cage_summary_table, \"cage_summary_table.csv\")\n\nCSV files are particularly great because they can be easily read into other software, like Excel.\nIt’s also possible to use the write_*() functions along with a pipe:\n\nm_dose %&gt;%\n  summarise(\n    n = n(),\n    mean_weight_lost = mean(weight_lost_g, na.rm = TRUE),\n    median_weight_lost = median(weight_lost_g, na.rm = TRUE),\n    sd_weight_lost = sd(weight_lost_g, na.rm = TRUE),\n    .by = cage_number) %&gt;%\n  write_csv(\"cage_summary_table.csv\")\n\nRemember here that the first argument (the data frame to save) is passed on by the pipe, so the only argument in the brackets is the second one: the file path.",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Working with data - Part 2</span>"
    ]
  },
  {
    "objectID": "chapter_3.html#summary",
    "href": "chapter_3.html#summary",
    "title": "3  Working with data - Part 2",
    "section": "3.5 Summary",
    "text": "3.5 Summary\nHere’s what we’ve covered in this chapter:\n\nThe basic dplyr verbs mutate(), and arrange() and how they can be used to tidy and analyse data.\nThe summarise() function and how it can be used to calculate summary statistics on your data, as well as the power of grouping data with the .by argument.\n\n\n\n\n\n\n\nWhy does data need to be tidy anyway?\n\n\n\nIn this chapter, we’ve been focusing on making our data ‘tidy’: that is, structured in a consistent way that makes it easy to work with. A nice visual illustration of tidy data and its importance can be found here.\n\n\n\n3.5.1 Practice questions\n\nWhat would be the result of evaluating the following expressions? You don’t need to know these off the top of your head, use R to help! (Hint: some expressions might give an error. Try to think about why)\n\nm_dose %&gt;% mutate(weight_lost_kg = weight_lost_g / 1000)\nm_dose %&gt;% summarise(mean_weight_lost = mean(weight_lost_g, na.rm = TRUE))\nm_dose %&gt;% summarise(mean_weight_lost = mean(weight_lost_g, na.rm = TRUE), .by = cage_number)\n\nI want to add a new column to the m_dose data frame that converts the mouse_strain column to lowercase. Hint: you can use the tolower() function in R to convert characters to lowercase. Look up its help page by typing ?tolower in the R console to see how to use it.\nHow could you find the maximum tail length for each unique combination of sex and mouse strain in the m_dose data frame?\nWrite a line of code to save the result of Q5 to a CSV file called max_tail_length.csv.\n\n\n\nSolutions\n\n\nThe result of evaluating the expressions would be:\n\nA data frame with an additional column weight_lost_kg that contains the weight lost in kilograms.\nA data frame with the mean weight lost by all mice.\nA data frame with the mean weight lost by mice in each cage.\n\nTo add a new column to the m_dose data frame that converts the mouse_strain column to lowercase, you can use mutate() as follows`:\n\n\nm_dose %&gt;%\n  mutate(mouse_strain_lower = tolower(mouse_strain))\n\n# A tibble: 344 × 10\n   mouse_strain cage_number weight_lost_g replicate sex    drug_dose_g\n   &lt;chr&gt;        &lt;chr&gt;               &lt;dbl&gt; &lt;chr&gt;     &lt;chr&gt;        &lt;dbl&gt;\n 1 CD-1         1A                   3.75 rep1      male       0.00181\n 2 CD-1         1A                   3.8  rep1      female     0.00186\n 3 CD-1         1A                   3.25 rep1      female     0.00195\n 4 CD-1         1A                  NA    rep1      &lt;NA&gt;      NA      \n 5 CD-1         1A                   3.45 rep1      female     0.00193\n 6 CD-1         1A                   3.65 rep1      male       0.0019 \n 7 CD-1         1A                   3.62 rep1      female     0.00181\n 8 CD-1         1A                   4.68 rep1      male       0.00195\n 9 CD-1         1A                   3.48 rep1      &lt;NA&gt;       0.00193\n10 CD-1         1A                   4.25 rep1      &lt;NA&gt;       0.0019 \n# ℹ 334 more rows\n# ℹ 4 more variables: tail_length_mm &lt;dbl&gt;, initial_weight_g &lt;dbl&gt;,\n#   id_num &lt;dbl&gt;, mouse_strain_lower &lt;chr&gt;\n\n\n\nYou can use the max() function within summarise(.by = c(sex, mouse_strain)) to find the maximum tail length of each unique sex/mouse strain combination:\n\n\nm_dose %&gt;%\n  summarise(max_tail_length = max(tail_length_mm, na.rm = TRUE), .by = c(sex, mouse_strain))\n\n# A tibble: 8 × 3\n  sex    mouse_strain max_tail_length\n  &lt;chr&gt;  &lt;chr&gt;                  &lt;dbl&gt;\n1 male   CD-1                    21.5\n2 female CD-1                    20.7\n3 &lt;NA&gt;   CD-1                    20.2\n4 female Black 6                 15.5\n5 male   Black 6                 17.3\n6 &lt;NA&gt;   Black 6                 15.7\n7 female BALB C                  19.4\n8 male   BALB C                  20.8\n\n\n\nTo save the result of Q5 to a CSV file called max_tail_length.csv, you can use the write_csv() function, either by using a pipe to connect it to the code you wrote previously:\n\n\nm_dose %&gt;%\n  summarise(max_tail_length = max(tail_length_mm, na.rm = TRUE), .by = c(sex, mouse_strain)) %&gt;%\n  write_csv(\"max_tail_length.csv\")\n\nOr by assigning this result to a variable and then saving it to a file:\n\nmax_tail_length &lt;- m_dose %&gt;%\n  summarise(max_tail_length = max(tail_length_mm, na.rm = TRUE), .by = c(sex, mouse_strain))\n\nwrite_csv(max_tail_length, \"max_tail_length.csv\")",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Working with data - Part 2</span>"
    ]
  },
  {
    "objectID": "chapter_4.html",
    "href": "chapter_4.html",
    "title": "4  Plotting with ggplot2",
    "section": "",
    "text": "4.1 Building our first plot, layer by layer\nIn this chapter we will learn how to create and customise plots using the ggplot2 package.\nTo get started, let’s load the tidyverse package, which includes ggplot2:\nAnd read in the m_dose that we have been using in previous chapters:\nAlthough R has a built-in plotting system, ggplot2 is a more powerful and flexible package for creating plots. The gg in ggplot2 stands for “Grammar of Graphics”, which is a way thinking about how each component of a plot (e.g. axes or colours) is part of the ‘language’ of data visualisation that allows you to compose complex plots piece by piece, just like you combine words to form sentences.",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Plotting with ggplot2</span>"
    ]
  },
  {
    "objectID": "chapter_4.html#building-our-first-plot-layer-by-layer",
    "href": "chapter_4.html#building-our-first-plot-layer-by-layer",
    "title": "4  Plotting with ggplot2",
    "section": "",
    "text": "4.1.1 Initialisation\nWhen making a ggplot, the first thing you need to do is initialise it with the ggplot() function. This function takes two arguments:\n\nthe data that you want to visualise (a dataframe/tibble), and\nmapping, which describes the scales that will be used to display the data (e.g. which variable should be the x axis, which should be represented by colour, etc.)\n\nThe mapping is specified using the aes() function, which stands for ‘aesthetics’. It takes named arguments, where the names are the aesthetics you want to use to show your data (e.g. x, y, colour, shape, etc.) and the values are the names of the columns in your data that you want to use for those aesthetics.\nFor example, to make a plot to explore the relationship between the initial weight of the mice and their tail length, we would write:\n\nm_dose %&gt;% ggplot(aes(x = initial_weight_g, y = tail_length_mm))\n\n\n\n\n\n\n\n\nIn the plot panel (bottom right hand corner), you should now see a blank plot with the x and y axes labelled with the column names we specified in the aes() function. There’s no data on it yet, because we haven’t told ggplot how to physically represent the data on the x and y scales we have specified.\n\n\n4.1.2 Adding data\nData is represented in ggplot using geoms (short for ‘geometric objects’). A geom is a visual representation of the data in the plot, such as points, lines or bars. They are named geom_* where * is the type of geom you want to use. We will cover some of the most common geoms later in this chapter.\nGeoms are added to plots layers (which are drawn on top of one another, like layers of a cake) using the + operator.\nFor example, let’s add points to the plot that we initialised above using geom_point():\n\nm_dose %&gt;% ggplot(aes(x = initial_weight_g, y = tail_length_mm)) +\n  geom_point()\n\nWarning: Removed 2 rows containing missing values or values outside the scale range\n(`geom_point()`).\n\n\n\n\n\n\n\n\n\nThis gives us a basic scatterplot of the data, with each point representing the tail length and initial weight of a mouse in our dataset.\nNotice how we didn’t have to specify the data or mapping again when we added the geom_point() layer, because the data and mapping are inherited from the initial ggplot() function call. This is a common pattern in ggplot2: you only need to specify the data and mapping once, and it is used by all subsequent layers.\n\n\n\n\n\n\nThe plus + vs the pipe %&gt;%\n\n\n\nYou might have noticed that + in ggplot works similarly to the pipe operator %&gt;% in the dplyr package in that you place it at the end of a line of code, but + is only ever used in the context of plotting.\nDon’t mix them up! A handy way to remember is that + looks a bit like the axes of a plot, so it’s what you should use when plotting.\n\n\n\n\n4.1.3 Overlaying additional data\nOf course, this is a very simple plot. To show more information, we can add additional layers using the + operator, or use additional aesthetics.\nFor example, let’s add a a layer containing a linear trendline using geom_smooth(method = \"lm\"):\n\nm_dose %&gt;% ggplot(aes(x = initial_weight_g, y = tail_length_mm)) +\n  geom_point() +\n  geom_smooth(method = \"lm\")\n\n`geom_smooth()` using formula = 'y ~ x'\n\n\nWarning: Removed 2 rows containing non-finite outside the scale range\n(`stat_smooth()`).\n\n\nWarning: Removed 2 rows containing missing values or values outside the scale range\n(`geom_point()`).\n\n\n\n\n\n\n\n\n\nHere, we supplied the method = \"lm\" argument to geom_smooth() to tell it fit a linear model (lm for short) to the data and plot the line of best fit, surrounded by a 95% confidence interval. Most geoms will have additional arguments like this that you can use to customise their appearance. Remember that we can check the documentation for geoms and other functions using ?geom_smooth.\n\n\n\n\n\n\nggplot2 and missing values\n\n\n\nYou might have noticed that, along with the plot, R is also printing a warning message that lets us know that some rows of our data contain missing values. ggplot2 will automatically remove these rows from the plot (and warn you that it’s happening), but it’s always a good idea to check your data for missing values before plotting it, as they can affect the results of your analysis. Recall from last chapter that we can do this by combining the is.na() function with filter():\n\n# find the rows of our data that contain missing values in the columns we're plotting\nm_dose %&gt;%\n  filter(is.na(initial_weight_g), is.na(tail_length_mm))\n\n# A tibble: 2 × 9\n  mouse_strain cage_number weight_lost_g replicate sex   drug_dose_g\n  &lt;chr&gt;        &lt;chr&gt;               &lt;dbl&gt; &lt;chr&gt;     &lt;chr&gt;       &lt;dbl&gt;\n1 CD-1         1A                     NA rep1      &lt;NA&gt;           NA\n2 Black 6      3E                     NA rep3      &lt;NA&gt;           NA\n# ℹ 3 more variables: tail_length_mm &lt;dbl&gt;, initial_weight_g &lt;dbl&gt;,\n#   id_num &lt;dbl&gt;\n\n\nFrom here on, we will hide these warnings in the ebook so that it’s easier to read, but you’ll still see them if you run the code in your own R session.\n\n\nWe can also add additional aesthetics to the plot beyond just x and y. For example, let’s use the colour aesthetic to represent the strain of each mouse. To do this, we add colour = strain to the aes() function that describes the mapping in the ggplot() call:\n\nm_dose %&gt;% ggplot(\n  aes(x = initial_weight_g, y = tail_length_mm, colour = mouse_strain)) +\n  geom_point() +\n  geom_smooth(method = \"lm\")\n\n`geom_smooth()` using formula = 'y ~ x'\n\n\nWarning: Removed 2 rows containing non-finite outside the scale range\n(`stat_smooth()`).\n\n\nWarning: Removed 2 rows containing missing values or values outside the scale range\n(`geom_point()`).\n\n\n\n\n\n\n\n\n\nNot only are the points now coloured by the strain of each mouse, but there are now three separate colour-coded trendlines, one for each strain. This is because the aesthetic mapping we supply to the ggplot() function when initialising the plot is inherited by all subsequent layers/geoms.\nNotice as well how adding colour to the plot totally changes the way we perceive the data! Without colour and just plotting a single trendline, it appeared that there was an overall negative association between initial weight and tail length, but we can now see that there is actually a positive association within each strain. This is an example of Simpson’s Paradox, and shows why it’s so important to visualise your data!\n\n\n4.1.4 Saving plots as images\nOnce you’re satisfied with the plot you’ve created, you can programmatically save your plot using the ggsave() function.\nTo use ggsave(), you need to specify:\n\nThe name of the file to to save the plot as (e.g. \"my_plot.png\"). Specifying a different file extension, e.g. \"my_plot.pdf\" will save the plot in the appropriate format.\nThe plot object you want to save (defaults to the last plot you sent to the plot pane).\nThe dimensions of the plot (e.g. width = 6, height = 4). Dimensions are in inches by default and can be changed using the units argument (e.g. units = \"cm\").\n\nFor example, to save the last plot we created as a .png file with dimensions of 5 by 7 inches, we would write:\n\nggsave(\"coloured_scatterplot.png\", width = 5, height = 7)\n\nOr to save it as a .pdf file with dimensions of 20 by 30 cm:\n\nggsave(\"coloured_scatterplot.pdf\", width = 20, height = 30, units = \"cm\")\n\nIt’s good practice to assign the plot you want to save to a variable, and provide it to the ‘plot’ argument of ggsave(), rather than relying on the last plot you created. This makes it clear what plot you’re saving, so that your code is more readable and reproducible.\n\n# first assign the plot to a variable\ncolourful_scatterplot &lt;- m_dose %&gt;% \n  ggplot(\n  aes(x = initial_weight_g, y = tail_length_mm, colour = mouse_strain)\n  ) +\n  geom_point() +\n  geom_smooth(method = \"lm\")\n\n# then save the plot: notice the 'plot' argument\nggsave(\"coloured_scatterplot.pdf\", plot = colourful_scatterplot, width = 20, height = 30, units = \"cm\")\n\nIt’s also possible to save plots using the export button in the plot panel: \nYou can choose to save the plot either as an image: \nIn this case, you can set the file type and dimensions, and see a preview of the plot before saving it. Tip: it’s also possible to change the dimensions of the plot by dragging the bottom left of the preview window.\nYou can also save plots as a PDF: \nAlthough there is no preview for PDFs within RStudio itself, you can click the ‘preview’ button to open the PDF in your default PDF viewer.\nIn general, it’s preferable to save plots programmatically using ggsave() because it’s more reproducible (because if you ever change your plotting code or data, new plot files can be automatically generated), but the export button can be useful for quickly saving plots during exploratory data analysis (or use the ultimate lazy hack: just screenshot the plot panel!).\n\n\n\n\n\n\nPractice exercises\n\n\n\nTry these practice questions to test your understanding\n\n1. Which of the following statements about the mapping in a ggplot is incorrect?\n\n\n\n\n ✗Mapping is specified using the aes() function\n\n\n ✔Mapping refers to the type of plot you want to create (e.g. scatterplot, line plot)\n\n\n ✗When you specify the mapping in the ggplot() function, it is inherited by all subsequent layers/geoms\n\n\n ✗Mapping allows you to specify which scales (e.g. x, y, colour) should be used to display the data\n\n\n\n\n\n\n2. Which of the following lines of code is a valid way to create a scatterplot of the drug dosage (x) and weight loss (y) in the m_dose dataset?\n\n\n\n\n ✗m_dose %&gt;% ggplot(aes(x = drug_dose_g, y = weight_lost_g)) %&gt;% geom_point()\n\n\n ✗m_dose %&gt;% ggplot(x = drug_dose_g, y = weight_lost_g) + geom_point()\n\n\n ✗m_dose %&gt;% ggplot2(aes(x = drug_dose_g, y = weight_lost_g))\n\n\n ✔m_dose %&gt;% ggplot(aes(x = drug_dose_g, y = weight_lost_g)) + geom_point()\n\n\n\n\n\n\n\nHow could you programmatically save the plot created in question 2 as a .pdf file with dimensions of 10 by 15 cm?\n\n\n\n\n\n ✔ggsave(\"drug_dosage_vs_weight_loss.pdf\", width = 10, height = 15, units = \"cm\")\n\n\n ✗save(\"drug_dosage_vs_weight_loss.pdf\", width = 10, height = 15, units = \"cm\")\n\n\n ✗ggsave(\"drug_dosage_vs_weight_loss.pdf\", width = 10, height = 15)\n\n\n ✗ggsave(\"drug_dosage_vs_weight_loss.pdf\", width = 10, height = 15)\n\n\n\n\n\n\n\nSolutions\n\n\nMapping in ggplot refers to the scales that will be used to display the data (e.g. x, y, colour), not the type of plot you want to create. It is specified using the aes() function, and when specified in the initial ggplot() function call, is inherited by all subsequent layers/geoms.\nThe correct way to create a scatterplot of the drug dosage and weight loss in the m_dose dataset is m_dose %&gt;% ggplot(aes(x = drug_dose_g, y = weight_lost_g)) + geom_point(). This specifies the data and mapping in the ggplot() function call, and adds a layer of points to the plot using geom_point(). The %&gt;% operator is not used in ggplot2, and the x and y mapping should be specified within the aes() function. Also, remember that although ggplot2 is the name of the package, the function you use to initialise a plot is ggplot().\nTo programmatically save the plot created in question 2 as a .pdf file with dimensions of 10 by 15 cm, you would use the ggsave() function with the arguments ggsave(\"drug_dosage_vs_weight_loss.pdf\", width = 10, height = 15, units = \"cm\"). This specifies the filename, file type, dimensions, and units of the plot you want to save. Remember that by default, dimensions are in inches (boooo), so you need to specify the units as “cm” to save the plot with dimensions in centimetres.",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Plotting with ggplot2</span>"
    ]
  },
  {
    "objectID": "chapter_4.html#some-commonly-used-geoms",
    "href": "chapter_4.html#some-commonly-used-geoms",
    "title": "4  Plotting with ggplot2",
    "section": "4.2 Some commonly used geoms",
    "text": "4.2 Some commonly used geoms\nggplot2 has (as of writing) almost 50 different geoms that you can use to represent your data. You can see the full list in the ggplot2 documentation, but some of the most commonly used geoms include:\n\ngeom_point() for visualising individual data points\ngeom_density() and geom_histogram() for visualising the distribution of a continuous variable\ngeom_violin() and geom_boxplot() for visualising the distribution of a continuous variable across different categories\ngeom_bar() and geom_col() for making bar plots\ngeom_h/vline() for adding horizontal and vertical lines to a plot\n\nIn this section, we will briefly cover these geoms and how you might use them to visualise your data. It’s not designed to be an exhaustive list, but hopefully it will help you get started with some of the most common types of plots you might want to create.\n\n\n\n\n\n\nHow do I make a … plot in ggplot2?\n\n\n\nOften, you might come across a specific type of plot you want to make that is a bit more complex than the basic geoms we’ve covered here. If you know the name of the plot you’re wanting to make, you can often find a tutorial/guide online by googling, or you could ask an AI assistant like ChatGPT. Particularly for specific types of data (e.g. clinical data, phylogenetic data), there are often field-specific packages that provide geoms or functions to make particular types of plots, like the ggtree package for phylogenetic trees or the survminer package for survival plots.\nIf the plot doesn’t have a specifc name, you can try to break it down by thinking about the geoms you might need to use to represent the data, or try uploading a picture of a similar plot to ChatGPT.\nWhatever method you use, remember to add ‘ggplot2’ to your search query to get the most relevant results, as there are many different plotting packages in R!\n\n\n\n4.2.1 Visualising individual data points: geom_point\nAbove, we saw how to use geom_point() to create a scatterplot, but geom_point() can be used in other ways too. For example, you can use it to create a dot plot, where the x axis is categorical and the y axis is continuous:\n\n# make a dot plot of initial weight by mouse strain\nm_dose %&gt;% ggplot(aes(x = mouse_strain, y = initial_weight_g)) +\n# remember we add layers to a plot with +\n  geom_point()\n\n\n\n\n\n\n\n\nNotice how the points are stacked on top of one another for each strain. This is because the x axis is categorical, and ggplot2 doesn’t know how to spread the points out. This can make it difficult to see the individual points (known as ‘overplotting’), so when making a plot like this it’s often better to use geom_jitter():\n\n# make a jittered dot plot of initial weight by mouse strain\nm_dose %&gt;% ggplot(aes(x = mouse_strain, y = initial_weight_g)) +\n  geom_jitter()\n\n\n\n\n\n\n\n\nThe geom_jitter() adds a small amount of random noise to the x & y positions of each point, which helps to spread them out and make it easier to see the individual points. Like most functions in ggplot2, geom_jitter() will try to guess an appropriate amount of jitter to add, but you can specify the amount as well:\n\n# use less jitter so there is more distinction between the different mouse strains\nm_dose %&gt;% ggplot(aes(x = mouse_strain, y = initial_weight_g)) +\n  geom_jitter(width = 0.2, height = 0)\n\n\n\n\n\n\n\n\nThe exact amount of jitter you need will depend heavily on your data, so it’s often a good idea to experiment with different amounts to see what works best.\n\n\n\n\n\n\nBeeswarm plots\n\n\n\nAnother way to spread out points in a dot plot is to use a beeswarm plot, in which points are spread out slightly along the x axis so that they don’t overlap. The ggbeeswarm package provides a geom_beeswarm() function that you can use to create beeswarm plots in ggplot2 (rather than using geom_jitter() like we did here). For more information, see the ggbeeswarm documentation.\n\n\nBeyond just scatterplots and dot plots, geom_point() is also really useful to overlay additional data on top of other geoms. For example, you can use it to add individual data points to a boxplot or violin plot, as we will see shortly!\n\n\n4.2.2 Visualising the distribution of a continuous variable: geom_histogram / geom_density\nAs the number of data points increases, it can be difficult to see individual points. In this case, it can be useful to visualise the distribution of a continuous variable using a histogram or density plot.\nHistograms are created using the geom_histogram() function. Seeing as only a single variable is being plotted, you only need to specify the x aesthetic in the aes() function.\nFor example, let’s create a histogram of the initial weight of the mice:\n\nm_dose %&gt;% ggplot(aes(x = initial_weight_g)) +\n  geom_histogram()\n\n\n\n\n\n\n\n\nOne of the most important arguments to geom_histogram() is the bins argument, which specifies the number of bins (bars) to use for the histogram. By default, it is 30, but you might want a smaller or larger value depending on the distribution of your data. For example, let’s create a histogram with 15 bins:\n\nm_dose %&gt;% ggplot(aes(x = initial_weight_g)) +\n  geom_histogram(bins = 15)\n\n\n\n\n\n\n\n\nSimilarly to histograms, density plots are also used to visualise the distribution of a continuous variable, but they are smoothed out. To create a density plot in ggplot2, you can use the geom_density() function:\n\nm_dose %&gt;% ggplot(aes(x = initial_weight_g)) +\n  geom_density()\n\n\n\n\n\n\n\n\nNotice how the density plot is smoothed out compared to the histogram, and it is also scaled so that the area under the curve is equal to 1. This means that the y axis of a density plot represents the probability density of the data, rather than the count of data points in each bin.\n\n\n4.2.3 Visualising the distribution of a continuous variable across categories: geom_boxplot / geom_violin\nOften in biological data, you will want to visualise the distribution of a continuous variable across different categories. For example, we might want to see how the initial weight of the mice varies by strain. Two plot types that are useful for this are boxplots and violin plots.\nBoxplots allow you to easily see the median, quartiles, and any outliers in the data. To create a boxplot win ggplot2, you can use the geom_boxplot() function:\n\nm_dose %&gt;% ggplot(aes(x = mouse_strain, y = initial_weight_g)) +\n  geom_boxplot()\n\n\n\n\n\n\n\n\nIt can sometimes be nice to add points to a boxplot to show the individual data points as well as the summary statistics. You can do this by adding a geom_point() or geom_jitter() layer to the plot:\n\nm_dose %&gt;% ggplot(aes(x = mouse_strain, y = initial_weight_g)) +\n  geom_boxplot() +\n  geom_jitter(width = 0.2)\n\n\n\n\n\n\n\n\nThis plot shows the distribution of initial weight for each strain (with the boxplot), as well as the individual data points. Notice how the points are jittered to avoid overlapping, as we did earlier with the dot plot.\nHowever, when you have a lot of data points (as we do here), a boxplot with overlaid points can be a bit messy and hard to read. In this case, it might be better to use a violin plot instead, which shows the distribution of the data as a density plot:\n\nm_dose %&gt;% ggplot(aes(x = mouse_strain, y = initial_weight_g)) +\n  geom_violin()\n\n\n\n\n\n\n\n\nYou can even combine geom_violin() with geom_boxplot() to show both the distribution of the data and the summary statistics:\n\nm_dose %&gt;% ggplot(aes(x = mouse_strain, y = initial_weight_g)) +\n  geom_violin() +\n  geom_boxplot(width = 0.1)\n\n\n\n\n\n\n\n\nNotice how we specified the width argument in geom_boxplot() to make the boxplot narrower, so that it doesn’t obscure the violin plot.\n\n\n4.2.4 geom_bar / geom_col\nThe last pair of basic geoms we’ll cover are geom_bar() and geom_col(), which are used to create bar plots. These are handy for visualising categorical data, such as the number of mice in each strain or the average weight loss for each dosage.\ngeom_bar() is used to create bar plots from counts of categorical data, while geom_col() is used to create bar plots from pre-computed values. This means that if you have already calculated the counts or averages for each category, you should use geom_col() instead of geom_bar().\nFor example, if we wanted to create a bar plot of the number of mice in each strain with geom_col(), we would first need to calculate the counts for each strain:\n\n# first count the number of mice per strain\nm_counts &lt;- m_dose %&gt;%\n  group_by(mouse_strain) %&gt;%\n  summarise(count = n())\n\n# then create the bar plot\nm_counts %&gt;% ggplot(  aes(x = mouse_strain, y = count) ) +\n  geom_col()\n\n\n\n\n\n\n\n\nWhereas if we used geom_bar(), we would not need to calculate the counts first:\n\nm_dose %&gt;% ggplot(\n  aes(x = mouse_strain)) +\n  geom_bar()\n\n\n\n\n\n\n\n\nNotice how we only specified the x aesthetic in the aes() function, and geom_bar() automatically calculated the counts for each strain.\nThe advantage of using geom_bar() is that it is simpler and easier to read for plotting counts, but it can’t be used for plotting pre-computed values. For example, if you wanted to plot the average weight loss for each strain, you would need to calculate the averages first with the dplyr functions we learned in Chapter 2 and use geom_col():\n\n# first calculate the average weight loss for each strain\navg_weight_loss &lt;- m_dose %&gt;%\n  group_by(mouse_strain) %&gt;%\n  summarise(avg_weight_loss = mean(weight_lost_g))\n\n# then create the bar plot\navg_weight_loss %&gt;% ggplot( aes(x = mouse_strain, y = avg_weight_loss)) +\n  geom_col()\n\nWarning: Removed 2 rows containing missing values or values outside the scale range\n(`geom_col()`).\n\n\n\n\n\n\n\n\n\n\n\n\n4.2.5 geom_hline / geom_vline\nThe geom_hline() and geom_vline() functions are used to add horizontal and vertical lines to a plot, respectively. Although you’ll probably never use them alone, they are great to add to your plots to highlight specific values or thresholds in your data. To use them, you need to specify the yintercept (for geom_hline()) or xintercept (for geom_vline()) argument, which specifies where to draw the line.\nFor example, let’s add a horizontal line to our scatterplot of drug dosage and weight loss at the 4g mark, which might represent a clinically significant amount of weight loss:\n\nm_dose %&gt;% ggplot(aes(x = drug_dose_g, y = weight_lost_g)) +\n  geom_point() +\n  geom_hline(yintercept = 4)\n\n\n\n\n\n\n\n\nWe could also add a vertical line at the 0.0025g mark to show the theorectical maximum dosage of the drug:\n\nm_dose %&gt;% ggplot(aes(x = drug_dose_g, y = weight_lost_g)) +\n  geom_point() +\n  geom_hline(yintercept = 4) +\n  geom_vline(xintercept = 0.0025)\n\n\n\n\n\n\n\n\nNotice how adding this line extends the x axis to include 0.0025, even though there are no data points at that value. This is because, by default, ggplot2 chooses axes limits for you that include all the data and any additional layers you add to the plot.\n\n\n\n\n\n\nPractice exercises\n\n\n\nTry these practice questions to test your understanding\n\n1. Which geom could you use to create a boxplot?\n\n\n\n\n ✔geom_boxplot()\n\n\n ✗geom_box()\n\n\n ✗geom_col()\n\n\n ✗geom_violin()\n\n\n\n\n\n\n2. Which of the following lines of code is a valid way to create a violin plot of the tail length of the mice by strain, with points overlaid?\n\n\n\n\n ✗m_dose %&gt;% ggplot(aes(x = mouse_strain, y = tail_length_mm)) + geom_violin(geom_jitter(width = 0.2))\n\n\n ✗m_dose %&gt;% ggplot(aes(x = mouse_strain, y = tail_length_mm)) + geom_jitter(width = 0.2)\n\n\n ✗m_dose %&gt;% ggplot(aes(x = mouse_strain, y = tail_length_mm)) + geom_violin()\n\n\n ✔m_dose %&gt;% ggplot(aes(x = mouse_strain, y = tail_length_mm)) + geom_violin() + geom_jitter(width = 0.2)\n\n\n\n\n\n\n\nWhat does this code do?\n\n\nm_dose %&gt;% ggplot(aes(x = cage_number)) +\n  geom_bar() +\n  geom_hline(yintercept = 60)\n\n\n\n\n\n ✗Makes a box plot of the number of mice in each cage, with a horizontal line at 60.\n\n\n ✗Makes a bar plot of the number of cages in the dataset, with a horizontal line at 60.\n\n\n ✔Makes a bar plot of the number of mice in each cage, with a horizontal line at 60.\n\n\n ✗Makes a bar plot of the number of mice in each cage\n\n\n\n\n\n\n\nSolutions\n\n\nThe correct answer is geom_boxplot(). This is the function used to create boxplots in ggplot2.\nThe correct way to create a violin plot of the tail length of the mice by strain, with points overlaid, is m_dose %&gt;% ggplot(aes(x = mouse_strain, y = tail_length_mm)) + geom_violin() + geom_jitter(width = 0.2). This specifies the data and mapping in the ggplot() function call, adds a layer of violin plots using geom_violin(), and then adds a layer of points using geom_jitter() to avoid overlapping.\nThe code creates a bar plot of the number of mice in each cage, with a horizontal line at 60. The geom_bar() function counts the number of mice in each cage and plots the counts as bars, while the geom_hline() function adds a horizontal line at the y value of 60. This could be used to show a threshold e.g. for the maximum number of mice allowed in a cage.",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Plotting with ggplot2</span>"
    ]
  },
  {
    "objectID": "chapter_4.html#aesthetics-and-scales",
    "href": "chapter_4.html#aesthetics-and-scales",
    "title": "4  Plotting with ggplot2",
    "section": "4.3 Aesthetics and scales",
    "text": "4.3 Aesthetics and scales\nNow that we’ve learned some of the common geoms we can use to physically represent our data, let’s discuss the aesthetics that govern how these geoms look and the scales that map our data to these aesthetics.\n\n4.3.1 Aesthetics\nAs described earlier, aesthetics are the visual properties of the geoms that we can control, such as colour, position, size and shape. We saw how the colour aesthetic could be used in all layers of the plot to show the strain of each mouse, by specifying colour = mouse_strain in the aes() function:\n\nm_dose %&gt;% ggplot(\n  aes(x = initial_weight_g, y = tail_length_mm, colour = mouse_strain)) +\n  geom_point() +\n  geom_smooth(method = \"lm\")\n\n`geom_smooth()` using formula = 'y ~ x'\n\n\nWarning: Removed 2 rows containing non-finite outside the scale range\n(`stat_smooth()`).\n\n\nWarning: Removed 2 rows containing missing values or values outside the scale range\n(`geom_point()`).\n\n\n\n\n\n\n\n\n\nIt’s also possible to specify aesthetics for specific geoms, rather than for the whole plot. For example, let’s say we wanted to colour the points by mouse strain, but just have a single trendline for all of the data (rather than one for each strain, like we have above). We could do this by specifying the colour aesthetic in the geom_point() layer, rather than in the ggplot() function:\n\nm_dose %&gt;% ggplot(\n  aes(x = initial_weight_g, y = tail_length_mm)) +\n  geom_point(aes(colour = mouse_strain)) +\n  geom_smooth(method = \"lm\")\n\n\n\n\n\n\n\n\nThis allows us to have different aesthetics for different layers of the plot, giving us the power to create some really complex visualisations.\nDifferent geoms can accept different aesthetics. For example, let’s try using the colour aesthetic to colour a boxplot of tail length by mouse strain:\n\nm_dose %&gt;% ggplot(\n  aes(x = mouse_strain, y = tail_length_mm, colour = mouse_strain)) +\n  geom_boxplot()\n\n\n\n\n\n\n\n\nNotice how the outline of the boxplot is coloured by strain, but the fill is not. For geoms that show an area of some sort (like boxplots, histograms, violin plots or bar charts), they have both a colour aesthetic that controls the colour of the outline of the shape, and a fill aesthetic that controls the fill colour. So if we wanted the boxplot to be filled with the colour of the strain, we should use the fill aesthetic instead:\n\nm_dose %&gt;% ggplot(\n  aes(x = mouse_strain, y = tail_length_mm, fill = mouse_strain)) +\n  geom_boxplot()\n\n\n\n\n\n\n\n\nYou can see all of the aesthetics that a geom accepts by checking its help page (e.g. ?geom_boxplot) and reading the “Aesthetics” section.\n\n\n4.3.2 Combining multiple aesthetics\nNotice how in the last example, we used mapped the same variable (mouse_strain) to both the x and fill aesthetics. It’s often helpful to show the same variable through multiple aesthetics, as it can convey the information more clearly. As another example, for the scatterplot example we used earlier, we could also use the shape aesthetic to show the strain of each mouse:\n\nm_dose %&gt;% ggplot(\n  aes(x = initial_weight_g, y = tail_length_mm, colour = mouse_strain, shape = mouse_strain)) +\n  geom_point()\n\n\n\n\n\n\n\n\nNow we can see the strain of each mouse through both colour and shape, which makes it even easier to distinguish between the different strains.\nOf course, we may instead want to use aesthetics to add additional variables to our visualisation. To illustrate this, let’s make a scatterplot that visualises the initial weight and tail length of each mouse, but also shows the drug dosage, cage number and mouse strain:\n\nm_dose %&gt;% ggplot(\n  aes(x = initial_weight_g, y = tail_length_mm, size = drug_dose_g, colour = mouse_strain, shape = cage_number)) +\n  geom_point()\n\n\n\n\n\n\n\n\nLooks pretty crazy right? There’s no limit to the number of aesthetics you can use in a single plot, but it’s important to remember that the more aesthetics you add, the harder it is to interpret. Try to keep it simple and only add aesthetics that are necessary to convey key information.\n\n\n4.3.3 Scales\nScales control how particular data values/variables are mapped to aesthetics. For example, when we specify colour = mouse_strain, ggplot2 automatically chooses a colour palette to use for each strain. Scales are specified using the scale_* functions, where * is the name of the aesthetic you want to control (e.g. scale_colour, scale_size, etc.) and the arguments control how data will be visually represented e.g. the colour palette used for the colour aesthetic, or the range of size of the points for the size aesthetic. You add scale functions to your plot using the + operator, just like you do with geoms.\n\n4.3.3.1 Colours\nOne thing you’ll often want to do is change the colour palette. You can do this manually, using either the scale_colour_manual() function (for categorical variables) or the scale_colour_gradient() function (for continuous variables). For example, if we wanted to use a different colour palette for the mouse strains in our scatterplot, we would use scale_colour_manual() as follows:\n\nm_dose %&gt;% ggplot(\n  aes(x = initial_weight_g, y = tail_length_mm, colour = mouse_strain)) +\n  geom_point() +\n  scale_colour_manual(values = c(\"red\", \"blue\", \"green\"))\n\n\n\n\n\n\n\n\nWhen using scale_colour_manual(), you need to provide to the values argument a vector of colours that matches the number of levels in the variable you’re mapping to colour. In the example above, we have three mouse strains, so we need to provide three colours in the values argument.\nR has a range of built-in colours that you can use, such as “red”, “blue”, “green”, etc., but you can also use hex codes to specify colours:\n\nm_dose %&gt;% ggplot(\n       aes(x = initial_weight_g, y = tail_length_mm, colour = mouse_strain)) +\n  geom_point() +\n  scale_colour_manual(values = c(\"#f45c2e\", \"#912247\", \"#039f22\"))\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nColour highlighting in RStudio\n\n\n\nTo help you see the colours you’re using, RStudio will highlight the colour names and hex codes when you type them in your R script panel:\n\n\n\nRStudio colour highlighting\n\n\nIf it doesn’t do this automatically, you can turn it on by going to Tools &gt; Global Options &gt; Code &gt; Display and checking the “Enable preview of named and hexadecimal colours” option.\n\n\nSo far, we’ve only used colour to visualise categorical variables, but it can also be used to visualise continuous variables. As an example, let’s colour each point in our scatterplot of initial weight and tail length by the drug dosage:\n\nm_dose %&gt;% ggplot(\n  aes(x = initial_weight_g, y = tail_length_mm, colour = drug_dose_g)) +\n  geom_point()\n\n\n\n\n\n\n\n\nThe points are now coloured based on the drug dosage, using a default gradient of blue colours. You can change the colour of the gradient using the scale_colour_gradient() function, which allows you to specify the colours to use for the low and high ends of the gradient:\n\nm_dose %&gt;% ggplot(\n  aes(x = initial_weight_g, y = tail_length_mm, colour = drug_dose_g)) +\n  geom_point() +\n  scale_colour_gradient(low = \"yellow\", high = \"red\")\n\n\n\n\n\n\n\n\nWe now have a gradient from yellow to red.\nInstead of specifying colours manually, there are also a range of pre-defined colour palettes you can use, such as scale_colour_brewer() or scale_colour_viridis(). Check out their help pages to learn more about them, or try the paleteer package for a huge range of other pre-defined colour palettes.\n\n\n4.3.3.2 The x and y axes\nScales are also used to control the x and y axes. In particular, it can be handy to specify the limits of the axes, or to apply some sort of transformation to the data.\nBy default, ggplot2 will automatically choose the limits of the x and y axes based on the data you provide. For example, look at the scatterplots of initial weight and tail length we created earlier, and you’ll see that the origin (0,0) is not shown because there are no data points near there. If we wanted to, we could change the limits of the axes using the xlim() and ylim() functions to include the origin:\n\nm_dose %&gt;% ggplot(aes(x = initial_weight_g, y = tail_length_mm)) +\n  geom_point() +\n  # specify axis limits like xlim(min, max)\n  xlim(0, 60) +\n  # if we want to use the automatic limit, use NA instead of a max value\n  ylim(0, NA)\n\n\n\n\n\n\n\n\nNotice how different this makes the plot look! Choosing appropriate axis limits is important for accurately conveying the data, so it’s worth spending some time thinking about what limits to use.\nBy default, ggplot2 uses a linear scale for both axes, but you can change this to a logarithmic scale using the scale_x_log10() or scale_y_log10() functions. This is useful when you have data that spans several orders of magnitude.\nWe don’t have anything like this in our m_dose dataset, so let’s use the diamonds dataset that comes with ggplot2 to demonstrate this. The diamonds dataset contains information about the price and carat weight of diamonds, both of which are continuous variables that span several orders of magnitude. Let’s create a scatterplot of the price and carat of the diamonds:\n\ndiamonds %&gt;% ggplot( aes(y = price, x = carat)) +\n  geom_point()\n\n\n\n\n\n\n\n\nTo linearise this relationship, we can apply a log10 transformation to the x and y axes using the scale_x_log10() and scale_y_log10() functions:\n\ndiamonds %&gt;% ggplot( aes(y = price, x = carat)) +\n  geom_point()+\n  scale_x_log10() +\n  scale_y_log10()\n\n\n\n\n\n\n\n\nNotice how the points are now more evenly distributed across the plot, and we can see the relationship between carat and price more clearly.\n\n\n\n4.3.4 Positions\nPositions aren’t really an aesthetic, but they are a way to control how geoms are displayed, particularly when parts of that geom overlap. For example, when we are using geom_bar() to create a bar plot that is coloured by a categorical variable, the bars will be stacked on top of each other by default. Let’s illustrate this by creating a bar plot of the number of mice in each strain, coloured by the sex of the mouse:\n\nm_dose %&gt;% ggplot(\n  aes(x = mouse_strain, fill = sex)) +\n  geom_bar()\n\n\n\n\n\n\n\n\nHaving the bars stacked up is useful when you want to see the total count for each strain, but it can make it difficult to see the individual counts for sex. Instead, we can use the position = \"dodge\" argument in geom_bar() to place the bars side by side:\n\nm_dose %&gt;% ggplot(\n  aes(x = mouse_strain, fill = sex)) +\n  geom_bar(position = \"dodge\")\n\n\n\n\n\n\n\n\nNotice how there is now a bar for each sex in each strain, and it’s easier to examine the sex distribution of each strain (but equally harder to appreciate the total number of mice in each strain!). There’s no right or wrong way to lay out the bars, but it’s worth trying both and seeing which one works best for the message you want to convey.\n\n\n\n\n\n\nPractice exercises\n\n\n\nTry these practice questions to test your understanding\n\n1. What kind of plot would the following code make?\n\nm_dose %&gt;% ggplot(\n  aes(x = mouse_strain, y = tail_length_mm)) +\n  geom_violin() +\n  geom_jitter(aes(colour = mouse_strain), width = 0.3)\n\n\n\n\n\n ✗A violin plot of tail length by mouse strain, with points overlaid\n\n\n ✗A violin plot of tail length by mouse strain, with points overlaid. The points are jittered to avoid overlapping. The points and the violin plots are both coloured by mouse strain.\n\n\n ✗A dot plot of tail length by mouse strain. The points are jittered to avoid overlapping and are coloured by mouse strain.\n\n\n ✔A violin plot of tail length by mouse strain, with points overlaid. The points are jittered to avoid overlapping and are coloured by mouse strain. The violin plot is not coloured.\n\n\n\n\n\n\n2. I would like to make a scatterplot of initial weight and tail length, but I also want to show the weight lost by each mouse using colour with the viridis palette. Which of the following lines of code would do this?\nHint: You can use the scale_colour_viridis_c() function to apply the viridis colour palette to a continuous variable.\n\n\n\n\n ✔m_dose %&gt;% ggplot(aes(x = initial_weight_g, y = tail_length_mm, colour = weight_lost_g)) + geom_point() + scale_colour_viridis_c()\n\n\n ✗m_dose %&gt;% ggplot(aes(x = initial_weight_g, y = tail_length_mm, colour = weight_lost_g)) + geom_point()\n\n\n ✗m_dose %&gt;% ggplot(aes(x = initial_weight_g, y = tail_length_mm, colour = weight_lost_g)) + scale_colour_viridis_c()\n\n\n ✗m_dose %&gt;% ggplot(aes(x = initial_weight_g, y = tail_length_mm, colour = weight_lost_g)) + geom_point(scale_colour_viridis_c())\n\n\n\n\n\n\n3. How can I make a histogram of the tail length of the mice, with 10 bins and coloured by mouse strain, with the different strains side by side?\n\n\n\n\n ✗m_dose %&gt;% ggplot(aes(x = tail_length_mm, fill = mouse_strain)) + geom_histogram(bins = 10)\n\n\n ✔m_dose %&gt;% ggplot(aes(x = tail_length_mm, fill = mouse_strain)) + geom_histogram(bins = 10, position = \"dodge\")\n\n\n ✗m_dose %&gt;% ggplot(aes(x = tail_length_mm, fill = mouse_strain)) + geom_histogram(bins = 10, position = \"stack\")\n\n\n ✗m_dose %&gt;% ggplot(aes(x = tail_length_mm)) + geom_histogram(bins = 10)\n\n\n\n\n\n\n\nSolutions\n\n\nThe correct answer is “A violin plot of tail length by mouse strain, with points overlaid. The points are jittered to avoid overlapping and are coloured by mouse strain. The violin plot is not coloured.” Note that because we specified the aes(colour = mouse_strain) argument within geom_jitter() and not in the ggplot() function, only the points will be coloured by mouse strain, while the violin plot will not be coloured.\nThe correct answer is m_dose %&gt;% ggplot(aes(x = initial_weight_g, y = tail_length_mm, colour = weight_lost_g)) + geom_point() + scale_colour_viridis_c(). This code creates a scatterplot of initial weight and tail length, with the points coloured by weight lost using the viridis colour palette. Remember that we add scales to the plot using the + operator, just like we do with geoms, and that we need to specify the colour aesthetic in the aes() function to map the weight lost to colour.\nThe correct answer is m_dose %&gt;% ggplot(aes(x = tail_length_mm, fill = mouse_strain)) + geom_histogram(bins = 10, position = \"dodge\"). Remember that the position = \"dodge\" argument in geom_histogram() specifies that the bars should be placed side by side rather than stacked on top of each other (the default behaviour). Also note that histograms, like bar plots, use the fill aesthetic to colour the entire bars (the colour aesthetic is only used to colour the outline of the bars).",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Plotting with ggplot2</span>"
    ]
  },
  {
    "objectID": "chapter_4.html#making-a-plot-pretty",
    "href": "chapter_4.html#making-a-plot-pretty",
    "title": "4  Plotting with ggplot2",
    "section": "4.4 Making a plot pretty",
    "text": "4.4 Making a plot pretty\nNow that we’ve covered the basics of creating plots in ggplot2, let’s talk about how to make them look good! Of course there are countless ways to customise the appearance of a plot in ggplot2. We’ll cover a few of the most common ones here to give you a starting point, but if you’re wanting to do something specific, you can often find a solution online, by using AI or by reading the ggplot2 documentation.\n\n4.4.1 Labels and text\nOne thing you’ll want to do is add labels to your plot, such as a title, axis labels and/or a caption. You can do this quickly and easily with the labs() function. For example, let’s add labels to our scatterplot:\n\nm_dose %&gt;% ggplot(\n  aes(x = initial_weight_g, y = tail_length_mm)) +\n  geom_point() +\n  # add labels to the plot\n  labs(title = \"Initial weight vs tail length\",\n       x = \"Initial weight (g)\",\n       y = \"Tail length (mm)\",\n       caption = \"Data from the m_dose dataset\")\n\n\n\n\n\n\n\n\nYou don’t need to specify all of these labels (just omit the ones you don’t want).\nIt’s also possible to change the way that the axes are labelled. You can do this by adding the labels argument to the appropriate x or y scale functions. For example, if we made the following plot of drug dosage and weight loss:\n\nm_dose %&gt;% ggplot(\n  aes(x = drug_dose_g, y = weight_lost_g)) +\n  geom_point()\n\n\n\n\n\n\n\n\nWe could use the scale_x_continuous() function to label the x axis in scientific notation:\n\nm_dose %&gt;% ggplot(\n  aes(x = drug_dose_g, y = weight_lost_g)) +\n  geom_point() +\n  scale_x_continuous(labels = scales::label_scientific()) +\n  labs(\n    title = \"Relationship between drug dosage and weight loss\",\n    x = \"Drug dosage (g)\",\n    y = \"Weight lost (g)\")\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nAccessing functions using ::\n\n\n\nYou may have noticed that we used scales::label_scientific() to access the label_scientific() function. This is because we haven’t loaded scales package (i.e. we haven’t run library(scales)), so we need to specify the package name to access the function. You can do this for any function in R by using the package::function() syntax.\nThis is useful when you only need one function from a package, although if you need to use a lot of different functions (like we do with the tidyverse packages in this course), it’s easier to load the package with library() instead.\n\n\nThere are a range of other functions you can use to label the axes, beyond just scales::label_scientific(). One that is particularly handy is scales::label_comma() which adds commas to large numbers (rather than using scientific notation, e.g. 1,000,000 instead of 1e6) so that they are easier to read. You can check out the full list of label functions in the ggplot2 book.\n\n\n4.4.2 Themes\nThemes are a way to control the non-data appearance of a plot (e.g. font, background colour, grid lines, etc.)\nThere are a number of pre-set theme functions in ggplot2, such as theme_bw(), theme_minimal() and theme_classic(). You can add these to your plot with the + operator to quickly change its appearance. For example, let’s use the theme_minimal() function to create a scatterplot with a simple white background:\n\nm_dose %&gt;% ggplot(\n  aes(x = initial_weight_g, y = tail_length_mm)) +\n  geom_point() +\n  theme_minimal()\n\n\n\n\n\n\n\n\nOne common edit you might want to make to a theme is to change the font size, so that the text is easier to read. You can do this by setting the base_size argument in the theme_*() function. For example, let’s increase the font size in our previous plot to 16 points:\n\nm_dose %&gt;% ggplot(\n  aes(x = initial_weight_g, y = tail_length_mm)) +\n  geom_point() +\n  theme_minimal(base_size = 16)\n\n\n\n\n\n\n\n\nTo modify other parts of the theme, you can use the theme() function to specify the elements you want to change. Make sure you put the theme() function after your theme preset, if any (e.g. theme_minimal()) as it will override the default settings.\nThere are more than 40 different plot elements you can modify using the theme() function, such as axis.text, axis.title, plot.title, legend.position, etc. It’s impossible to remember them all, so you can refer to the ggplot2 documentation, search online or ask ChatGPT.\nIn general though, to set the value of a plot element, you need to know its name, and the name of the function that sets it. Usually this will be element_text() (for text), element_line() (for lines) or element_rect() (for rectangles). As an example, let’s change the colour of our plot title to red, make it bold size 20 and change the plot background colour to pink:\n\nm_dose %&gt;% ggplot(\n  aes(x = initial_weight_g, y = tail_length_mm)) +\n  geom_point() +\n  # add a title to the plot\n  labs(title = \"Relationship between initial weight & tail length\") +\n  theme_minimal() +\n  # place the theme function after the theme preset\n  theme(\n    # use setting functions like element_text() to set the value of a plot element\n    plot.title = element_text(colour = \"red\", face = \"bold\", size = 20),\n    plot.background = element_rect(fill = \"pink\")\n  )\n\n\n\n\n\n\n\n\nIf your plot has a legend, you can also modify its appearance using the theme() function. For example, in our colour-coded scatterplot of tail length and initial weight, let’s move it to the bottom of the plot:\n\nm_dose %&gt;% ggplot(\n  aes(x = initial_weight_g, y = tail_length_mm, colour = mouse_strain)) +\n  geom_point() +\n  labs(title = \"Initial weight vs tail length\",\n       x = \"Initial weight (g)\",\n       y = \"Tail length (mm)\",\n       colour = \"Mouse strain\") +\n  theme_minimal() +\n  theme(legend.position = \"bottom\")\n\n\n\n\n\n\n\n\nYou can remove the legend altogether by setting legend.position = \"none\" in the theme() function. This is useful when you have a lot of data points and the legend takes up too much space, or when the legend is not needed to interpret the plot.\n\nm_dose %&gt;% ggplot(\n  aes(x = initial_weight_g, y = tail_length_mm, colour = mouse_strain)) +\n  geom_point() +\n  labs(title = \"Initial weight vs tail length\",\n       x = \"Initial weight (g)\",\n       y = \"Tail length (mm)\",\n       colour = \"Mouse strain\") +\n  theme_minimal() +\n  theme(legend.position = \"none\")\n\n\n\n\n\n\n\n\n\n\n4.4.3 Changing colours/sizes/shapes\nEarlier, we saw how to map variables in our data to aesthetics like colour, size and shape. But you can also set these aesthetics manually to make the plot prettier, rather than to show something about the data. For example, if we wanted to make all the points in our scatterplot violet, we could do this by setting the colour aesthetic directly in the geom_point() layer, rather than in the aes() function:\n\nm_dose %&gt;% ggplot(\n  aes(x = initial_weight_g, y = tail_length_mm)) +\n  geom_point(colour = \"violet\")\n\n\n\n\n\n\n\n\nThis will make all the points violet, regardless of the strain of the mouse. You can do this for any aesthetic, such as size or shape. For example, let’s make all the points in our scatterplot size 3 and shape 17:\n\nm_dose %&gt;% ggplot(\n  aes(x = initial_weight_g, y = tail_length_mm)) +\n  geom_point(size = 3, shape = 17, colour = \"violet\")\n\n\n\n\n\n\n\n\nNow, all of our plots have changed to violet triangles! You can see the full list of point shapes here to help you customise your plot.\n\n\n\n\n\n\nPractice exercises\n\n\n\n\n1. I’ve made the following plot:\n\nm_dose %&gt;% ggplot(\n  aes(x = cage_number, y = weight_lost_g, fill = mouse_strain)) +\n  geom_violin()\n\nWarning: Removed 2 rows containing non-finite outside the scale range\n(`stat_ydensity()`).\n\n\n\n\n\n\n\n\n\nWhich of the following could I use to add labels to the plot?\n\n\n\n\n ✔labs(title = \"Weight lost by cage number and mouse strain\", x = \"Cage number\", y = \"Weight lost (g)\")\n\n\n ✗labels(title = \"Weight lost by cage number and mouse strain\", x = \"Cage number\", y = \"Weight lost (g)\")\n\n\n ✗labels(title = \"Weight lost\", x = \"Cage number\", y = \"Weight lost (g)\")\n\n\n ✗labels(x = \"Cage number\", y = \"Weight lost (g)\")\n\n\n\n\n\n\n2. I’m trying to change move my plot legend to the top and change the font of my title to bold, but it’s not working. What am I doing wrong?\n\nm_dose %&gt;% ggplot(\n  aes(x = initial_weight_g, y = tail_length_mm, colour = mouse_strain)) +\n  geom_point() +\n  labs(title = \"Initial weight vs tail length\",\n       x = \"Initial weight (g)\",\n       y = \"Tail length (mm)\",\n       colour = \"Mouse strain\") +\n  theme(legend.position = \"top\", plot.title = element_text(face = \"bold\")) +\n  theme_bw()\n\nWarning: Removed 2 rows containing missing values or values outside the scale range\n(`geom_point()`).\n\n\n\n\n\n\n\n\n\n\n\n\n\n ✗You need to use the pipe operator to combine the two theme() functions\n\n\n ✗You can’t use the theme_bw() function and the theme() function in the same plot\n\n\n ✗You need to specify the legend.position and plot.title arguments in the theme_bw() function, not the theme() function.\n\n\n ✔You need to put the theme() function after the theme_bw() function, because currently the theme_bw() function is overriding the theme() function.\n\n\n\n\n\n\n3. I have the following code to make a boxplot of the initial weight of the mice by strain:\n\nm_dose %&gt;% ggplot(\n  aes(x = mouse_strain, y = initial_weight_g)) +\n  geom_boxplot()\n\nWarning: Removed 2 rows containing non-finite outside the scale range\n(`stat_boxplot()`).\n\n\n\n\n\n\n\n\n\nHow can I add points over the top of the boxplot, that are jittered to avoid overlap, size 0.5 and square shaped? Hint: find the shape number for squares here.\n\n\n\n\n ✗Add geom_jitter(width = 0.2) to the plot code above with the + operator and specify the size and shape in the aes() function\n\n\n ✔Add geom_jitter(size = 0.5, shape = 15, width = 0.2) to the plot code above with the + operator\n\n\n ✗It’s not possible to add points to a boxplot\n\n\n ✗Add geom_point() to the plot code above with the + operator\n\n\n\n\n\n\n\nSolutions\n\n\n\nThe correct answer is labs(title = \"Weight lost by cage number and mouse strain\", x = \"Cage number\", y = \"Weight lost (g)\"). This will add a title and axis labels to the plot. The labels() function does not exist in ggplot2, so the second option is incorrect. The third and fourth options are also incorrect because they do not include an title informative title.\nThe correct answer is “You need to put the theme() function after the theme_bw() function, because currently the theme_bw() function is overriding the theme() function.” The theme_bw() function sets the default theme for the plot, so if you want to modify it, you need to put the theme() function after it. The other options are incorrect because you can use the theme() function and the theme_bw() function together, and you don’t need to specify the legend.position and plot.title arguments in the theme_bw() function. You always use + when adding a new layer to a plot, so you don’t need to use the pipe operator.\nThe correct answer is “Add geom_jitter(size = 0.5, shape = 15, width = 0.2) to the plot code above with the + operator.” This will add points to the boxplot that are size 0.5 and square shaped. The first option is incorrect because you need to specify the size and shape in the geom_point() function, not in the aes() function (as the size and shape here don’t represent anything in the data, they are just used to style the plot). The third option is incorrect because it is possible to add points to a boxplot, and the fourth option is incorrect because it does not specify the size or shape of the points, or the jitter.",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Plotting with ggplot2</span>"
    ]
  },
  {
    "objectID": "chapter_4.html#making-many-similar-plots-with-facets",
    "href": "chapter_4.html#making-many-similar-plots-with-facets",
    "title": "4  Plotting with ggplot2",
    "section": "4.5 Making many similar plots with facets",
    "text": "4.5 Making many similar plots with facets\nFaceting is a powerful way to create multiple plots that each show subsets of your data. This is useful when you want to compare different groups or categories.\nBefore, we saw how to do this by using aesthetics such as colour to distinguish between groups. For example, let’s consider the relationship between weight lost and drug dosage in our m_dose dataset. We could use what we’ve learned so far to create a scatterplot of weight lost vs drug dosage, and colour the points by mouse strain:\n\nm_dose %&gt;% ggplot(\n  aes(x = drug_dose_g, y = weight_lost_g, colour = mouse_strain)) +\n  geom_point() +\n  labs(title = \"Weight lost vs drug dosage for each mouse strain\",\n       x = \"Drug dosage (g)\",\n       y = \"Weight lost (g)\")\n\n\n\n\n\n\n\n\nNotice how the points for the CD-1 and BALB/c strains are sitting pretty much on top of each other. This makes it difficult to see the differences between the strains, so it might be better to create separate plots for each strain. This is where faceting comes in!\nWhen we want to facet our data by a single variable, we can use the facet_wrap() function. This will create a series of plots, with each plot showing a different subset of the data according to that variable.\nLet’s repeat our previous plot, but this time we’ll facet it by mouse strain:\n\nm_dose %&gt;% ggplot(\n  aes(x = drug_dose_g, y = weight_lost_g)) +\n  geom_point() +\n  labs(title = \"Weight lost vs drug dosage for each mouse strain\",\n       x = \"Drug dosage (g)\",\n       y = \"Weight lost (g)\") +\n  # facet the plot by mouse strain\n  facet_wrap(~ mouse_strain)\n\n\n\n\n\n\n\n\nYou use the facet_wrap() function by specifying the variable you want to facet by with a ~.\nBy default, all of the facets will have the same x and y axis limits, which is useful when you want to compare the data across all of them. However, if you want to allow each facet to have its own x and y axis limits, you can set the scales argument to \"free\":\n\nm_dose %&gt;% ggplot(\n  aes(x = drug_dose_g, y = weight_lost_g)) +\n  geom_point() +\n  labs(title = \"Weight lost vs drug dosage for each mouse strain\",\n       x = \"Drug dosage (g)\",\n       y = \"Weight lost (g)\") +\n  # facet the plot by mouse strain\n  facet_wrap(~ mouse_strain, scales = \"free\")\n\n\n\n\n\n\n\n\nThis makes it easier to see patterns within each strain, but it makes it harder to compare the strains to each other. So it’s a trade-off between clarity and comparability.\nTwo other useful arguments to facet_wrap() are nrow and ncol, which allow you to specify the number of rows or columns to use for the facets. For example, if we wanted our three facets to be arranged in a single column, we could set ncol = 1:\n\nm_dose %&gt;% ggplot(\n  aes(x = drug_dose_g, y = weight_lost_g)) +\n  geom_point() +\n  labs(title = \"Weight lost vs drug dosage for each mouse strain\",\n       x = \"Drug dosage (g)\",\n       y = \"Weight lost (g)\") +\n  # facet the plot by mouse strain\n  facet_wrap(~ mouse_strain, ncol = 1)\n\n\n\n\n\n\n\n\nPlay around with different layouts to see what works best for your data!\nIt’s also possible to facet by two variables, using the facet_grid() function. In this case, you need to specify the two column names to facet by, separated by a ~. For example, if we wanted to facet our previous plot by both mouse strain and cage number, we could do this:\n\nm_dose %&gt;% ggplot(\n  aes(x = drug_dose_g, y = weight_lost_g)) +\n  geom_point() +\n  labs(title = \"Weight lost vs drug dosage for each mouse strain\",\n       x = \"Drug dosage (g)\",\n       y = \"Weight lost (g)\") +\n  # facet the plot by mouse strain and cage number\n  facet_grid(mouse_strain ~ cage_number)\n\n\n\n\n\n\n\n\nThere is now a separate plot for each combination of mouse strain and cage number. Notice how some of the plots are empty, because there are no data points for that combination of mouse strain and cage number.\n\n\n\n\n\n\nPractice exercises\n\n\n\nTry these practice questions to test your understanding\n\n1. Using the mtcars dataset, create a scatterplot of mpg vs hp, faceted by cyl, with the same x and y axes across each facet.\n\n\n\n\n ✗mtcars %&gt;% ggplot( aes(x = hp, y = mpg)) + geom_point() + facet_wrap(hp ~ mpg)\n\n\n ✔mtcars %&gt;% ggplot( aes(x = hp, y = mpg)) + geom_point() + facet_wrap(~ cyl)\n\n\n ✗mtcars %&gt;% ggplot( aes(x = hp, y = mpg)) + geom_point() + facet_wrap(~ hp)\n\n\n ✗mtcars %&gt;% ggplot( aes(x = hp, y = mpg)) + geom_point() + facet_grid(~ cyl)\n\n\n\n\n\n\n2. What does the following code do?\n\nm_dose %&gt;% ggplot( aes(x = tail_length_mm)) +\n  geom_boxplot() +\n  facet_grid(mouse_strain ~ sex, scales = \"free\")\n\n\n\n\n\n ✗Creates a scatterplot of the tail length for each unique combination of ‘sex’ and ‘mouse strain’, with the y axis limits set independently for each facet.\n\n\n ✗Creates a boxplot of the tail length for each unique combination of ‘sex’ and ‘mouse strain’.\n\n\n ✗Creates boxplots of the tail length of mice, in mm.\n\n\n ✔Creates a boxplot of the tail length for each unique combination of ‘sex’ and ‘mouse strain’, with the y axis limits set independently for each facet.\n\n\n\n\n\n\n\nSolutions\n\n\n\nThe correct answer is mtcars %&gt;% ggplot( aes(x = hp, y = mpg)) + geom_point() + facet_wrap(~ cyl). This code creates a scatterplot of mpg vs hp, faceted by cyl, with the same x and y axes across each facet. The other options are incorrect because they either use the wrong variable to facet by or use the wrong function to create the facets (since we are faceting by a single variable, we should use facet_wrap()).\nThis code creates a boxplot of the tail length for each unique combination of ‘sex’ and ‘mouse strain’, with the y axis limits set independently for each facet (with the scales = \"free\" argument).",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Plotting with ggplot2</span>"
    ]
  },
  {
    "objectID": "chapter_4.html#laying-out-multiple-plots-into-a-single-figure",
    "href": "chapter_4.html#laying-out-multiple-plots-into-a-single-figure",
    "title": "4  Plotting with ggplot2",
    "section": "4.6 Laying out multiple plots into a single figure",
    "text": "4.6 Laying out multiple plots into a single figure\nFaceting is a great way to create multiple versions of the same plot, but sometimes you want to create completely different plots and lay them out together. For example, let’s say we are interested in the tail length variable from our m_dose dataset. We might want to create a scatterplot of initial weight vs tail length, and a boxplot of tail length by cage number, and lay them out together.\nWe can do this using the patchwork package, which allows you to combine multiple ggplot2 plots into a single figure. To use it, you first need to load the package:\n\n# if you get an error saying that the package is not installed, uncomment and then run the following line to install it\n#install.packages(\"patchwork\")\n\n# otherwise just load the package\nlibrary(patchwork)\n\nThe patchwork package changes the way that the + operator works, so that it can be used to combine multiple plots together, as well as to add layers to plots like we’ve seen so far. To use it, you just create your plots as normal, but assign them to variables. Then, you can use the + operator to combine them.\nReturning to the example above, we can create our plots and assign them to variables. We’ll also use this as an opportunity to revise some of the things we’ve learned so far, such as adding labels and changing the theme:\n\ntail_cage_boxplot &lt;- m_dose %&gt;% ggplot(\n  aes(x = cage_number, y = tail_length_mm, fill = cage_number)) +\n  geom_boxplot() +\n  # add labels\n  labs(title = \"Tail length by cage number\",\n       x = \"Cage number\",\n       y = \"Tail length (mm)\") +\n  # change the theme\n  theme_minimal() +\n  # remove the legend, because we will use the same colour for the points and the plot, don't need both legends\n  theme(legend.position = \"none\")\n\ntail_weight_scatterplot &lt;- m_dose %&gt;% ggplot(\n  aes(x = initial_weight_g, y = tail_length_mm, colour = cage_number)) +\n  geom_point(size = 2) +\n  labs(title = \"Initial weight vs tail length\",\n       x = \"Initial weight (g)\",\n       y = \"Tail length (mm)\") +\n  theme_minimal()\n\nNotice how there is no output from these lines of code, because we are not printing the plots to the console (just assigning them).\nNow, we can use the + operator to combine the two plots together into a single figure:\n\ntail_cage_boxplot + tail_weight_scatterplot\n\n\n\n\n\n\n\n\nThis will create a single figure with the boxplot on the left and the scatterplot on the right (following the order in which we specified them).\nIf we want to stack our plots on top of eachother in a column, we can use the \\ operator. For example:\n\n# put the boxplot on top of the scatterplot\ntail_cage_boxplot / tail_weight_scatterplot\n\n\n\n\n\n\n\n\nThe patchwork package has several other ways to lay out plots, particularly for more complex layouts. For more information, check out the patchwork documentation.\nAnother useful feature of the patchwork package is that you can add annotations to your plots, such ‘A’ or ‘B’ to indicate which plot is which. You can do this using the plot_annotation() function, with the tag_levels = \"A\" argument. We can add this to the plot with the + operator, just like we do with layers in a singular ggplot.\nFor example, if we wanted to identify our two plots as ‘A’ and ‘B’:\n\ntail_cage_boxplot + tail_weight_scatterplot +\n  plot_annotation(tag_levels = \"A\")\n\nThis allows you to make entire figures within R!\nOnce you’ve decided on your layout and added your annotations, you probably want to save it to a file. You can do this using the ggsave() function, just like you would for a single plot:\n\ncombined_plot &lt;- tail_cage_boxplot + tail_weight_scatterplot\n\nggsave(\"combined_plot.png\", plot = combined_plot, width = 10, height = 5)\n\nWarning: Removed 2 rows containing non-finite outside the scale range\n(`stat_boxplot()`).\n\n\nWarning: Removed 2 rows containing missing values or values outside the scale range\n(`geom_point()`).\n\n\n\n\n\n\n\n\nPractice exercises\n\n\n\nTry this practice question to test your understanding!\n1. Using the mtcars dataset, create a scatterplot of mpg vs hp, and a boxplot of mpg by cyl, and lay them out together in a single figure. Add labels to each plot and remove the legend from the boxplot. Use your creativity to make the plots look nice!\n\n\nSolution\n\nFirst, we create the scatterplot and boxplot, remembering to assign them to variables:\n\nmpg_hp_scatterplot &lt;- mtcars %&gt;% ggplot(\n  aes(x = hp, y = mpg)) +\n  geom_point(colour = \"purple\") +\n  # to know what the column names are, I looked at the\n  # help page for the mtcars dataset by running ?mtcars\n  labs(title = \"MPG vs HP\",\n       x = \"Horsepower (hp)\",\n       y = \"Miles per gallon (mpg)\") +\n  theme_minimal()\n\nmpg_cyl_boxplot &lt;-  mtcars %&gt;% ggplot(\n  # change the cyl column to a character variable\n  # because even though it's a number, it represents a category\n  aes(x = as.character(cyl), y = mpg, colour = as.character(cyl))) +\n  # use lwd = 1.5 to make the line thicker so it's easier to see\n  geom_boxplot(lwd = 1.5) +\n  labs(title = \"MPG by number of cylinders\",\n       x = \"Number of cylinders\",\n       y = \"Miles per gallon (mpg)\") +\n  # use the viridis colour palette for the boxplot\n  # note it's scale_colour_viridis_d() because this is discrete data\n  scale_colour_viridis_d() +\n  theme_minimal() +\n  theme(legend.position = \"none\")\n\nThen, we combine the two plots together with the + operator. To add the labels, we can use the plot_annotation() function:\n\nmpg_hp_scatterplot + mpg_cyl_boxplot +\n  plot_annotation(tag_levels = \"A\")\n\n\n\n\n\n\n\n\nOf course, your plots might look quite different, depending on how you choose to style them. The important thing is that you create a scatterplot of mpg vs hp, and a boxplot of mpg by cyl, and lay them out together in a single figure.",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Plotting with ggplot2</span>"
    ]
  },
  {
    "objectID": "chapter_4.html#summary",
    "href": "chapter_4.html#summary",
    "title": "4  Plotting with ggplot2",
    "section": "4.7 Summary",
    "text": "4.7 Summary\nToday, we’ve covered a lot of ground in ggplot2! Here’s a quick summary of what we’ve learned:\n\nHow to use the tibble %&gt;% ggplot(aes(x = ..., y = ...)) framework to initialise a plot\nThat we can add layers to a plot using the + operator\nHow to use the geom_*() functions to add different physical representations of the data to your plot (e.g. points with geom_point(), bars with geom_bar(), etc.)\nHow to save a plot to a file using the ggsave() function, or through the RStudio plot window\nUsing the aes() function to map variables in your data to aesthetics like colour, x/y position, size and shape, as well as the different scale_*() functions that can change the appearance of these aesthetics\nWays we can change the appearance of a plot with pre-set themes (e.g. theme_bw(), theme_minimal(), etc.), using the theme() function and adding labels with the labs() function\nThat we can use the facet_wrap() and facet_grid() functions to create multiple plots that show different subsets of the data according to particular categorical variable(s)\nHow to use the patchwork package to combine multiple plots into a single figure with operators like + and /\n\nThese are just the basics of ggplot2, and there are many more features and functions that you can use to create beautiful and informative plots. If you’re interested in learning more, check out the ggplot2 book, the R graph gallery or explore some of the many packages that extend ggplot2, like ggbeeswarm for making beeswarm plots or ggrepel to label plots without the text overlapping.\n\n4.7.1 Practice questions\nTry these practice questions to test your understanding!\n\nLook at the following ggplot2 code and try to describe in words what type of plot it will make. If you’re not sure, try looking up the help pages for the functions!\n\n\n\n\n\nm_dose %&gt;% ggplot(\n  aes(x = cage_number, y = weight_lost_g)) +\n  geom_boxplot(aes(fill = sex), width = 0.5) +\n  geom_hline(yintercept = 4, linetype = \"dashed\") +\n  theme_minimal() +\n  theme(legend.position = \"bottom\")\n\n\n\n\n\nm_dose %&gt;% ggplot(\n  aes(x = initial_weight_g, y = weight_lost_g)) +\n  geom_point(aes(colour = drug_dose_g)) +\n  geom_smooth(method = \"lm\", se = FALSE, colour = \"black\") +\n  scale_colour_viridis_c() +\n  theme_minimal()\n\n\nWrite some ggplot2 code that will create:\n\n\nA violin plot with points overlaid of drug dosage for each of the mouse strains. The violins should be coloured by mouse strain, and the points should be jittered to avoid overlap.\nA histogram of the weight lost, faceted into separate plots for each combination of sex and mouse strain. Each histogram should be coloured pink, and should have 15 bins.\n\nTry to make them look as nice as possible, using the techniques we’ve learned in this chapter.\n\nI’ve written the following code to create a scatterplot of initial weight vs tail length, with points coloured by weight lost. However, I’m getting an error. What’s wrong?\n\n\nm_dose %&gt;% ggplot(\n  aes(x = initial_weight_g, y = tail_length_mm)) +\n  geom_point(colour = weight_lost_g) +\n  labs(title = \"Initial weight vs tail length\",\n       x = \"Initial weight (g)\",\n       y = \"Tail length (mm)\") +\n  theme_minimal()\n\nHint: read the error message carefully! It will give you a clue about what the problem is.\n\nWrite some code to re-create the plots below in ggplot2.\n\n\nHint: you can use geom_smooth() twice, once to add the overall trendline, and once to add the separate trendlines for each mouse strain. You’ll want to use the aes() function within the geoms that need to be colour coded.\n\n\n\n`geom_smooth()` using formula = 'y ~ x'\n\n\nWarning: Removed 2 rows containing non-finite outside the scale range\n(`stat_smooth()`).\n\n\n`geom_smooth()` using formula = 'y ~ x'\n\n\nWarning: Removed 2 rows containing non-finite outside the scale range\n(`stat_smooth()`).\n\n\nWarning: Removed 2 rows containing missing values or values outside the scale range\n(`geom_point()`).\n\n\n\n\n\n\n\n\n\n\nThe font size here is 16 and the thicker line is size 2.\n\n\n\nWarning: Removed 2 rows containing non-finite outside the scale range\n(`stat_boxplot()`).\n\n\n\n\n\n\n\n\n\n\nAssign the plots you created in question 4 to variables, use the patchwork package to combine them into a single figure, and save it to a file.\n\n\n\nSolutions\n\n\nThe plotting code would generate:\n\n\nBoxplots of the weight lost (in grams), with one for each sex in each cage. The boxplots are coloured by sex and the width of the boxplots is set to 0.5 so they are a bit skinnier than usual. A dashed line is drawn at y = 4 (4g of weight lost), and the legend is placed at the bottom of the plot. The plot uses a minimal theme.\nA scatterplot of initial weight (in grams) vs weight lost (in grams), with points coloured by drug dosage (using a the viridis colour palette for continuous variables). A black linear trendline is plotted over the top, and the confidence interval is not shown (se = FALSE). The plot uses a minimal theme.\n\n\nBelow are some sample answers. Your plots might look a little different depending on your aesthetic preferences.\n\n\nTo make the plot you could use the following code:\n\n\nm_dose %&gt;% ggplot(\n  aes(x = mouse_strain, y = drug_dose_g, fill = mouse_strain)) +\n  # you could also use aes(colour = mouse_strain) here to have the outline of the violin be the same colour as the fill\n  geom_violin() +\n  geom_jitter(width = 0.2) +\n  # choose a scale you like\n  # here I am using a vector of three different hex colours for the three different strains\n  scale_fill_manual(values = c(\"#FFBA49\", \"#EF5B5B\", \"#3581B8\")) +\n  # don't forget to label!!\n  labs(title = \"Drug dosage by mouse strain\",\n       x = \"Drug dosage (g)\",\n       y = \"Mouse strain\") +\n  theme_minimal()\n\nWarning: Removed 2 rows containing non-finite outside the scale range\n(`stat_ydensity()`).\n\n\nWarning: Removed 2 rows containing missing values or values outside the scale range\n(`geom_point()`).\n\n\n\n\n\n\n\n\n\n\nTo make the plot you could use the following code:\n\n\nm_dose %&gt;% ggplot(aes(x = weight_lost_g)) +\n  # choose your fave pink colour, here i just used \"pink\"\n  # don't forget to set the bins to 15\n  geom_histogram(fill = \"pink\", bins = 15) +\n  facet_grid(sex ~ mouse_strain) +\n  # don't forget to label!!\n  labs(\"Weight lost by sex and mouse strain\",\n       x = \"Weight lost (g)\",\n       y = \"Count\") +\n  # my fave theme\n  theme_minimal()\n\nWarning: Removed 2 rows containing non-finite outside the scale range\n(`stat_bin()`).\n\n\n\n\n\n\n\n\n\n\nThe error is because you are trying to colour the points by weight lost, but you haven’t specified it in the aes() function. You need to put colour = weight_lost_g inside the aes() function. This can be either the first aes() function call inside ggplot():\n\n\nm_dose %&gt;% ggplot(\n  aes(x = initial_weight_g, y = tail_length_mm, colour = weight_lost_g)) +\n  geom_point() +\n  labs(title = \"Initial weight vs tail length\",\n       x = \"Initial weight (g)\",\n       y = \"Tail length (mm)\") +\n  theme_minimal()\n\nWarning: Removed 2 rows containing missing values or values outside the scale range\n(`geom_point()`).\n\n\n\n\n\n\n\n\n\nOr, you could set the colour in the geom_point() function, like this:\n\nm_dose %&gt;% ggplot(\n  aes(x = initial_weight_g, y = tail_length_mm)) +\n  geom_point(aes(colour = weight_lost_g)) +\n  labs(title = \"Initial weight vs tail length\",\n       x = \"Initial weight (g)\",\n       y = \"Tail length (mm)\") +\n  theme_minimal()\n\nWarning: Removed 2 rows containing missing values or values outside the scale range\n(`geom_point()`).\n\n\n\n\n\n\n\n\n\nEither way, if you want to map a variable to an aesthetic, you need to put it inside the aes() function!\n\nTo recreate the plots, you could use the following code:\n\n\nNote how the aes() function is used to colour the points and individual trendlines by mouse strain, but not the overall trendline because we specify it within the geoms, not in the initial ggplot() function call:\n\n\nm_dose %&gt;% ggplot(\n  aes(x = initial_weight_g, y = tail_length_mm)) +\n  # colour the points by mouse strain\n  # we put this in geom_point() because we want to colour the points by mouse strain but not the overall trendline\n  geom_point(aes(colour = mouse_strain), size = 2) +\n  # add a grey trendline for the overall trend (not coloured by mouse strain)\n  geom_smooth(method = \"lm\", se = FALSE, colour = \"grey\") +\n  # add a separate trendline for each mouse strain\n  geom_smooth(method = \"lm\", se = FALSE, aes(colour = mouse_strain)) +\n  # label the plot\n  labs(title = \"Scatterplot of Simpson's Paradox in the relationship between initial weight and tail length\",\n       x = \"Initial weight (g)\",\n       y = \"Tail length (mm)\") +\n  # use the minimal theme\n  theme_minimal()\n\n`geom_smooth()` using formula = 'y ~ x'\n\n\nWarning: Removed 2 rows containing non-finite outside the scale range\n(`stat_smooth()`).\n\n\n`geom_smooth()` using formula = 'y ~ x'\n\n\nWarning: Removed 2 rows containing non-finite outside the scale range\n(`stat_smooth()`).\n\n\nWarning: Removed 2 rows containing missing values or values outside the scale range\n(`geom_point()`).\n\n\n\n\n\n\n\n\n\n\nNotice how we specified the linewidth argument in the geom_boxplot() and geom_hline() functions to make the lines thicker. This is not inside the aes() function because it doesn’t represent anything in the data, it’s just used to style the plot. We also set the base_size argument in the theme_minimal() function to make the font size larger:\n\n\nm_dose %&gt;% ggplot(\n  aes(x = cage_number, y = weight_lost_g, colour = mouse_strain)) +\n  # set linewidth = 2 to make the lines thicker\n  geom_boxplot(linewidth = 2) +\n  # add a dashed line at y = 4\n  geom_hline(yintercept = 4, linetype = \"dashed\", linewidth = 2) +\n  #endregion\n  labs(title = \"Weight lost by cage number and mouse strain\",\n       x = \"Cage number\",\n       y = \"Weight lost (g)\") +\n  # minimal theme and increase font size\n  theme_minimal(base_size = 16) +\n  # move the legend to the bottom\n  theme(legend.position = \"bottom\")\n\nWarning: Removed 2 rows containing non-finite outside the scale range\n(`stat_boxplot()`).\n\n\n\n\n\n\n\n\n\n\nTo combine the plots, you could use the following code:\n\n\n# assuming you have already created the plots and assigned them to variables 'plot1' and 'plot2'\n\n# don't forget to load the patchwork package!\nlibrary(patchwork)\n\n# combine the plots\ncombined_plot &lt;- plot1 + plot2 +\n  # we can add annotation if we like\n  plot_annotation(tag_levels = \"A\")\n\n# save the plot to a file\nggsave(\"combined_plot.png\", plot = combined_plot, width = 10, height = 5)",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Plotting with ggplot2</span>"
    ]
  },
  {
    "objectID": "chapter_5.html",
    "href": "chapter_5.html",
    "title": "5  Putting it all together",
    "section": "",
    "text": "5.1 Introduction to the dataset\nIn this chapter we will combine all the skills we have learned so far to perform a complete analysis of a small dataset.\nIn this chapter we will use the mousezempic dosage data m_dose and mouse expression data m_exp data frames, which contain information about the mice including mousezempic dose, and their gene expression levels, respectively.\nlibrary(tidyverse)\nlibrary(patchwork)\n\n# read in dosage data\nm_dose &lt;- read_csv(\"data/mousezempic_dosage_data.csv\")\nm_dose\n\n# A tibble: 344 × 9\n   mouse_strain cage_number weight_lost_g replicate sex    drug_dose_g\n   &lt;chr&gt;        &lt;chr&gt;               &lt;dbl&gt; &lt;chr&gt;     &lt;chr&gt;        &lt;dbl&gt;\n 1 CD-1         1A                   3.75 rep1      male       0.00181\n 2 CD-1         1A                   3.8  rep1      female     0.00186\n 3 CD-1         1A                   3.25 rep1      female     0.00195\n 4 CD-1         1A                  NA    rep1      &lt;NA&gt;      NA      \n 5 CD-1         1A                   3.45 rep1      female     0.00193\n 6 CD-1         1A                   3.65 rep1      male       0.0019 \n 7 CD-1         1A                   3.62 rep1      female     0.00181\n 8 CD-1         1A                   4.68 rep1      male       0.00195\n 9 CD-1         1A                   3.48 rep1      &lt;NA&gt;       0.00193\n10 CD-1         1A                   4.25 rep1      &lt;NA&gt;       0.0019 \n# ℹ 334 more rows\n# ℹ 3 more variables: tail_length_mm &lt;dbl&gt;, initial_weight_g &lt;dbl&gt;,\n#   id_num &lt;dbl&gt;\n# read in expression data\nm_exp &lt;- read_tsv(\"data/mousezempic_expression_data.tsv\")\nm_exp\n\n# A tibble: 453 × 11\n   id_num Th_rep1 Th_rep2 Th_rep3 Prlh_rep1 Prlh_rep2 Prlh_rep3 Hprt1_rep1\n    &lt;dbl&gt;   &lt;dbl&gt;   &lt;dbl&gt;   &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;      &lt;dbl&gt;\n 1      1   1431.   2737.   2036.      297.      428.      320.       741.\n 2      2   2699.   4180.   3860.      388.      680.      500.       843.\n 3      3   3596.   5194.   4128.      201.      346.      266.      1047.\n 4      4   2723.   4442.   3728.      317.      576.      478.       541.\n 5      5   2197.   3656.   2887.      114.      205.      173.       798.\n 6      6   2316.   3949.   3355.      242.      383.      305.       763.\n 7      7   1570.   2740.   2129.      294.      489.      427.       796.\n 8      8   2683.   4749.   3563.      231.      400.      309.       922.\n 9      9   3023.   5170.   3830.      289.      464.      390.       921.\n10     10   3254.   5980.   4250.      337.      583.      436.       740.\n# ℹ 443 more rows\n# ℹ 3 more variables: Hprt1_rep2 &lt;dbl&gt;, Hprt1_rep3 &lt;dbl&gt;, group &lt;chr&gt;",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Putting it all together</span>"
    ]
  },
  {
    "objectID": "chapter_5.html#introduction-to-the-dataset",
    "href": "chapter_5.html#introduction-to-the-dataset",
    "title": "5  Putting it all together",
    "section": "",
    "text": "Note\n\n\n\nWe have used read_csv() for the mouse data and read_tsv() for the expression data. These are for reading data separated by commas and tab characters respectively. The readr package also provides read_delim() to let the package guess your delimiter, but if you know the format of your file then it’s good practice to use the appropriate reading function for more predictable behaviour.\n\n\n\n\n\n\n\n\nCaution\n\n\n\nThere’s nothing stopping someone from naming a file file.csv while having tab-separated data inside. This happens quite often in real-world data so it’s a good idea to have a quick look at the data in an text editor before reading it in.",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Putting it all together</span>"
    ]
  },
  {
    "objectID": "chapter_5.html#tidy-data",
    "href": "chapter_5.html#tidy-data",
    "title": "5  Putting it all together",
    "section": "5.2 Tidy Data",
    "text": "5.2 Tidy Data\nThe tidyverse revolves around an important concept called “tidy data”. This is a specific representation of tabular data that is considered easy to work with. Tidy data is roughly defined as tabular data that contains:\n\nIndividual variables in columns\nIndividual observations in rows\nOne data value in each cell\n\nHaving individual variables in columns makes then accessible for performing tidyverse operations like select(), mutate(), filter() and arrange(). If variables were not stored as columns, then these functions would not be able to access them by name.\nHaving individual observations in rows is important because it associates all variables of each observation with the same row. If the data from one observation is spread across multiple rows then it is easy to incorrect summaries from the summarise() function. When using the filter() function with tidy data, you can expect to keep all the data for an observation or none at all. When the data for observations is split over different rows, it’s possible to unknowingly lose partial data from observations.\nHaving a single value in each cell makes it possible to perform meaningful computations for the values, for example you cannot take a mean() of a column of values that contain multiple different values.\nAlthough tidy data is the easiest to work with, it’s often necessary to alter the format of your data for plotting or table displays. It’s a good idea to keep your core data in a tidy format and treating plot or table outputs as representations of that tidy data.\n\n\n\n\n\n\nNote\n\n\n\nMost data you encounter will not be tidy, the first part of data analysis is usually called “data-wranging” and involves tidying up your data so it is easier to use for downstream analysis.",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Putting it all together</span>"
    ]
  },
  {
    "objectID": "chapter_5.html#sec-reshaping",
    "href": "chapter_5.html#sec-reshaping",
    "title": "5  Putting it all together",
    "section": "5.3 Reshaping and combining data",
    "text": "5.3 Reshaping and combining data\nThe filter(), select(), mutate() and summarise() functions we learned last chapter all operate along either the columns or the rows of data. Combining these operations cleverly can answer the majority of questions about your data. However, there are two useful families of functions: pivot for reshaping your data and join for combining your data from shared columns.\n\n5.3.1 Reshaping data with pivot functions\nPivoting is a way to change the shape of your tibble.\n\nPivoting longer reshapes the data to transfer data stored in columns into rows, resulting in more rows and fewer columns.\nPivoting wider is the reverse, moving data from rows into columns.\n\n\n\n\nPivot functions allow you to change the structure of your data frame\n\n\nThe pivot_longer() function is used to pivot data from wide to long format, and the pivot_wider() function is used to pivot data from long to wide format.\n\n5.3.1.1 Pivot wider\nA common use case for pivot_wider() is to make a contingency table, which shows the number of observations for each combination of two variables. This is often easier to read than the same information in long format.\nFor example, let’s say we want to create a table that shows how many mice there are of each strain, in each cage number. We can achieve this in a long format using summarise() as we learned in the previous section:\n\nm_dose %&gt;%\n  summarise(\n    n_mice = n(),\n    .by = c(cage_number, mouse_strain))\n\n# A tibble: 5 × 3\n  cage_number mouse_strain n_mice\n  &lt;chr&gt;       &lt;chr&gt;         &lt;int&gt;\n1 1A          CD-1             52\n2 3E          CD-1             44\n3 2B          CD-1             56\n4 3E          Black 6         124\n5 2B          BALB C           68\n\n\nFor the specific task of counting, we can achieve the same effect using the count() tidyverse function.\n\nm_dose %&gt;%\n  count(cage_number, mouse_strain, name = \"n_mice\")\n\n# A tibble: 5 × 3\n  cage_number mouse_strain n_mice\n  &lt;chr&gt;       &lt;chr&gt;         &lt;int&gt;\n1 1A          CD-1             52\n2 2B          BALB C           68\n3 2B          CD-1             56\n4 3E          Black 6         124\n5 3E          CD-1             44\n\n\nThis summarises by each combination of cage_number and mouse_strain, with the n() function giving the count of data belonging to that combination.\nTo get a contingency table, we wish to have the information in the mouse_strain column displayed along the column names and the values of n_mice becoming the values of the cells in the new table. Since the goal is to make the table wider, we use the pivot_wider() function. To achieve this, we instruct the pivot_wider() function to take names from the mouse_strain column and the values from the n_mice column.\n\nm_dose %&gt;%\n  count(cage_number, mouse_strain, name = \"n_mice\") %&gt;%\n  pivot_wider(names_from = mouse_strain, values_from = n_mice)\n\n# A tibble: 3 × 4\n  cage_number `CD-1` `BALB C` `Black 6`\n  &lt;chr&gt;        &lt;int&gt;    &lt;int&gt;     &lt;int&gt;\n1 1A              52       NA        NA\n2 2B              56       68        NA\n3 3E              44       NA       124\n\n\nThis has transformed our data into a contingency table, with NA where no data corresponding data exists for the specific cage_number and mouse_strain combination.\nWe can do the same thing to see how many of each mouse strains is in each of our experiment replicates.\n\nm_dose %&gt;%\n  count(replicate, mouse_strain, name = \"n_mice\") %&gt;%\n  pivot_wider(names_from = mouse_strain, values_from = n_mice)\n\n# A tibble: 3 × 4\n  replicate `BALB C` `Black 6` `CD-1`\n  &lt;chr&gt;        &lt;int&gt;     &lt;int&gt;  &lt;int&gt;\n1 rep1            26        34     50\n2 rep2            18        46     50\n3 rep3            24        44     52\n\n\n\n\n5.3.1.2 Pivot longer\nData can often arrive in the form similar to the contingency table we constructed. Although this data is easy to read, it is difficult to operate on using tidyverse functions because the mouse_strain data is now stored in the column names and not inside a column we can use as a variable. In order to make this kind of data tidy, we use the pivot_longer() function, which will create a pair of columns from the column names and the value of the corresponding cell.\nTo demonstrate pivot_longer(), we will use the m_exp that we downloaded earlier. This data frame contains the expression levels of two genes (TH and PRLH) suspected to be upregulated in mice taking MouseZempic, as well as one housekeeping gene (HPRT1), all measured in triplicate.\n\nm_exp\n\n# A tibble: 453 × 11\n   id_num Th_rep1 Th_rep2 Th_rep3 Prlh_rep1 Prlh_rep2 Prlh_rep3 Hprt1_rep1\n    &lt;dbl&gt;   &lt;dbl&gt;   &lt;dbl&gt;   &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;      &lt;dbl&gt;\n 1      1   1431.   2737.   2036.      297.      428.      320.       741.\n 2      2   2699.   4180.   3860.      388.      680.      500.       843.\n 3      3   3596.   5194.   4128.      201.      346.      266.      1047.\n 4      4   2723.   4442.   3728.      317.      576.      478.       541.\n 5      5   2197.   3656.   2887.      114.      205.      173.       798.\n 6      6   2316.   3949.   3355.      242.      383.      305.       763.\n 7      7   1570.   2740.   2129.      294.      489.      427.       796.\n 8      8   2683.   4749.   3563.      231.      400.      309.       922.\n 9      9   3023.   5170.   3830.      289.      464.      390.       921.\n10     10   3254.   5980.   4250.      337.      583.      436.       740.\n# ℹ 443 more rows\n# ℹ 3 more variables: Hprt1_rep2 &lt;dbl&gt;, Hprt1_rep3 &lt;dbl&gt;, group &lt;chr&gt;\n\n\nThe data is currently in wide format, with each row representing a different mouse (identified by its id_num) and each column representing a different measurement of a gene. To reshape this data into a long format (where each measurement is contained on a separate row), we can use pivot_longer(), specifying three arguments:\n\ncols: the columns to pivot from. You can use selection helpers like contains() or starts_with() to easily select multiple columns at once.\nnames_to: the name of a new column that will contain the original column names.\nvalues_to: the name of a new column that will contain the values from the original columns.\n\nIn this particular case here’s what the code would look like:\n\nm_exp_long &lt;- m_exp %&gt;%\n  pivot_longer(\n    cols = contains(\"_rep\"),\n    names_to = \"measurement\",\n    values_to = \"expression_level\"\n  )\n\nm_exp_long\n\n# A tibble: 4,077 × 4\n   id_num group     measurement expression_level\n    &lt;dbl&gt; &lt;chr&gt;     &lt;chr&gt;                  &lt;dbl&gt;\n 1      1 treatment Th_rep1                1431.\n 2      1 treatment Th_rep2                2737.\n 3      1 treatment Th_rep3                2036.\n 4      1 treatment Prlh_rep1               297.\n 5      1 treatment Prlh_rep2               428.\n 6      1 treatment Prlh_rep3               320.\n 7      1 treatment Hprt1_rep1              741.\n 8      1 treatment Hprt1_rep2             1300.\n 9      1 treatment Hprt1_rep3              988.\n10      2 treatment Th_rep1                2699.\n# ℹ 4,067 more rows\n\n\n\n\n\n\n\n\nPerplexed by pivoting?\n\n\n\nPivoting can be a bit tricky to get your head around! Often when you’re doing analysis, you’ll run into the problem of knowing that you need to pivot, but not knowing exactly what arguments to use. In these cases, it can be helpful to look at examples online, like those in the R for Data Science book.\n\n\n\n\n\n5.3.2 Separating data in a column\nWhen we look at the measurement column we see that it contains two pieces of information. The gene being measured and the replicate number separated by “_”. We can use the separate() function to split this data into individual columns so that one column does not contain multiple variables.\n\nm_exp_separate &lt;- m_exp_long %&gt;%\n  separate(measurement, into = c(\"gene\", \"replicate\"), sep = \"_\")\n\nm_exp_separate\n\n# A tibble: 4,077 × 5\n   id_num group     gene  replicate expression_level\n    &lt;dbl&gt; &lt;chr&gt;     &lt;chr&gt; &lt;chr&gt;                &lt;dbl&gt;\n 1      1 treatment Th    rep1                 1431.\n 2      1 treatment Th    rep2                 2737.\n 3      1 treatment Th    rep3                 2036.\n 4      1 treatment Prlh  rep1                  297.\n 5      1 treatment Prlh  rep2                  428.\n 6      1 treatment Prlh  rep3                  320.\n 7      1 treatment Hprt1 rep1                  741.\n 8      1 treatment Hprt1 rep2                 1300.\n 9      1 treatment Hprt1 rep3                  988.\n10      2 treatment Th    rep1                 2699.\n# ℹ 4,067 more rows\n\n\n\n\n5.3.3 Summarising values\nNow suppose we wanted to combine the gene expression data across replicates by adding them up, we can use the summarise() function to do so.\n\nm_exp_rep_summed &lt;- m_exp_separate %&gt;%\n  summarise(\n    expression_level = sum(expression_level),\n    .by = c(id_num, group, gene)\n  )\n\nm_exp_rep_summed\n\n# A tibble: 1,359 × 4\n   id_num group     gene  expression_level\n    &lt;dbl&gt; &lt;chr&gt;     &lt;chr&gt;            &lt;dbl&gt;\n 1      1 treatment Th               6204.\n 2      1 treatment Prlh             1045.\n 3      1 treatment Hprt1            3029.\n 4      2 treatment Th              10738.\n 5      2 treatment Prlh             1568.\n 6      2 treatment Hprt1            3669.\n 7      3 treatment Th              12918.\n 8      3 treatment Prlh              813.\n 9      3 treatment Hprt1            4297.\n10      4 treatment Th              10892.\n# ℹ 1,349 more rows\n\n\nWe may also want to get the average expression level of each gene within each experimental group and plot it as a bar chart.\n\nm_exp_rep_summed %&gt;%\n  summarise(\n    expression_level = mean(expression_level),\n    .by = c(group, gene)\n  ) %&gt;%\n  ggplot(aes(x = gene, y = expression_level, fill = group)) +\n  geom_col(position = \"dodge\")\n\n\n\n\n\n\n\n\nWe see that all 3 genes are slightly higher in the treatment group.\n\n\n5.3.4 Reshaping for plotting\nSuppose we wanted to plot the value of two genes against each other. We would need the expression values of genes to be in individual columns. However we have lost this structure after using pivot_longer(). We can restore it using pivot_wider() after we have summarised the replicates.\n\nm_exp_rep_summed_wide &lt;- m_exp_rep_summed %&gt;% \n  pivot_wider( names_from = \"gene\", values_from = \"expression_level\")\n\nm_exp_rep_summed_wide\n\n# A tibble: 453 × 5\n   id_num group         Th  Prlh Hprt1\n    &lt;dbl&gt; &lt;chr&gt;      &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n 1      1 treatment  6204. 1045. 3029.\n 2      2 treatment 10738. 1568. 3669.\n 3      3 treatment 12918.  813. 4297.\n 4      4 treatment 10892. 1371. 2213.\n 5      5 treatment  8740.  491. 3159.\n 6      6 treatment  9620.  930. 2875.\n 7      7 treatment  6440. 1211. 3339.\n 8      8 treatment 10996.  939. 3854.\n 9      9 treatment 12022. 1144. 3781.\n10     10 treatment 13485. 1356. 2848.\n# ℹ 443 more rows\n\n\nWith the replicate aggregated expression levels in individual columns, we can now plot the gene expression values against each other.\n\nm_exp_rep_summed_wide %&gt;% ggplot( aes(x = Th, y = Prlh)) +\n  geom_point()\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nPractice exercise\n\n\n\nMake all the pair-wise scatter plots and assemble them together using patchwork. There should be plots of:\nTh vs Prlh\nTh vs Hprt1\nPrlh vs Hprt1\n\n\n\n\n5.3.5 Combining data with join functions\nData analysis typically involves multiple tables of data. Often there will be tables that are contain related information that must be combined to answer the questions you’re interested in. Tables that are related to each other tend to have one or more columns in common, and are referred to as “relational data”. Combining relational data in useful ways requires the join family of functions. In general joins can accomplish two tasks\n\nAdd new variables to an existing table containing additional information.\nFilter observations in one table based on whether or not they match observations in another table.\nBoth of the above at the same time.\n\n\n\n\nThe left_join() function allows you to combine two data frames\n\n\nA common and basic join is the left_join(). It takes two data frame as arguments and optionally a vector of common columns to perform the join on. The reason it’s called a left-join because it retains all rows from the left data frame while adding on columns from the right data frame only when the data in the designed joining column(s) match.\nFor example, we can join the m_dose data frame with the m_exp_rep_summed_wide data frame based on the id_num column, which is common to both data frames:\n\nleft_join(m_dose, m_exp_rep_summed_wide, by = \"id_num\")\n\n# A tibble: 344 × 13\n   mouse_strain cage_number weight_lost_g replicate sex    drug_dose_g\n   &lt;chr&gt;        &lt;chr&gt;               &lt;dbl&gt; &lt;chr&gt;     &lt;chr&gt;        &lt;dbl&gt;\n 1 CD-1         1A                   3.75 rep1      male       0.00181\n 2 CD-1         1A                   3.8  rep1      female     0.00186\n 3 CD-1         1A                   3.25 rep1      female     0.00195\n 4 CD-1         1A                  NA    rep1      &lt;NA&gt;      NA      \n 5 CD-1         1A                   3.45 rep1      female     0.00193\n 6 CD-1         1A                   3.65 rep1      male       0.0019 \n 7 CD-1         1A                   3.62 rep1      female     0.00181\n 8 CD-1         1A                   4.68 rep1      male       0.00195\n 9 CD-1         1A                   3.48 rep1      &lt;NA&gt;       0.00193\n10 CD-1         1A                   4.25 rep1      &lt;NA&gt;       0.0019 \n# ℹ 334 more rows\n# ℹ 7 more variables: tail_length_mm &lt;dbl&gt;, initial_weight_g &lt;dbl&gt;,\n#   id_num &lt;dbl&gt;, group &lt;chr&gt;, Th &lt;dbl&gt;, Prlh &lt;dbl&gt;, Hprt1 &lt;dbl&gt;\n\n\nThe m_dose contains information about characteristics of each mouse, while the m_exp_rep_summed_wide contains the replicate-summed gene expressions of the mice. Each data frame has an id_num column that relates the data from the two data frames together, and we have joined them into one table that contains both the data about the mice as well as the expression of their genes.\nWith the left_join(), if there is a id_num value that exists in the right data frame but not found in the left, then that data will not be present in the joined table. For any id_num that appears only in the left but not the right data frame, the values in the newly created columns will be NA.\n\n\n\n\n\n\nCaution\n\n\n\nIf the values from the left data frame matches to multiple rows of the column in the right data frame, the left_join() will duplicate the data from the left data frame for each match to the right. This can cause issues with downstream summarisation if not carefully considered.\n\n\n\n5.3.5.1 Joining with mismatched column names\nOften the column containing the matching information has different names in different data frames. For example what might be called “id_num” in one data frame could also be called “mouse_id” in another data frame. In those cases the by argument of left_join() can be formatted to let the function know which column in the left data frame matches to which column on the right.\nWe will demonstrate this by renaming the id_num column in the m_dose to mouse_id and using it to perform the join instead. We will use the join_by(mouse_id == id_num) helper function for the by argument to specify the different columns we wish to join by.\n\n# rename id_num to mouse_id\nm_dose_data_new &lt;- m_dose %&gt;%\n  rename(mouse_id = id_num)\n\nm_dose_data_new\n\n# A tibble: 344 × 9\n   mouse_strain cage_number weight_lost_g replicate sex    drug_dose_g\n   &lt;chr&gt;        &lt;chr&gt;               &lt;dbl&gt; &lt;chr&gt;     &lt;chr&gt;        &lt;dbl&gt;\n 1 CD-1         1A                   3.75 rep1      male       0.00181\n 2 CD-1         1A                   3.8  rep1      female     0.00186\n 3 CD-1         1A                   3.25 rep1      female     0.00195\n 4 CD-1         1A                  NA    rep1      &lt;NA&gt;      NA      \n 5 CD-1         1A                   3.45 rep1      female     0.00193\n 6 CD-1         1A                   3.65 rep1      male       0.0019 \n 7 CD-1         1A                   3.62 rep1      female     0.00181\n 8 CD-1         1A                   4.68 rep1      male       0.00195\n 9 CD-1         1A                   3.48 rep1      &lt;NA&gt;       0.00193\n10 CD-1         1A                   4.25 rep1      &lt;NA&gt;       0.0019 \n# ℹ 334 more rows\n# ℹ 3 more variables: tail_length_mm &lt;dbl&gt;, initial_weight_g &lt;dbl&gt;,\n#   mouse_id &lt;dbl&gt;\n\n\n\n# perform left join by matching mouse_id of the left data frame to id_num of the right data frame\nm_joined_data &lt;- left_join(\n  m_dose_data_new, m_exp_rep_summed_wide,\n  by = join_by(mouse_id == id_num)\n) %&gt;%\n  drop_na() # keep only rows without NA\n\nm_joined_data\n\n# A tibble: 333 × 13\n   mouse_strain cage_number weight_lost_g replicate sex    drug_dose_g\n   &lt;chr&gt;        &lt;chr&gt;               &lt;dbl&gt; &lt;chr&gt;     &lt;chr&gt;        &lt;dbl&gt;\n 1 CD-1         1A                   3.75 rep1      male       0.00181\n 2 CD-1         1A                   3.8  rep1      female     0.00186\n 3 CD-1         1A                   3.25 rep1      female     0.00195\n 4 CD-1         1A                   3.45 rep1      female     0.00193\n 5 CD-1         1A                   3.65 rep1      male       0.0019 \n 6 CD-1         1A                   3.62 rep1      female     0.00181\n 7 CD-1         1A                   4.68 rep1      male       0.00195\n 8 CD-1         1A                   3.2  rep1      female     0.00182\n 9 CD-1         1A                   3.8  rep1      male       0.00191\n10 CD-1         1A                   4.4  rep1      male       0.00198\n# ℹ 323 more rows\n# ℹ 7 more variables: tail_length_mm &lt;dbl&gt;, initial_weight_g &lt;dbl&gt;,\n#   mouse_id &lt;dbl&gt;, group &lt;chr&gt;, Th &lt;dbl&gt;, Prlh &lt;dbl&gt;, Hprt1 &lt;dbl&gt;\n\n\n\n\n\n\n\n\nNote\n\n\n\nWhen joining data frames with mismatched column names, the column name from the left data frame argument will be retained for the joined result.\n\n\n\n\n\n\n\n\nNote\n\n\n\nAn older syntax exists for the by argument that would look like by = c(\"mouse_id\" = \"id_num\"). This does the same thing as what is shown above but the documentation now recommends the new syntax which allows for flexible options like joining to the closest.",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Putting it all together</span>"
    ]
  },
  {
    "objectID": "chapter_5.html#visualising-testing-expression-between-strains",
    "href": "chapter_5.html#visualising-testing-expression-between-strains",
    "title": "5  Putting it all together",
    "section": "5.4 Visualising & testing expression between strains",
    "text": "5.4 Visualising & testing expression between strains\nWith the joined data we now have more information about the mice in addition to the expression data. So we can check if there is any significant difference in gene expressions between mouse strains.\n\nm_joined_data %&gt;% \n  ggplot( aes(x = mouse_strain, y = Th, fill = mouse_strain)) +\n  geom_violin()\n\n\n\n\n\n\n\n\nIf we wanted to plot all 3 genes, one way is to make 3 different plots, but we can also use facets. However to use facets we would need to have the faceting variable in a column, and currently our gene names are in the column names. So we must use pivot_longer().\n\nm_joined_data_long &lt;- m_joined_data %&gt;%\n  pivot_longer(cols = c(Th, Prlh, Hprt1), names_to = \"gene\", values_to = \"expression\")\n\nm_joined_data_long\n\n# A tibble: 999 × 12\n   mouse_strain cage_number weight_lost_g replicate sex    drug_dose_g\n   &lt;chr&gt;        &lt;chr&gt;               &lt;dbl&gt; &lt;chr&gt;     &lt;chr&gt;        &lt;dbl&gt;\n 1 CD-1         1A                   3.75 rep1      male       0.00181\n 2 CD-1         1A                   3.75 rep1      male       0.00181\n 3 CD-1         1A                   3.75 rep1      male       0.00181\n 4 CD-1         1A                   3.8  rep1      female     0.00186\n 5 CD-1         1A                   3.8  rep1      female     0.00186\n 6 CD-1         1A                   3.8  rep1      female     0.00186\n 7 CD-1         1A                   3.25 rep1      female     0.00195\n 8 CD-1         1A                   3.25 rep1      female     0.00195\n 9 CD-1         1A                   3.25 rep1      female     0.00195\n10 CD-1         1A                   3.45 rep1      female     0.00193\n# ℹ 989 more rows\n# ℹ 6 more variables: tail_length_mm &lt;dbl&gt;, initial_weight_g &lt;dbl&gt;,\n#   mouse_id &lt;dbl&gt;, group &lt;chr&gt;, gene &lt;chr&gt;, expression &lt;dbl&gt;\n\n\nNow that the gene variable is in a column, we can use this information to create our faceted plot. We use facet_wrap() with the scales = \"free_y\" argument so each gene can have its own y-axis.\n\nm_joined_data_long %&gt;% \n  ggplot( aes(x = mouse_strain, y = expression, fill = mouse_strain)) +\n  geom_violin() +\n  facet_wrap(~gene, scales = \"free_y\")\n\n\n\n\n\n\n\n\nThere doesn’t appear to be clear differences in the expression of these three genes between the haplotypes.\n\n5.4.1 Simple linear model (discrete x)\nTo fit a line through the gene expression values of each mouse genotype, and test for significance of the x~y relationship, we can use a handy function lm_test() from the tidyrstats library.\n\nlibrary(tidyrstats)\n\nThis function takes a long-format data frame as input, and the formula for the linear model we want to fit. (We will read more about linear models in later chapters). For this test, for each gene, we want to know whether the response (gene expression ; aka ‘y’), changes significantly with the predictor (mouse strain ; aka ‘x’). The model formula will be y ~ x1, that is expression ~ mouse_strain.\n\nm_joined_data_long %&gt;% \n  group_by(gene) %&gt;% \n  lm_test(expression ~ mouse_strain) %&gt;% \n  filter(term!='intercept') %&gt;% \n  arrange(gene,term)\n\nResults for linear model: expression ~ mouse_strain\n\n\n# A tibble: 6 × 6\n  gene  term                estimate std.error statistic p.value\n  &lt;chr&gt; &lt;chr&gt;                  &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;   &lt;dbl&gt;\n1 Hprt1 mouse_strainBlack 6     3.31      68.4    0.0485   0.961\n2 Hprt1 mouse_strainCD-1       48.2       66.0    0.730    0.466\n3 Prlh  mouse_strainBlack 6    10.2       42.3    0.240    0.810\n4 Prlh  mouse_strainCD-1      -19.8       40.9   -0.485    0.628\n5 Th    mouse_strainBlack 6   666.       557.     1.20     0.233\n6 Th    mouse_strainCD-1      697.       538.     1.29     0.196\n\n\nOur intuition from the violin plots is correct. None of the genes show significant differences in expression between the Black6 vs the reference (BALBC), nor the CD-1 vs the reference. Note that all of the P values are &gt; 0.05, meaning we dont have enough evidence to reject the null hypothesis.",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Putting it all together</span>"
    ]
  },
  {
    "objectID": "chapter_5.html#visualising-testing-relationships-between-dosage-and-genes",
    "href": "chapter_5.html#visualising-testing-relationships-between-dosage-and-genes",
    "title": "5  Putting it all together",
    "section": "5.5 Visualising & testing relationships between dosage and genes",
    "text": "5.5 Visualising & testing relationships between dosage and genes\nWith the joined data frame we can also visualise the relationship between the drug dosage and the genes, separated by mouse strain. We do this by using our m_joined_data_long to plot with facet_grid() specifying the layout of our grid.\n\nm_joined_data_long %&gt;% \n  ggplot(aes(x = drug_dose_g, y = expression, color = mouse_strain)) +\n  geom_point() +\n  geom_smooth(method = \"lm\") +\n  facet_grid(cols = vars(mouse_strain), rows = vars(gene), scales = \"free\")\n\n`geom_smooth()` using formula = 'y ~ x'\n\n\n\n\n\n\n\n\n\nAlthough very minor, there appears to be some effect of dosage on gene expression that is strain specific.\n\n5.5.1 Simple linear model (continuous x)\nAgain, we can test this using lm_test(), where y is expression, and x is now the continuous variable drug_dose_g. We are testing the association for each gene in each mouse strain, by grouping the input data before lm_test(). Note this is different from correcting for gene and mouse strain as covariates, because the model only tests one gene-strain combination at a time.\n\nm_joined_data_long %&gt;% \n  group_by(mouse_strain, gene) %&gt;% \n  lm_test(expression ~ drug_dose_g) %&gt;% \n  filter(term!='intercept') %&gt;% \n  arrange(mouse_strain, gene, p.value)\n\nResults for linear model: expression ~ drug_dose_g\n\n\n# A tibble: 9 × 7\n  mouse_strain gene  term         estimate std.error statistic p.value\n  &lt;chr&gt;        &lt;chr&gt; &lt;chr&gt;           &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;   &lt;dbl&gt;\n1 BALB C       Hprt1 drug_dose_g -1531022.   862835.    -1.77  0.0806 \n2 BALB C       Prlh  drug_dose_g  -319172.   405419.    -0.787 0.434  \n3 BALB C       Th    drug_dose_g  4018858.  6176909.     0.651 0.518  \n4 Black 6      Hprt1 drug_dose_g -1561066.   582482.    -2.68  0.00842\n5 Black 6      Prlh  drug_dose_g  -391751.   383201.    -1.02  0.309  \n6 Black 6      Th    drug_dose_g -4385855.  5391197.    -0.814 0.418  \n7 CD-1         Hprt1 drug_dose_g   377655.   556772.     0.678 0.499  \n8 CD-1         Prlh  drug_dose_g   478143.   379983.     1.26  0.210  \n9 CD-1         Th    drug_dose_g  5299211.  4503093.     1.18  0.241  \n\n\nHere we can see, in fact there is a significant association between Mousezempic drug dose and gene expression: within the Black 6 strain, for the Hprt1 gene.\n\n\n\n\n\n\nStating statistical findings\n\n\n\nFrom our summary table above, can you finish this sentence which is the formal statement of results from a linear model?\n“In the Black 6 mouse strain, for every 1 gram increase in drug dose, on average, Hprt1 gene expression …”\n\n\nYou can read and work through more lm_test() examples in the Statistics in R Primer.",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Putting it all together</span>"
    ]
  },
  {
    "objectID": "chapter_5.html#saving-multiple-objects",
    "href": "chapter_5.html#saving-multiple-objects",
    "title": "5  Putting it all together",
    "section": "5.6 Saving multiple objects",
    "text": "5.6 Saving multiple objects\nWe can save our newly transformed and joined data frames for easy access using the save() command, which takes any number of environment objects, and a new Rdata format file name as arguments:\n\nsave(\n  m_exp_rep_summed,\n  m_exp_rep_summed_wide,\n  m_joined_data_long,\n  file = 'data_processed/mousezempic_cleaned_joined.Rdata')",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Putting it all together</span>"
    ]
  },
  {
    "objectID": "chapter_5.html#another-case-study---who-tuberculosis-data",
    "href": "chapter_5.html#another-case-study---who-tuberculosis-data",
    "title": "5  Putting it all together",
    "section": "5.7 Another case study - WHO tuberculosis data",
    "text": "5.7 Another case study - WHO tuberculosis data\nWe can look at another dataset containing tuberculosis (TB) cases broken down by year, country, age, gender, and diagnosis method. The data comes from the 2014 World Health Organization Global Tuberculosis Report and is typical of many real-life datasets in terms of structure. There are redundant columns, odd variable codes and missing values.\nWe want to tidy it up using the tools we have learned in order to try to extract some information from this data.\n\nwho\n\n# A tibble: 7,240 × 60\n   country  iso2  iso3   year new_sp_m014 new_sp_m1524 new_sp_m2534 new_sp_m3544\n   &lt;chr&gt;    &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt;       &lt;dbl&gt;        &lt;dbl&gt;        &lt;dbl&gt;        &lt;dbl&gt;\n 1 Afghani… AF    AFG    1980          NA           NA           NA           NA\n 2 Afghani… AF    AFG    1981          NA           NA           NA           NA\n 3 Afghani… AF    AFG    1982          NA           NA           NA           NA\n 4 Afghani… AF    AFG    1983          NA           NA           NA           NA\n 5 Afghani… AF    AFG    1984          NA           NA           NA           NA\n 6 Afghani… AF    AFG    1985          NA           NA           NA           NA\n 7 Afghani… AF    AFG    1986          NA           NA           NA           NA\n 8 Afghani… AF    AFG    1987          NA           NA           NA           NA\n 9 Afghani… AF    AFG    1988          NA           NA           NA           NA\n10 Afghani… AF    AFG    1989          NA           NA           NA           NA\n# ℹ 7,230 more rows\n# ℹ 52 more variables: new_sp_m4554 &lt;dbl&gt;, new_sp_m5564 &lt;dbl&gt;,\n#   new_sp_m65 &lt;dbl&gt;, new_sp_f014 &lt;dbl&gt;, new_sp_f1524 &lt;dbl&gt;,\n#   new_sp_f2534 &lt;dbl&gt;, new_sp_f3544 &lt;dbl&gt;, new_sp_f4554 &lt;dbl&gt;,\n#   new_sp_f5564 &lt;dbl&gt;, new_sp_f65 &lt;dbl&gt;, new_sn_m014 &lt;dbl&gt;,\n#   new_sn_m1524 &lt;dbl&gt;, new_sn_m2534 &lt;dbl&gt;, new_sn_m3544 &lt;dbl&gt;,\n#   new_sn_m4554 &lt;dbl&gt;, new_sn_m5564 &lt;dbl&gt;, new_sn_m65 &lt;dbl&gt;, …\n\n\nThe first thing we notice is that country, iso2 and iso3 all seem to be different encodings for the country. The year column is fine as a variable but the rest of the columns seem appear to be coding values in the column names. There are numeric values in the cells, and since we know this dataset is supposed to contain case numbers, and no column clearly denotes this, we suspect that the values in the columns are case numbers with the column names being descriptive of the cases.\nSince we believe that many of these column names are in fact encoding data, we want to pivot_longer() to put that information in a column for further processing.\n\n# pivot longer with columns 5 to 60, drop NA values\nwho_long &lt;- who %&gt;%\n  pivot_longer(\n    cols = 5:60, # alternatively contains(\"_\")\n    names_to = \"description\",\n    values_to = \"cases\",\n    values_drop_na = TRUE\n  )\n\nwho_long\n\n# A tibble: 76,046 × 6\n   country     iso2  iso3   year description  cases\n   &lt;chr&gt;       &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; &lt;chr&gt;        &lt;dbl&gt;\n 1 Afghanistan AF    AFG    1997 new_sp_m014      0\n 2 Afghanistan AF    AFG    1997 new_sp_m1524    10\n 3 Afghanistan AF    AFG    1997 new_sp_m2534     6\n 4 Afghanistan AF    AFG    1997 new_sp_m3544     3\n 5 Afghanistan AF    AFG    1997 new_sp_m4554     5\n 6 Afghanistan AF    AFG    1997 new_sp_m5564     2\n 7 Afghanistan AF    AFG    1997 new_sp_m65       0\n 8 Afghanistan AF    AFG    1997 new_sp_f014      5\n 9 Afghanistan AF    AFG    1997 new_sp_f1524    38\n10 Afghanistan AF    AFG    1997 new_sp_f2534    36\n# ℹ 76,036 more rows\n\n\nIt doesn’t look like the values in description are unique, so we can try to count them to get a sense of what we’re dealing with. It will show us the unique values as well as the counts for each value.\n\nwho_long %&gt;%\n  count(description)\n\n# A tibble: 56 × 2\n   description      n\n   &lt;chr&gt;        &lt;int&gt;\n 1 new_ep_f014   1032\n 2 new_ep_f1524  1021\n 3 new_ep_f2534  1021\n 4 new_ep_f3544  1021\n 5 new_ep_f4554  1017\n 6 new_ep_f5564  1017\n 7 new_ep_f65    1014\n 8 new_ep_m014   1038\n 9 new_ep_m1524  1026\n10 new_ep_m2534  1020\n# ℹ 46 more rows\n\n\nSome patterns emerge, and it maybe be possible to guess at exactly what these values mean. For example we see the presence of “m” and “f” in the encoding which probably encodes sex. Luckily we have a data dictionary ready from the source that tells us what this means.\n\nThe first part tells us if the data is new or old, in this case all data is new.\nThe next part describe the type of TB:\n\n\nrel for relapse\nep for extrapulmonary\nsn for pulmonary TB that cannot be diagnosed with a pulmonary smear (smear negative)\nsp for pulmonary TB that can be diagnosed with a smear (smear positive)\n\n\nThe sex of the patient. Males and females denoted by m and f respectively.\nThe 7 age groups the data is divided into:\n\n\n014: 0 - 14 years old\n1524: 15 - 24 years old\n2534: 25 - 34 years old\n3544: 35 - 44 years old\n4554: 45 - 54 years old\n5564: 55 - 64 years old\n65: 65 or older\n\n\n5.7.1 String manupulation\nArmed with that knowledge we can begin to tidy up our dataset! The first thing we will do is tidy up the description column, we will do this with some string manipulation functions from the tidyverse. These functions help us manipulate strings programatically and are essential in dealing with real-world data.\nSome useful functions for string manipulation include:\n\nstr_replace(string, pattern, replacement): replaces the pattern in the string with the replacement.\nstr_extract(string, pattern): extracts the part of the string matching the pattern.\nstr_remove(string, pattern): removes the part of the string matching the pattern.\n\nThe full list of functions can be found in the stringr package documentation and patterns can be written in very powerful ways with regular expressions. For our purposes we will just use simply fixed patterns.\nWe saw previously that we can use separate() to break apart on column into multiple columns. However, we see there is a problem in this dataset where the cases that are marked as relapse are encoded newrel which doesn’t leave us with a separator to use. We can remedy this by using a combination of mutate() and str_replace() to replace all instances of newrel with new_rel.\n\nwho_long &lt;- who_long %&gt;%\n  mutate(description = str_replace(description, \"newrel\", \"new_rel\"))\n\nwho_long\n\n# A tibble: 76,046 × 6\n   country     iso2  iso3   year description  cases\n   &lt;chr&gt;       &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; &lt;chr&gt;        &lt;dbl&gt;\n 1 Afghanistan AF    AFG    1997 new_sp_m014      0\n 2 Afghanistan AF    AFG    1997 new_sp_m1524    10\n 3 Afghanistan AF    AFG    1997 new_sp_m2534     6\n 4 Afghanistan AF    AFG    1997 new_sp_m3544     3\n 5 Afghanistan AF    AFG    1997 new_sp_m4554     5\n 6 Afghanistan AF    AFG    1997 new_sp_m5564     2\n 7 Afghanistan AF    AFG    1997 new_sp_m65       0\n 8 Afghanistan AF    AFG    1997 new_sp_f014      5\n 9 Afghanistan AF    AFG    1997 new_sp_f1524    38\n10 Afghanistan AF    AFG    1997 new_sp_f2534    36\n# ℹ 76,036 more rows\n\n\nSince every single observation contains only new cases and no old cases, the new_ portion of the encoding is redundant. So we can remove it using str_remove().\n\nwho_long &lt;- who_long %&gt;%\n  mutate(description = str_remove(description, \"new_\"))\n\nwho_long\n\n# A tibble: 76,046 × 6\n   country     iso2  iso3   year description cases\n   &lt;chr&gt;       &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; &lt;chr&gt;       &lt;dbl&gt;\n 1 Afghanistan AF    AFG    1997 sp_m014         0\n 2 Afghanistan AF    AFG    1997 sp_m1524       10\n 3 Afghanistan AF    AFG    1997 sp_m2534        6\n 4 Afghanistan AF    AFG    1997 sp_m3544        3\n 5 Afghanistan AF    AFG    1997 sp_m4554        5\n 6 Afghanistan AF    AFG    1997 sp_m5564        2\n 7 Afghanistan AF    AFG    1997 sp_m65          0\n 8 Afghanistan AF    AFG    1997 sp_f014         5\n 9 Afghanistan AF    AFG    1997 sp_f1524       38\n10 Afghanistan AF    AFG    1997 sp_f2534       36\n# ℹ 76,036 more rows\n\n\nNow one last problem remains, there is no separator between the sex and age group. So we can once again use str_replace() to edit in an underscore. Note that we use \"_f\" and \"_m\" as our patterns as a precaution in case the letters naturally occur elsewhere in the encoding.\n\nwho_long &lt;- who_long %&gt;%\n  mutate(description = str_replace(description, \"_f\", \"_f_\")) %&gt;%\n  mutate(description = str_replace(description, \"_m\", \"_m_\"))\n\nwho_long\n\n# A tibble: 76,046 × 6\n   country     iso2  iso3   year description cases\n   &lt;chr&gt;       &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; &lt;chr&gt;       &lt;dbl&gt;\n 1 Afghanistan AF    AFG    1997 sp_m_014        0\n 2 Afghanistan AF    AFG    1997 sp_m_1524      10\n 3 Afghanistan AF    AFG    1997 sp_m_2534       6\n 4 Afghanistan AF    AFG    1997 sp_m_3544       3\n 5 Afghanistan AF    AFG    1997 sp_m_4554       5\n 6 Afghanistan AF    AFG    1997 sp_m_5564       2\n 7 Afghanistan AF    AFG    1997 sp_m_65         0\n 8 Afghanistan AF    AFG    1997 sp_f_014        5\n 9 Afghanistan AF    AFG    1997 sp_f_1524      38\n10 Afghanistan AF    AFG    1997 sp_f_2534      36\n# ℹ 76,036 more rows\n\n\nWith that we are finally able to separate the data into individual columns with separate().\n\nwho_separated &lt;- who_long %&gt;%\n  separate(description, into = c(\"type\", \"sex\", \"age_group\"), sep = \"_\")\n\nwho_separated\n\n# A tibble: 76,046 × 8\n   country     iso2  iso3   year type  sex   age_group cases\n   &lt;chr&gt;       &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt;     &lt;dbl&gt;\n 1 Afghanistan AF    AFG    1997 sp    m     014           0\n 2 Afghanistan AF    AFG    1997 sp    m     1524         10\n 3 Afghanistan AF    AFG    1997 sp    m     2534          6\n 4 Afghanistan AF    AFG    1997 sp    m     3544          3\n 5 Afghanistan AF    AFG    1997 sp    m     4554          5\n 6 Afghanistan AF    AFG    1997 sp    m     5564          2\n 7 Afghanistan AF    AFG    1997 sp    m     65            0\n 8 Afghanistan AF    AFG    1997 sp    f     014           5\n 9 Afghanistan AF    AFG    1997 sp    f     1524         38\n10 Afghanistan AF    AFG    1997 sp    f     2534         36\n# ℹ 76,036 more rows\n\n\nBecause the columns iso2 and iso3 contain redundant information about the country, we can remove them, but also retain them for reference as we may want to know what the short forms of the countries are when relating it other tables. To do so we can select() the columns containing this information, then use distinct() to keep only unique rows.\n\ncountry_codes &lt;- who_separated %&gt;%\n  select(country, iso2, iso3) %&gt;%\n  distinct()\n\ncountry_codes\n\n# A tibble: 219 × 3\n   country             iso2  iso3 \n   &lt;chr&gt;               &lt;chr&gt; &lt;chr&gt;\n 1 Afghanistan         AF    AFG  \n 2 Albania             AL    ALB  \n 3 Algeria             DZ    DZA  \n 4 American Samoa      AS    ASM  \n 5 Andorra             AD    AND  \n 6 Angola              AO    AGO  \n 7 Anguilla            AI    AIA  \n 8 Antigua and Barbuda AG    ATG  \n 9 Argentina           AR    ARG  \n10 Armenia             AM    ARM  \n# ℹ 209 more rows\n\n\nWith that we can safely remove the redundant information from our data and end up with a tidy data frame.\n\nwho_tidy &lt;- who_separated %&gt;%\n  select(-iso2, -iso3)\n\nwho_tidy\n\n# A tibble: 76,046 × 6\n   country      year type  sex   age_group cases\n   &lt;chr&gt;       &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt;     &lt;dbl&gt;\n 1 Afghanistan  1997 sp    m     014           0\n 2 Afghanistan  1997 sp    m     1524         10\n 3 Afghanistan  1997 sp    m     2534          6\n 4 Afghanistan  1997 sp    m     3544          3\n 5 Afghanistan  1997 sp    m     4554          5\n 6 Afghanistan  1997 sp    m     5564          2\n 7 Afghanistan  1997 sp    m     65            0\n 8 Afghanistan  1997 sp    f     014           5\n 9 Afghanistan  1997 sp    f     1524         38\n10 Afghanistan  1997 sp    f     2534         36\n# ℹ 76,036 more rows\n\n\nFrom there we can easily visualise various aspects of the data for analysis. For example we can see what country had the highest number of total cases in the year 2010.\n\nwho_tidy %&gt;%\n  filter(year == 2010) %&gt;%\n  summarise(total_cases = sum(cases), .by = country) %&gt;%\n  arrange(desc(total_cases))\n\n# A tibble: 204 × 2\n   country                               total_cases\n   &lt;chr&gt;                                       &lt;dbl&gt;\n 1 China                                      869092\n 2 India                                      630164\n 3 South Africa                               364992\n 4 Indonesia                                  296272\n 5 Bangladesh                                 150856\n 6 Pakistan                                   124455\n 7 Russian Federation                         102823\n 8 Philippines                                 89198\n 9 Kenya                                       85484\n10 Democratic People's Republic of Korea       81240\n# ℹ 194 more rows\n\n\nWe can extract only the data from the top 10 countries based in 2010 cases and plot how their total case numbers between the years 2000 and 2010.\n\ntop_10_countries &lt;- who_tidy %&gt;%\n  filter(year == 2010) %&gt;%\n  summarise(total_cases = sum(cases), .by = country) %&gt;%\n  arrange(desc(total_cases)) %&gt;%\n  slice(1:10)\n\ntop_10_countries\n\n# A tibble: 10 × 2\n   country                               total_cases\n   &lt;chr&gt;                                       &lt;dbl&gt;\n 1 China                                      869092\n 2 India                                      630164\n 3 South Africa                               364992\n 4 Indonesia                                  296272\n 5 Bangladesh                                 150856\n 6 Pakistan                                   124455\n 7 Russian Federation                         102823\n 8 Philippines                                 89198\n 9 Kenya                                       85484\n10 Democratic People's Republic of Korea       81240\n\n\n\nwho_tidy %&gt;%\n  filter(\n    country %in% top_10_countries$country,\n    year &gt;= 2000,\n    year &lt;= 2010\n  ) %&gt;%\n  summarise(\n    total_cases = sum(cases), .by = c(country, year)\n  ) %&gt;%\n  ggplot(aes(x = year, y = total_cases, col = country)) +\n  geom_point() +\n  geom_line()",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Putting it all together</span>"
    ]
  },
  {
    "objectID": "chapter_5.html#summary",
    "href": "chapter_5.html#summary",
    "title": "5  Putting it all together",
    "section": "5.8 Summary",
    "text": "5.8 Summary\nToday we learned about the concept of “tidy data”. A particular form of tabular data that is particularly suitable for the tidyverse. It contains:\n\none variable per column\none observation per row\none value per cell\n\nWe learned to reshape data frames using various functions powerful functions.\n\npivot_wider() reduces the number of rows and move information into new columns.\npivot_longer() reduces the number of columns and increase the number of rows. Moving the column names into a new column.\nseparate() separates multiple values encoded in a single column into individual columns based on a separator character.\n\nWe learned to combine data frames using the left_join() function. This allows us to merge data frames together that have common columns, matching up the rows according to the shared column.\n\nleft_join(left, right, by = shared_column) takes two data frames and merges them based on the shared_column column. The information from the right data frame is added to the left if there is a match within the shared column.\nleft_join(left, right, by = join_by(left_col_name == right_col_name)) can be used to join using columns from two data frames that encode the same values but have different column names\n\nWe also learned some useful string manipulation functions that help us clean up data columns\n\nstr_replace() lets us replace patterns in a string\nstr_remove() lets us remove patterns in a string\n\nTogether these make up a very versatile toolkit for transforming messy data you find in the wild into a tidy, more useful format to summarise information or produce plots with.",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Putting it all together</span>"
    ]
  },
  {
    "objectID": "stats_primer.html",
    "href": "stats_primer.html",
    "title": "Statistics in R Primer",
    "section": "",
    "text": "Linear modelling in the tidyverse\nIn the second half of this book we will use statistics in R for exploratory data analysis, bioinformatics and machine learning. At this juncture its helpful to distinguish three domains in which we’ll apply statistics\nLinear models are very useful for testing for significant associations between variables, or significant differences between groups. They have the advantage of being able to correct for the effects of other variables, and thereby remove unwanted sources of variation that could otherwise reduce our ability to discover true relationships.\nLinear modeling is essentially a two-step process: fitting a straight line through the data (making a linear model of the relationship between x and y), and then testing whether the slope of that line is ‘greater than would be expected by chance’ via a hypothesis test. In practice the slope and variance around the fitted line, and the p value for the hypothesis test, are estimated using a single function and reported in the same summary table.\nIn the R tidyverse, plotting data is a central part of exploratory data analysis, with ggplot2 as the foundational package. We will reuse the data from Chapter 5 to investigate linear modeling in the tidyverse.\nFirst we load the .Rdata file to restore the environment objects (data frames) we created:\nload('data_processed/mousezempic_cleaned_joined.Rdata')\nlibrary(tidyverse)\nlibrary(tidyrstats)",
    "crumbs": [
      "Statistics in R Primer"
    ]
  },
  {
    "objectID": "stats_primer.html#testing-differences-between-groups-discrete-x",
    "href": "stats_primer.html#testing-differences-between-groups-discrete-x",
    "title": "Statistics in R Primer",
    "section": "Testing differences between groups (discrete x)",
    "text": "Testing differences between groups (discrete x)\nLong format data works seamlessly with ggplot(), as follows:\n\nm_exp_rep_summed\n\n# A tibble: 1,359 × 4\n   id_num group     gene  expression_level\n    &lt;dbl&gt; &lt;chr&gt;     &lt;chr&gt;            &lt;dbl&gt;\n 1      1 treatment Th               6204.\n 2      1 treatment Prlh             1045.\n 3      1 treatment Hprt1            3029.\n 4      2 treatment Th              10738.\n 5      2 treatment Prlh             1568.\n 6      2 treatment Hprt1            3669.\n 7      3 treatment Th              12918.\n 8      3 treatment Prlh              813.\n 9      3 treatment Hprt1            4297.\n10      4 treatment Th              10892.\n# ℹ 1,349 more rows\n\nm_exp_rep_summed %&gt;% \n  ggplot(aes(x=group,y=expression_level)) +\n  geom_boxplot() + \n  facet_wrap(~gene, scales='free')\n\n\n\n\n\n\n\n\nOften in an exploratory data analysis, we want to quickly test for statistically significant differences in the data we have just plotted.\nHere, we want to test the differences in mean gene expression by treatment, for each gene. The lm_test() function from tidyrstats allows us to do this using the exact same data format required for ggplot.\nlm_test() is simply a wrapper for some fairly awful code that we would otherwise have to use here (in the form data %&gt;% do(broom::tidy(lm(y~x, data = .)).\nLet’s see how this works below, by grouping the data so that we have a separate test for each gene:\n\nm_exp_rep_summed %&gt;% \n  group_by(gene) %&gt;% \n  lm_test(expression_level ~ group)\n\nResults for linear model: expression_level ~ group\n\n\n# A tibble: 6 × 6\n  gene  term           estimate std.error statistic   p.value\n  &lt;chr&gt; &lt;chr&gt;             &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;\n1 Hprt1 intercept        2951.       43.3     68.1  2.07e-239\n2 Prlh  intercept         906.       25.0     36.3  8.43e-136\n3 Th    intercept        9192.      333.      27.6  6.94e- 99\n4 Prlh  grouptreatment    218.       28.7      7.60 1.72e- 13\n5 Th    grouptreatment   1716.      382.       4.49 9.12e-  6\n6 Hprt1 grouptreatment     72.4      49.7      1.46 1.46e-  1\n\n\nWe can ignore the intercept term rows, and inspect the p value column for significant values (p&lt;0.05).\nWe see that Prlh and Th show significant differences in expression between treatment and control groups. In the model formulation expression_level ~ group, the control group mean is the intercept, and the treatment group is the tested term.",
    "crumbs": [
      "Statistics in R Primer"
    ]
  },
  {
    "objectID": "stats_primer.html#testing-differences-relative-to-0-discrete-x",
    "href": "stats_primer.html#testing-differences-relative-to-0-discrete-x",
    "title": "Statistics in R Primer",
    "section": "Testing differences relative to 0 (discrete x)",
    "text": "Testing differences relative to 0 (discrete x)\nIf we use lm_test(expression_level ~ 0 + group) we will get the mean expression per group as the estimate, and the difference in each group mean from 0, is tested. However, the differences between the mean gene expression levels in each group, are not directly tested:\n\nm_exp_rep_summed %&gt;% \n  group_by(gene) %&gt;% \n  lm_test(expression_level ~ 0 + group)\n\nResults for linear model: expression_level ~ 0 + group\n\n\n# A tibble: 6 × 6\n  gene  term           estimate std.error statistic   p.value\n  &lt;chr&gt; &lt;chr&gt;             &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;\n1 Hprt1 grouptreatment    3023.      24.4     124.  0        \n2 Prlh  grouptreatment    1124.      14.1      79.9 2.01e-268\n3 Hprt1 groupcontrol      2951.      43.3      68.1 2.07e-239\n4 Th    grouptreatment   10908.     188.       58.2 9.99e-212\n5 Prlh  groupcontrol       906.      25.0      36.3 8.43e-136\n6 Th    groupcontrol      9192.     333.       27.6 6.94e- 99\n\n\nNote that the p values are wildly significant (because every gene in each group has vastly higher expression than 0). However, we cannot easily conclude whether the treatment is having a significant effect on gene expression compared to control.\nTo answer this question requires a second round of specific pair-wise ‘contrast testing’, which is most relevant for RNA sequencing analysis, covered in later chapters.",
    "crumbs": [
      "Statistics in R Primer"
    ]
  },
  {
    "objectID": "stats_primer.html#testing-associations-between-variables-continuous-x",
    "href": "stats_primer.html#testing-associations-between-variables-continuous-x",
    "title": "Statistics in R Primer",
    "section": "Testing associations between variables (continuous x)",
    "text": "Testing associations between variables (continuous x)\nWe can also test for associations between a continuous x and a continuous y variable, using lm_test(). To plot expression of different genes in a scatter plot, values for each gene must reside in separate columns\n\n m_exp_rep_summed_wide %&gt;% \n   ggplot( aes(x = Th, y = Prlh)) +\n    geom_point() +\n   geom_smooth(method='lm')\n\n\n\n\n\n\n\n\nThe same tibble can be fed directly into lm_test() to test the significance of the Prlh ~ Th gene expression association described by the geom_smooth() line above.\n\nm_exp_rep_summed_wide %&gt;% \n  lm_test(Prlh ~ Th)\n\nResults for linear model: Prlh ~ Th\n\n\n# A tibble: 2 × 5\n  term        estimate std.error statistic  p.value\n  &lt;chr&gt;          &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;    &lt;dbl&gt;\n1 intercept 1035.       40.6        25.5   2.02e-89\n2 Th           0.00348   0.00366     0.948 3.43e- 1\n\n\nThe y intercept is ~1000, and for each incremental unit of increase in expression of Th, Prlh is predicted to increase by a further 0.003 units. This association is not significantly stronger than would be expected by chance, as the T statistic is 0.9, and the p value for the T test is 0.34.",
    "crumbs": [
      "Statistics in R Primer"
    ]
  },
  {
    "objectID": "stats_primer.html#correcting-for-covariates",
    "href": "stats_primer.html#correcting-for-covariates",
    "title": "Statistics in R Primer",
    "section": "Correcting for covariates",
    "text": "Correcting for covariates\nThus far we have tested relationships between a single covariate and a response (y) variable.\nOften we want to ensure that other possible sources of variation are minimized so that we can better detect true differences, aka test our ‘main effect of interest’. Say we want to understand whether the Mousezempic dosage affects gene expression regardless of mouse strain. That is, we want to subtract the mean effect of any strain-specific differences.\nFirst to inspect any differences in gene expression between strains:\n\nm_joined_data_long %&gt;%\n  ggplot(aes(y = expression, x = mouse_strain)) + geom_boxplot()  +\n  geom_jitter(size = 0.2, height = 0, width = 0.2) +\n  facet_wrap( ~ gene, scales = 'free_y')\n\n\n\n\n\n\n\n\nWe can see there are modest (likely non-significant) differences in mean gene expression between strains.\nFor the gene Prlh we can plot the expression ~ dose relationship colouring points by mouse strain:\n\nm_joined_data_long %&gt;%\n  filter(gene == 'Prlh') %&gt;%\n  ggplot(aes(x = drug_dose_g, y = expression)) +\n  geom_point(aes(col = mouse_strain))  +\n  geom_smooth(method = 'lm') + \n  ggtitle('Prlh gene')\n\n\n\n\n\n\n\n\nTo test the association between drug dose and gene expression without correcting for mouse strain (i.e., testing the slope of the fitted blue line above):\n\nm_joined_data_long %&gt;% \n  filter(gene=='Prlh') %&gt;% \n  lm_test(expression ~ drug_dose_g)\n\nResults for linear model: expression ~ drug_dose_g\n\n\n# A tibble: 2 × 5\n  term        estimate std.error statistic   p.value\n  &lt;chr&gt;          &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;\n1 intercept       967.      219.     4.41  0.0000140\n2 drug_dose_g   76201.   108876.     0.700 0.484    \n\n\nTo estimate and then remove any gene expression differences between strains, before testing the drug treatment association, we can use the model expression ~ drug_dose_g + strain.\n\nm_joined_data_long %&gt;% \n  filter(gene=='Prlh') %&gt;% \n  lm_test(expression ~ drug_dose_g + mouse_strain)\n\nResults for linear model: expression ~ drug_dose_g + mouse_strain\n\n\n# A tibble: 4 × 5\n  term                estimate std.error statistic p.value\n  &lt;chr&gt;                  &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;   &lt;dbl&gt;\n1 intercept             1145.      452.     2.53    0.0117\n2 mouse_strainCD-1       -20.4      43.0   -0.474   0.636 \n3 mouse_strainBlack 6     12.3      65.0    0.189   0.850 \n4 drug_dose_g          -9768.   229977.    -0.0425  0.966 \n\n\nNotice that the p value for the drug_dose_g (our main effect of interest), is 0.48 before correcting for mouse strain, and 0.96 after correcting.\nThis indicates that there is less effect of drug dose on gene expression than we would otherwise have reported. Put another way, the slightly stronger association between drug dose and Prlh expression using the model expression ~ drug_dose_g, is simply the result of underlying differences in gene expression between strains!\n\n\n\n\n\n\nMarginal vs Conditional effects\n\n\n\nThe estimate (slope) for a simple linear model with a single x variable, is called the ‘marginal effect’.\nThe estimates for a multiple linear regression model (where effects for each covariate are calculated after setting the mean effect of all other covariates to 0), are called ‘conditional effects.’\nIn order to create a scatter plot that displays the expression ~ drug_dose_g relationship corrected for mouse strain, we would have to subtract the average effect of mouse strain on gene expression, from each data point depending on the strain of that animal.\nThis is called ‘conditioning’ or ‘residualisation’ and is beyond the scope of this course. Just be aware that a multiple linear regression model that finds very low p values for a main effect of interest, may be difficult to show graphically without ‘residualising the data’.",
    "crumbs": [
      "Statistics in R Primer"
    ]
  },
  {
    "objectID": "chapter_6.html",
    "href": "chapter_6.html",
    "title": "6  RNA-seq - Part 1",
    "section": "",
    "text": "6.1 Data files\nIn this chapter we will run through the basic steps for analysing a simple RNA-seq experiment using the limma-voom workflow. This includes:\nCompared to the original article linked above, this workflow has been modified for simplicity but retains all the crucial steps and concepts.\nThe aim of this chapter is to give you experience with a real-world RNA-seq analysis, and making extensive use of an external library. We will not cover the statistics in any depth. Instead, the goal is to understand how to construct data structures required for specific packages and how to use the functions in those packages to perform the analysis.\nMuch of the materials here are explained in greater detail in the limma user’s guide. You can view this by typing help(\"limma\") and following the links.\nWe will work with a counts matrix similar to that generated by Subread featureCounts, and an Entrez gene annotation file.\nDownload RNAseq counts\nDownload mouse gene annotations\nSave these files in the data/ directory within your R project parent directory.",
    "crumbs": [
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>RNA-seq - Part 1</span>"
    ]
  },
  {
    "objectID": "chapter_6.html#r-packages",
    "href": "chapter_6.html#r-packages",
    "title": "6  RNA-seq - Part 1",
    "section": "6.2 R Packages",
    "text": "6.2 R Packages\nLet’s load edgeR (Estimating Digital Gene Expression in R), which also loads the limma package. We also load the tidyverse packages, which will be used to extract and plot data from the edgeR and limma objects.\n\nlibrary(edgeR)\nlibrary(tidyverse)\n\nIf you get an error, the package can be downloaded by the following commands.\n\nif (!requireNamespace(\"BiocManager\", quietly = TRUE))\n    install.packages(\"BiocManager\")\n\nBiocManager::install(\"edgeR\")",
    "crumbs": [
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>RNA-seq - Part 1</span>"
    ]
  },
  {
    "objectID": "chapter_6.html#loading-in-read-count-data-and-annotation",
    "href": "chapter_6.html#loading-in-read-count-data-and-annotation",
    "title": "6  RNA-seq - Part 1",
    "section": "6.3 Loading in read count data and annotation",
    "text": "6.3 Loading in read count data and annotation\nThe data we are looking at comes from three cell populations (basal, luminal progenitor (LP) and mature luminal (ML)) sorted from the mammary glands of female virgin mice, each profiled in triplicate. These samples have been sequenced using Illumina RNAseq platforms and we will be using the edgeR package to analyse the data.\nLet’s read in the raw counts and gene annotation data:\n\ncounts_tbl &lt;- read_tsv('data/rnaseq_counts.tsv')\n\ngene_anno &lt;- read_tsv('data/Ses3_geneAnnot.tsv')",
    "crumbs": [
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>RNA-seq - Part 1</span>"
    ]
  },
  {
    "objectID": "chapter_6.html#creating-the-dgelist-object",
    "href": "chapter_6.html#creating-the-dgelist-object",
    "title": "6  RNA-seq - Part 1",
    "section": "6.4 Creating the DGEList object",
    "text": "6.4 Creating the DGEList object\nTo use the edgeR package we first need to construct a DGEList object. This object contains 3 key pieces of data:\n\ncounts: the main data of this object, a matrix of count values with samples along the columns and features/genes along the rows. All data must be numeric!\nsamples: a data frame containing annotation for the samples. The rows in this table describe the corresponding column of the counts data. samples is created automatically by the DGEList() function.\ngenes: a data frame containing annotation for the genes in the counts matrix. The rows in this table describe the corresponding row in the counts matrix. Importantly, the row order for counts and genes must be identical for your analysis to run as expected!\n\n\n\n\n\n\n\nData objects\n\n\n\nData objects in general are a way to store related pieces of information together. Often they provide features to maintain the relationships between the pieces of information. For example, in a DGEList object, the counts are stored as a matrix while samples and genes are stored as data frames. When you subset the DGEList object, the rows and columns of the counts matrix are subset along with the corresponding rows of the samples and genes data frames. This prevents errors that can occur if the user tries to manually subset all three pieces of information separately.\n\n\nA common way to create a DGEList object is to read in the count data as a matrix or data frame, and then create the DGEList object using the DGEList() function.\n\nWhat you can do with data objects is determined by package that the object comes from. You will need to read the package documentation to find out how to access data from the object. Here edgeR informs us that the DGEList has data that can be accessed as if it was a list.\n\nDGEList converts numeric data into matrix format for the counts element.\n\ndge &lt;- DGEList(counts = counts_tbl %&gt;% select(-1),\n               genes = gene_anno)\n\nThe samples table is automatically created based on information in counts\n\ndge$samples\n\n          group lib.size norm.factors\n10_6_5_11     1 32863052            1\n9_6_5_11      1 35335491            1\npurep53       1 57160817            1\nJMS8-2        1 51368625            1\nJMS8-3        1 75795034            1\nJMS8-4        1 60517657            1\nJMS8-5        1 55086324            1\nJMS9-P7c      1 21311068            1\nJMS9-P8c      1 19958838            1\n\n\nWe have the library size (column sums for counts matrix) pre-computed. Note that the experimental group has not yet been defined. To do this we first create a text vector encoded as a factor.\n\n6.4.1 A brief detour to factors\nAccording to the original experimental description, the counts in each column are either from basal, luminal progenitor (LP) or mature luminal (ML) cell populations. The exact experimental groups are as follows\n\ngroups &lt;- c(\"LP\", \"ML\", \"Basal\", \"Basal\", \"ML\", \"LP\", \"Basal\", \"ML\", \"LP\")\n\ngroups &lt;- parse_factor(groups,  levels = c(\"Basal\", \"LP\", \"ML\"))\n\nNote that when we declared the groups variable, we used factors. Factors are a special data type that is used to encode categorical variables. They have multiple useful properties in comparison to regular character vectors: - They allow you to specify the order of the levels. - They are stored as integers but displayed as labels. - They encode all the valid levels of the factor, even if they are not present in the data.\nSpecifying the order of the levels is useful because it allows you to re-arrange labels when used in plots. In this data we would have the “Basal” group first, followed by “LP” and then “ML”. Using parse_factor() also allows you to check that the values are all valid levels, for example if one of the samples was labelled “Bassal” instead of “Basal”, it would throw an error. You can read the R for Data Science chapter on factors for more information, as well as the forcats package for many useful functions for working with factors.",
    "crumbs": [
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>RNA-seq - Part 1</span>"
    ]
  },
  {
    "objectID": "chapter_6.html#finalising-the-dgelist-object",
    "href": "chapter_6.html#finalising-the-dgelist-object",
    "title": "6  RNA-seq - Part 1",
    "section": "6.5 Finalising the DGEList object",
    "text": "6.5 Finalising the DGEList object\nTo specify the experimental groups, we can update the group column in the samples table as follows:\n\ndge$samples$group &lt;- groups\n\nLastly we can set the rownames (a text vector) for the counts and genes tables, which is useful to avoid losing information downstream.\n\nrownames(dge$counts) &lt;-  counts_tbl %&gt;% pull(ENTREZID)\n\nrownames(dge$genes) &lt;-  gene_anno %&gt;% pull(ENTREZID)\n\nhead(dge$counts)\n\n          10_6_5_11 9_6_5_11 purep53 JMS8-2 JMS8-3 JMS8-4 JMS8-5 JMS9-P7c\n497097            1        2     342    526      3      3    535        2\n100503874         0        0       5      6      0      0      5        0\n100038431         0        0       0      0      0      0      1        0\n19888             0        1       0      0     17      2      0        1\n20671             1        1      76     40     33     14     98       18\n27395           431      771    1368   1268   1564    769    818      468\n          JMS9-P8c\n497097           0\n100503874        0\n100038431        0\n19888            0\n20671            8\n27395          342\n\nhead(dge$genes)\n\n           ENTREZID  SYMBOL TXCHROM\n497097       497097    Xkr4    chr1\n100503874 100503874 Gm19938    &lt;NA&gt;\n100038431 100038431 Gm10568    &lt;NA&gt;\n19888         19888     Rp1    chr1\n20671         20671   Sox17    chr1\n27395         27395  Mrpl15    chr1\n\n\nNow we have a data object that can be used for downstream analysis.",
    "crumbs": [
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>RNA-seq - Part 1</span>"
    ]
  },
  {
    "objectID": "chapter_6.html#filtering",
    "href": "chapter_6.html#filtering",
    "title": "6  RNA-seq - Part 1",
    "section": "6.6 Filtering",
    "text": "6.6 Filtering\nThe first step of our analysis is to filter out lowly expressed genes. There are two main problems with low abundant genes:\n\nTechnical variation is more problematic for low abundance genes. This variation is thought to be due to two factors; insufficient mixing and low sampling fraction1.\n\nInsufficient mixing of solutions during library preparation can result in uneven distribution of reads.\nRNA sequencing can be thought of as sampling. Measurement errors will occur simply due to the random nature of the sampling process. This problem affects lowly abundant RNA species more because the relative error for small count values is larger than it would be for more highly abundant RNA species.\n\nGenes that are very lowly expressed do not produce sufficient information to be useful for biological interpretation. For example, it is very hard to believe the biological significance of genes that have counts ranging from 0 to 3 across samples even if come up as statistically significant.\n\nRemoving these highly variable, lowly expressed genes increases your ‘power’ to detect differentially expressed genes2, where ‘power’ is your ability to detect true positives. In testing for differential expression, a statistical test is conducted for each gene. When a high number of statistical tests are performed, a portion of them will be significant purely due to random chance. A common procedure to control for the number of false positive is to perform ‘multiple testing correction’ on the p-values. This adjusts the p-value in a way that reduces the number of false positives but comes at the cost of reduced power to detect true positives. If we filter out uninteresting, lowly expressed genes, we need to perform fewer statistical tests and reduce the impact that multiple testing adjustment has on detection power.\nThe edgeR provides the filterByExpr() function to automate gene filtering. By default, it aims to keep genes with a count of 10 or more, in at least as many samples as the smallest experimental group. In our experiment, there are 3 phenotype groups each with 3 samples. Therefore we retain only genes that have 10 or more counts in 3 or more samples. The actual filtering is done on counts per million, prevent bias against samples with small library sizes. This complex procedure is the reason why the package provides a function to perform the filtering for you.\nThe output of this function is a vector of logicals, indicating which genes (rows) should be kept and which filtered.\nIts good practice to create a new DGEList for each step of the filtering and normalization process, to allow easy before-and-after comparisons. We create dge_filt here:\n\nkeep &lt;- filterByExpr(dge)\ntable(keep)\n\nkeep\nFALSE  TRUE \n10555 16624 \n\nproportions(table(keep))\n\nkeep\n    FALSE      TRUE \n0.3883513 0.6116487 \n\ndge_filt &lt;- dge[keep, , keep.lib.sizes = FALSE]\n\nCompare the effect of filtering out lowly-expressed genes on the data dimensions\n\ndim(dge)\n\n[1] 27179     9\n\ndim(dge_filt)\n\n[1] 16624     9\n\n\nWe can see that we now have 16624 genes. We started with 27179 genes - meaning that ~40% of genes have been filtered out.",
    "crumbs": [
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>RNA-seq - Part 1</span>"
    ]
  },
  {
    "objectID": "chapter_6.html#library-size-normalisation",
    "href": "chapter_6.html#library-size-normalisation",
    "title": "6  RNA-seq - Part 1",
    "section": "6.7 Library-size normalisation",
    "text": "6.7 Library-size normalisation\nAfter filtering, our next step is to normalise the data. Normalisation refers to the process of adjusting the data to reduce or eliminate systematic bias. This allows the data to be meaningfully compared across samples or experimental groups.\nThere are two main factors that need to be normalised for in RNA-seq:\n\nSequencing depth/library size - technically, sequencing a sample to half the depth will give, on average, half the number of reads mapping to each gene3.\nRNA composition - if a large number of genes are unique to, or highly expressed in, only one experimental condition, the sequencing capacity available for the remaining genes in that sample is decreased. For example, if there are only five genes being studied in two experimental groups, if one gene is particularly high in group A, then with limited sequencing depth, that gene will reduce the counts of the remaining four genes. The effect of this is that the remaining four genes appear under-expressed in group A compared to group B when the true amount of gene product is actually equal for these 4 genes3.\n\nSequencing depth is accounted for by calculating the counts per million (cpm). This metric is calculated by:\n\ntaking the library size (sum of all counts for a sample),\ndividing this by 1,000,000 to get the ‘per million’ scaling factor,\nthen dividing all read counts for each gene in that sample by the ‘per million’ scaling factor\n\nRNA composition can be accounted for by using more sophisticated normalisation methodologies. We will use ‘trimmed mean of M-values’ (TMM), which estimates relative RNA levels from RNA-seq data3. Under the assumption that most genes are not differentially expressed, TMM calculates a library size scaling factor for each library (sample). This is done using the following steps:\n\ncalculate the gene expression log fold changes and absolute expression values for pair-wise samples (selecting one sample from the experiment as a reference)\nremove the genes with the highest and lowest fold changes and absolute expression values\ntake a weighted mean of the remaining genes (where the weight is the inverse of the approximate asymptotic variances). This gives the normalisation factor for each library (sample)\n\nSubsequent steps in this analysis will use log-cpm values, calculated using the normalisation factors, which scales each library size.\nWe can calculate the normalisation factors, specifying that we want to use the \"TMM\" method. We now create dge_norm from dge_filt.\n\ndge_norm &lt;- calcNormFactors(dge_filt, method = \"TMM\")\n\nThis function calculates the normalisation factors for each library (sample) and puts this information in the samples data frame. Note that it takes dge (our DGEList object as input) and returns a DGEList object as well.\nLet’s take a look at our normalisation factors:\n\ndge_norm$samples\n\n          group lib.size norm.factors\n10_6_5_11    LP 32857304    0.8943956\n9_6_5_11     ML 35328624    1.0250186\npurep53   Basal 57147943    1.0459005\nJMS8-2    Basal 51356800    1.0458455\nJMS8-3       ML 75782871    1.0162707\nJMS8-4       LP 60506774    0.9217132\nJMS8-5    Basal 55073018    0.9961959\nJMS9-P7c     ML 21305254    1.0861026\nJMS9-P8c     LP 19955335    0.9839203\n\n\nThese normalisation factors are all close to 1 for all samples, suggesting minimal difference in RNA composition between samples.",
    "crumbs": [
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>RNA-seq - Part 1</span>"
    ]
  },
  {
    "objectID": "chapter_6.html#extracting-tidy-tables",
    "href": "chapter_6.html#extracting-tidy-tables",
    "title": "6  RNA-seq - Part 1",
    "section": "6.8 Extracting tidy tables",
    "text": "6.8 Extracting tidy tables\nFor ease of tidy data manipulation and plotting, at this point let’s extract tidy tables from the tables nested within the DGEList!\n\nsamples_tbl &lt;- dge_norm$samples %&gt;% as_tibble(rownames = 'id')\n\ncounts_raw_tbl  &lt;- dge$counts %&gt;% as_tibble(rownames='gene')\n\ncounts_filt_tbl &lt;- dge_filt$counts %&gt;% as_tibble(rownames='gene')",
    "crumbs": [
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>RNA-seq - Part 1</span>"
    ]
  },
  {
    "objectID": "chapter_6.html#visualising-the-effect-of-normalisation",
    "href": "chapter_6.html#visualising-the-effect-of-normalisation",
    "title": "6  RNA-seq - Part 1",
    "section": "6.9 Visualising the effect of normalisation",
    "text": "6.9 Visualising the effect of normalisation\nTo visualise the effect of TMM normalisation, we can plot the log-counts as a boxplot, and observe the effect of applying the normalisation. To create a boxplot of the log-counts, we can use log(dge$counts + 0.5) to create the log-count matrix. The addition of 0.5 is to avoid taking the log of zero. Then in order to use ggplot2 for plotting, we must convert the matrix to a data frame. We can use the as_tibble(rownames = \"gene\") function to convert the matrix to a data frame where the rownames are converted to a column called “gene”. We can then use the pivot_longer() function to convert the data frame from wide format to long format, where each row represents a single observation. This is necessary for ggplot2 to plot the data correctly.\n\ncounts_raw_tbl %&gt;% \n  pivot_longer(cols = -gene,\n               names_to = \"sample\", values_to = \"counts\"\n  ) %&gt;% \n  mutate(log_counts  = log10(counts + 0.5)) %&gt;% \n  ggplot(aes(x = sample, y = log_counts)) +\n  geom_boxplot() +\n  ggtitle('Log-transformed raw counts, before filtering')\n\n\n\n\n\n\n\ncounts_filt_tbl %&gt;% \n   pivot_longer(cols = -gene,\n               names_to = \"sample\", values_to = \"counts\"\n  ) %&gt;% \n  mutate(log_counts  = log10(counts + 0.5)) %&gt;% \n  ggplot(aes(x = sample, y = log_counts)) +\n  geom_boxplot() +\n  ggtitle('Log-transformed raw counts, after filtering')\n\n\n\n\n\n\n\n\nWe can compare this to the cpm values which when calculated using the cpm() function, automatically applies normalisation factors if they are present.\n\nlogcpm_tbl &lt;- cpm(dge_norm$counts, log=T) %&gt;% as_tibble(rownames='gene')\n\n\nlogcpm_tbl %&gt;% \n  pivot_longer(cols = -gene,\n               names_to = \"sample\", \n               values_to = \"log_cpm\") %&gt;% \n  ggplot(aes(x = sample, y = log_cpm)) +\n  geom_boxplot() +\n  ggtitle('Expression normalized by lib size [CPM] and complexity [TMM]')\n\n\n\n\n\n\n\n\nWe see that by performing normalisation on our data, the gene expression values of each sample now have similar medians and quantiles. This indicates that the relative expression values of each sample can be more meaningfully compared.",
    "crumbs": [
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>RNA-seq - Part 1</span>"
    ]
  },
  {
    "objectID": "chapter_6.html#mds-plots",
    "href": "chapter_6.html#mds-plots",
    "title": "6  RNA-seq - Part 1",
    "section": "6.10 MDS plots",
    "text": "6.10 MDS plots\nBefore we perform statistical tests, it’s useful to perform some exploratory visual analysis to get an overall idea of how our data is behaving.\nMDS is a way to visualise distances between sets of data points (samples in our case). It is a dimensionality reduction technique, similar to principal components analysis (PCA). We treat gene expression in samples as if they were coordinates in a high-dimensional coordinate system, then we can find “distances” between samples as we do between points in space. Then the goal of the algorithm is to find a representation in lower dimensional space such that points that the distance of two objects from each other in high dimensional space is preserved in lower dimensions.\nThe plotMDS() from limma creates an MDS plot from a DGEList object.\n\nplotMDS(dge_norm)\n\n\n\n\n\n\n\n\nEach point on the plot represents one sample and is ‘labelled’ using the sample name. The distances between each sample in the resulting plot can be interpreted as the typical log2-fold-change between the samples, for the most differentially expressed genes.\nWe can change the labelling to use the name of the group the sample belongs to instead:\n\nplotMDS(dge_norm, labels = groups)\n\n\n\n\n\n\n\n\nThis shows us that the phenotype groups tend to cluster together, meaning that the gene expression profiles are similar for samples within a phenotype group. The ‘Basal’ type samples quite close together while the ‘LP’ (luminal progenitor) and ‘ML’ (mature luminal) type samples are further apart, signifying that their expression profiles are more variable.",
    "crumbs": [
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>RNA-seq - Part 1</span>"
    ]
  },
  {
    "objectID": "chapter_6.html#mds-plot-using-ggplot2",
    "href": "chapter_6.html#mds-plot-using-ggplot2",
    "title": "6  RNA-seq - Part 1",
    "section": "6.11 MDS plot using ggplot2",
    "text": "6.11 MDS plot using ggplot2\nFor more customisability and better consistency with the style of other plots, it’d be nice to be able to draw the MDS plot using ggplot2. In order to do this we would need the MDS coordinates calculated by plotMDS(). Luckily the documentation of plotMDS() shows that it returns multiple computed values.\n\nmds_result &lt;- plotMDS(dge_norm, plot = FALSE)\nmds_result\n\nAn object of class MDS\n$eigen.values\n[1]  6.844419e+01  1.154413e+01  3.790044e+00  2.994025e+00  2.021565e+00\n[6]  1.613173e+00  1.202805e+00  1.094072e+00 -7.018692e-16\n\n$eigen.vectors\n            [,1]        [,2]        [,3]         [,4]        [,5]        [,6]\n [1,] -0.2461859  0.54036454  0.12401524  0.677678569  0.20623170  0.07294476\n [2,] -0.2851986 -0.33460855  0.67471878  0.007007206 -0.46099085  0.15319914\n [3,]  0.4690174 -0.04145263  0.05041410  0.056945694 -0.03695319 -0.03494949\n [4,]  0.4711165 -0.04907588  0.05443024  0.161230059 -0.03439028 -0.55065413\n [5,] -0.2626081 -0.18747095  0.18504793 -0.355202862  0.66319443 -0.33464804\n [6,] -0.1568565  0.41423458 -0.09091514 -0.468642654  0.04620796  0.26492304\n [7,]  0.4670465  0.01138476 -0.03115306 -0.161357159  0.07822632  0.56941932\n [8,] -0.2405667 -0.57831836 -0.56474831  0.302172046  0.07568690  0.20422089\n [9,] -0.2157647  0.22494250 -0.40180977 -0.219830899 -0.53721300 -0.34445549\n             [,7]         [,8]       [,9]\n [1,] -0.11742920 -0.004177629 -0.3333333\n [2,]  0.04463732 -0.048147665 -0.3333333\n [3,]  0.03859114  0.810760474 -0.3333333\n [4,]  0.33482254 -0.468041790 -0.3333333\n [5,] -0.26519650  0.047152480 -0.3333333\n [6,]  0.62647876 -0.002850499 -0.3333333\n [7,] -0.44130343 -0.344258233 -0.3333333\n [8,]  0.19689394 -0.010674134 -0.3333333\n [9,] -0.41749458  0.020236996 -0.3333333\n\n$var.explained\n[1] 0.73830888 0.12452679 0.04088328 0.03229660 0.02180666 0.01740133 0.01297468\n[8] 0.01180178 0.00000000\n\n$dim.plot\n[1] 1 2\n\n$distance.matrix.squared\n           10_6_5_11   9_6_5_11   purep53    JMS8-2     JMS8-3     JMS8-4\n10_6_5_11 -18.127013  -5.738791  16.10192  16.03204  -5.792252 -8.3908112\n9_6_5_11   -5.738791 -18.115187  17.75982  17.85109 -11.197198 -2.5513014\npurep53    16.101924  17.759816 -31.64208 -29.63783  16.733543 10.6453322\nJMS8-2     16.032036  17.851094 -29.63783 -32.34830  16.749432 11.0446228\nJMS8-3     -5.792252 -11.197198  16.73354  16.74943 -13.580395 -4.1528811\nJMS8-4     -8.390811  -2.551301  10.64533  11.04462  -4.152881 -9.8867331\nJMS8-5     15.954448  18.363197 -29.18038 -28.91308  16.698190  9.6067888\nJMS9-P7c   -1.642914 -10.966083  15.03939  15.00405  -9.571938  0.3388923\nJMS9-P8c   -8.396628  -5.405548  14.18030  14.21798  -5.886502 -6.6539093\n              JMS8-5    JMS9-P7c   JMS9-P8c\n10_6_5_11  15.954448  -1.6429143  -8.396628\n9_6_5_11   18.363197 -10.9660831  -5.405548\npurep53   -29.180384  15.0393893  14.180296\nJMS8-2    -28.913082  15.0040512  14.217981\nJMS8-3     16.698190  -9.5719377  -5.886502\nJMS8-4      9.606789   0.3388923  -6.653909\nJMS8-5    -31.824715  15.4926837  13.802874\nJMS9-P7c   15.492684 -18.8595492  -4.834532\nJMS9-P8c   13.802874  -4.8345322 -11.024033\n\n$top\n[1] 500\n\n$gene.selection\n[1] \"pairwise\"\n\n$axislabel\n[1] \"Leading logFC dim\"\n\n$x\n[1] -2.036721 -2.359477  3.880228  3.897594 -2.172583 -1.297689  3.863923\n[8] -1.990232 -1.785043\n\n$y\n[1]  1.83597803 -1.13688798 -0.14084219 -0.16674343 -0.63696359  1.40743060\n[7]  0.03868159 -1.96493242  0.76427939\n\n\nWe see that there’s are x and y values in the list returned by the plotMDS() function, we can put these into a table and see if they match up to the positions plotted by the function.\n\nmds_tbl &lt;- tibble(\n  id = samples_tbl %&gt;% pull(id),\n  dim1 = mds_result$x,\n  dim2 = mds_result$y\n) %&gt;% print()\n\n# A tibble: 9 × 3\n  id         dim1    dim2\n  &lt;chr&gt;     &lt;dbl&gt;   &lt;dbl&gt;\n1 10_6_5_11 -2.04  1.84  \n2 9_6_5_11  -2.36 -1.14  \n3 purep53    3.88 -0.141 \n4 JMS8-2     3.90 -0.167 \n5 JMS8-3    -2.17 -0.637 \n6 JMS8-4    -1.30  1.41  \n7 JMS8-5     3.86  0.0387\n8 JMS9-P7c  -1.99 -1.96  \n9 JMS9-P8c  -1.79  0.764 \n\nggplot(mds_tbl, aes(x = dim1, y = dim2)) +\n  geom_point()\n\n\n\n\n\n\n\n\nThe positions of the points and the range of the scales seem to match, so we want to add in more metadata to help use plot. We can try to recreate the MDS plot using just ggplot2.\nFirst we extract the transcriptional variance explained by each dimension into a tibble, and add a column defining the dimensions.\n\nvar_expln &lt;- tibble(propn = mds_result$var.explained * 100 ) |&gt; \n    rownames_to_column(var = 'dimension') \n\nDimensions 1 and 2 are plotted by default. We can now extract and round the proportion of variance explained in rows 1 and 2 of the var_expln tibble\n\ndim1_expl &lt;- var_expln |&gt; filter(dimension==1) |&gt; pull(propn) |&gt; round()\ndim2_expl &lt;- var_expln |&gt; filter(dimension==2) |&gt; pull(propn) |&gt; round()\n\nFinally we join the full sample metadata with the MDS coordinates for plotting, using left_join()\n\nmds_tbl_label &lt;- left_join(samples_tbl, mds_tbl, by = 'id') %&gt;% \n  print()\n\n# A tibble: 9 × 6\n  id        group lib.size norm.factors  dim1    dim2\n  &lt;chr&gt;     &lt;fct&gt;    &lt;dbl&gt;        &lt;dbl&gt; &lt;dbl&gt;   &lt;dbl&gt;\n1 10_6_5_11 LP    32857304        0.894 -2.04  1.84  \n2 9_6_5_11  ML    35328624        1.03  -2.36 -1.14  \n3 purep53   Basal 57147943        1.05   3.88 -0.141 \n4 JMS8-2    Basal 51356800        1.05   3.90 -0.167 \n5 JMS8-3    ML    75782871        1.02  -2.17 -0.637 \n6 JMS8-4    LP    60506774        0.922 -1.30  1.41  \n7 JMS8-5    Basal 55073018        0.996  3.86  0.0387\n8 JMS9-P7c  ML    21305254        1.09  -1.99 -1.96  \n9 JMS9-P8c  LP    19955335        0.984 -1.79  0.764 \n\n\nTo recreate the plotMDS plot:\n\nmds_tbl_label |&gt; \n  ggplot(aes(x=dim1, y=dim2)) + \n  geom_text(aes(label = group)) + \n  labs(x = paste0('Dim 1 variance explained = ', dim1_expl,'%'),\n       y = paste0('Dim 2 variance explained = ', dim2_expl,'%'))\n\n\n\n\n\n\n\n\nNow that we have our data in a nice tidy format we can use with ggplot, it’s easy to create variations of the plot. For example we can draw points instead of group labels, and use colour to identify the groups.\n\nmds_tbl_label |&gt; \n  ggplot(aes(x=dim1, y=dim2, colour = group)) + \n  geom_point() + \n  labs(x = paste0('Dim 1 variance explained = ', dim1_expl,'%'),\n       y = paste0('Dim 2 variance explained = ', dim2_expl,'%'))\n\n\n\n\n\n\n\n\nAlternatively we can also use the labels to identify the individual samples while colouring them by their group.\n\nmds_tbl_label %&gt;% \n  ggplot( aes(x = dim1, y = dim2, col = group)) +\n  geom_point() +\n  geom_text(aes(label = id)) +\n  labs(x = paste0('Dim 1 variance explained = ', dim1_expl,'%'),\n       y = paste0('Dim 2 variance explained = ', dim2_expl,'%'))\n\n\n\n\n\n\n\n\nWe see that some labels are very hard to read due to the overlapping, so we can use the ggrepel package to fix this. The ggrepel package creates labels that repel each other in order to avoid overlap. It’s a good idea to use it in conjunction with geom_point() in order to keep track of exact coordinate of the data point.\n\nlibrary(ggrepel)\n\nmds_tbl_label %&gt;% \n  ggplot( aes(x = dim1, y = dim2, col = group)) +\n  geom_point() +\n  geom_text_repel(aes(label = id)) +\n  labs(x = paste0('Dim 1 variance explained = ', dim1_expl,'%'),\n       y = paste0('Dim 2 variance explained = ', dim2_expl,'%'))",
    "crumbs": [
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>RNA-seq - Part 1</span>"
    ]
  },
  {
    "objectID": "chapter_6.html#summary",
    "href": "chapter_6.html#summary",
    "title": "6  RNA-seq - Part 1",
    "section": "6.12 Summary",
    "text": "6.12 Summary\nToday we started on the early steps of the RNA-seq analysis workflow.\n\nWe learned how to create a DGEList object, demonstrating how to create data objects required by specific packages.\nWe learned how to use edgeR’s filterByExpr() function to filter out lowly expressed genes.\nWe learned how to normalise the data using TMM normalisation.\nWe learned how to create MDS plots using both plotMDS() and ggplot2.\nWe learned how to use ggrepel to create non-overlapping labels in ggplot2 plots.\n\nThis provides a good foundation for organising data to satisfy the requirements of specific packages, and how to pull data out of the objects created by those packages. The data we pulled out can then be organised into a tidy format to leverage the power of all the tidyverse functions that we have learned so far.\nIn the next chapter we will continue the RNA-seq analysis workflow and complete our differential expression analysis.",
    "crumbs": [
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>RNA-seq - Part 1</span>"
    ]
  },
  {
    "objectID": "chapter_6.html#references",
    "href": "chapter_6.html#references",
    "title": "6  RNA-seq - Part 1",
    "section": "6.13 References",
    "text": "6.13 References\n\n\n\n\n\n\n1. McIntyre LM, Lopiano KK, Morse AM, Amin V, Oberg AL, Young LJ, et al. RNA-seq: technical variability and sampling. BMC Genomics [Internet]. 2011 Jun 6;12(1). Available from: http://dx.doi.org/10.1186/1471-2164-12-293\n\n\n2. Bourgon R, Gentleman R, Huber W. Independent filtering increases detection power for high-throughput experiments. Proceedings of the National Academy of Sciences [Internet]. 2010 May 11;107(21):9546–51. Available from: http://dx.doi.org/10.1073/pnas.0914005107\n\n\n3. Robinson MD, Oshlack A. A scaling normalization method for differential expression analysis of RNA-seq data. Genome Biology [Internet]. 2010 Mar 2;11(3). Available from: http://dx.doi.org/10.1186/gb-2010-11-3-r25",
    "crumbs": [
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>RNA-seq - Part 1</span>"
    ]
  },
  {
    "objectID": "chapter_7.html",
    "href": "chapter_7.html",
    "title": "7  RNA-seq - Part 2",
    "section": "",
    "text": "7.1 Linear modelling\nThe aim of this chapter is to complete the analysis of the RNA-seq data using the limma and edgeR packages. With the results of the analysis, we want to be able to produce publication quality figures and write out the results to a file for sharing or publication.\nFirst we run the essential code to regenerate the DGEList objects from Chapter 6.\nTo identify differentially expressed genes from our normalised gene expression data, we will use the limma package to fit linear models to the genes. A linear model is a broad class of statistical models that fit the value of an response (or dependent) variable as a linear function of one or more explanatory (or independent) variables (also called covariates).\nThe general form of a linear model looks like this:\n\\(Y = \\beta_{0} + \\beta_{1}X_{1} + \\beta_{2}X_{2}... + \\epsilon\\)\nThis equation is saying that a response variable of interest \\(Y\\) is equal to a constant (\\(\\beta_{0}\\)) plus the sum of the covariates (\\(X_{i}\\)) each multiplied by a constant coefficient (\\(\\beta_{i}\\)) and some error term (\\(\\epsilon\\)). The error term is the difference between the observed value and the predicted value of the model and is assumed to have a normal distribution with mean 0 and some variance.\nOur experiment is quite simple, since there is only a single covariate, the cell type. The true benefit of using linear models is in its ability to accommodate more complex designs including multiple covariates.\nTo fit the linear models in the limma-voom framework we need two objects in addition to our data:",
    "crumbs": [
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>RNA-seq - Part 2</span>"
    ]
  },
  {
    "objectID": "chapter_7.html#linear-modelling",
    "href": "chapter_7.html#linear-modelling",
    "title": "7  RNA-seq - Part 2",
    "section": "",
    "text": "A design matrix, representing the covariates.\nA contrast matrix, representing the specific comparison we wish to make.\n\n\n7.1.1 Design matrix\nThe first step to fitting a linear model is to specify a design matrix. The design matrix specifies the values of the covariates for each sample, and is represented as a matrix due to the mathematical convenience.\nTo generate a design matrix. We use the function model.matrix(), with the expression ~ 0 + group. This returns a matrix representing the design where there is no intercept term and group is the only covariate. This is known as a ‘means model.’ If we omit the 0 then there would be an intercept in the model, and if we included more covariates then more columns would be generated.\n\ndesign &lt;- model.matrix(~ 0 + group, data = dge_norm$samples)\ndesign\n\n          groupBasal groupLP groupML\n10_6_5_11          0       1       0\n9_6_5_11           0       0       1\npurep53            1       0       0\nJMS8-2             1       0       0\nJMS8-3             0       0       1\nJMS8-4             0       1       0\nJMS8-5             1       0       0\nJMS9-P7c           0       0       1\nJMS9-P8c           0       1       0\nattr(,\"assign\")\n[1] 1 1 1\nattr(,\"contrasts\")\nattr(,\"contrasts\")$group\n[1] \"contr.treatment\"\n\n\nThere are 9 rows, one for each sample (enabled by the rownames set on the dge_norm$samples data frame).\nThe column names correspond to the experimental groups.\nThe values in the cells denote membership of the particular sample for a particular group, as our groups in this case are mutually exclusive, each row contains only a single 1 to denote membership in a single group.\nFor an excellent comprehensive explanation of design matrices in limma, see this Further reading article.\n\n\n7.1.2 Contrasts\nContrast matrices are companions to design matrices. They are used to specify the comparison of interest. In our case, we have three experimental groups: Basal, LP and ML. So if we are to perform differential expression analysis, we are most likely interested in the differences between only two of the groups at a time. Contrast matrices let use specify which comparison we’d like to make, and are also represented as a matrix just like the design.\nA contrast matrix can be made using the makeContrasts() function. Within this function, we specify the name of each specific contrast and the formula for that contrast. For example, the BasalvsLP contrasts compares the difference between the Basal and LP groups. Note that the name of the phenotype groups must be written exactly as they are in the column names of our design matrix (see above).\nIn addition to the individual contrasts, the function must know about the design of the model. This is passed through the levels argument, which either accepts a matrix with the column names corresponding to levels of your experimental groups, or the levels themselves as a character vector. Here we first simplify the column names of our design matrix to make it easier to read. Then we create the contrast matrix using the makeContrasts() function.\n\ncolnames(design) &lt;- c(\"Basal\", \"LP\", \"ML\")\n\ncontr_matrix &lt;- makeContrasts(\n  BasalvsLP = \"Basal - LP\",\n  BasalvsML = \"Basal - ML\",\n  LPvsML = \"LP - ML\",\n  levels = design # alternatively 'levels = colnames(design)'\n)\n\ncontr_matrix\n\n       Contrasts\nLevels  BasalvsLP BasalvsML LPvsML\n  Basal         1         1      0\n  LP           -1         0      1\n  ML            0        -1     -1\n\n\nThere are two things to note about a design matrix. First, the sum of the numbers in each column is equal to 0. Second, the way that you set up the equation in the matrix will determine the interpretation of the log-fold-change calculated later, as well as the meaning of up-regulated and down-regulated genes. For example, the contrast Basal - LP will give a positive log-fold-change for genes that are up-regulated in the Basal group compared to the LP group. If we had set up the contrast as LP - Basal, then the opposite would be true, and we would get a negative log-fold-change for genes that are up-regulated in the Basal group compared to the LP group.\n\n\n7.1.3 Variance modelling with voom\nWe are now ready to fit our linear models. Limma fits linear models to the data with the assumption that the underlying data is normally distributed. Count data is generally not normally distributed, but log transforming count data gives it a roughly normal distribution sufficient for linear models to work well. To do this, limma transforms the raw count data to log-cpm using library sizes and the normalisation factors we calculated previously.\nIn addition to the normalisation steps, the limma-voom pipeline uses the voom() function to generate weights for the individual genes based on a modelled mean-variance relationship. This modelling allows us to get more information out of small sample sizes as the weights prevent our model from being more heavily influenced by more variable data points. The weights will then allow the linear model to be less influenced by genes with high variability, which is important for small sample sizes. The voom function also generates a mean-variance plot, which is useful for visualising the data.\nThe voom() function takes as arguments, our DGEList object and our design matrix. It also optionally outputs a plot of the mean-variance relationship of our data, called the ‘voom plot’.\n\nv &lt;- voom(dge_norm, design, plot = TRUE)\n\n\n\n\n\n\n\n\nThe output of voom() (our variable v) is an EList object which contains the following elements:\n\ngenes - a data frame of gene annotation data.\ntargets - data frame of sample data.\nE - numeric matrix of normalised log-cpm values.\nweights - numeric matrix of precision weights.\ndesign - the design matrix.\n\nThe ‘voom plot’ shows the mean-variance relationship of the data. The x-axis is the average log2 expression of each gene, and the y-axis is the log2 standard deviation of each gene. The idea is that the variance of a gene can be estimated as a function of its main expression, and that this estimate is more accurate than the direct calculation of the variance.\n\n\n7.1.4 Fitting the linear model\nWe are now ready to fit our linear model with lmFit(), which calculates coefficients we defined in our design matrix design. The resulting object, vfit is a MArrayLM object. It contains a information about our genes (the same data frame as genes from our EList object v above), the design matrix and a number of statistical outputs. Of most interest to us is the coefficients, stored in an element called coefficients. The first rows of this matrix is shown below. Each gene is row and is labelled using the EntrezID. Each column gives coefficients for each of our phenotype groups. These coefficients are weighted averages of the log-cpm of each gene in each group.\n\nvfit &lt;- lmFit(v)\nhead(vfit$coefficients)\n\n            Basal        LP        ML\n497097  3.0241632 -4.490392 -3.944477\n20671   0.2681245 -2.488746 -2.024896\n27395   4.3271126  3.901078  4.365378\n18777   5.2069566  4.976083  5.654066\n21399   5.2108711  4.901842  4.876380\n58175  -1.9296994  3.581328  3.133985\n\n\nWe can then use contrasts.fit() to calculate coefficients for each contrast (or ‘comparison’) we specified in our contr_matrix. The output is also an object of the class MArrayLM (also known as an MArrayLM object). When we inspect the coefficients element now, we can see that each column is a contrast that we specified in our contrast matrix.\n\nvfit &lt;- contrasts.fit(vfit, contrasts = contr_matrix)\nhead(vfit$coefficients)\n\n        Contrasts\n          BasalvsLP   BasalvsML      LPvsML\n  497097  7.5145557  6.96864007 -0.54591559\n  20671   2.7568708  2.29302094 -0.46384989\n  27395   0.4260347 -0.03826548 -0.46430022\n  18777   0.2308732 -0.44710891 -0.67798213\n  21399   0.3090294  0.33449065  0.02546125\n  58175  -5.5110274 -5.06368468  0.44734272\n\n\nWith these values we essentially want to know whether or not the difference in values is significantly different from 0. If the difference is not significantly different from 0, then we have failed to establish a difference in the expression of a particularly gene between two groups. If the difference is significantly greater than 0, then we have up-regulation in the first group of the contrast, and if the difference is significantly less than 0, then we have down-regulation in the first group of the contrast.",
    "crumbs": [
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>RNA-seq - Part 2</span>"
    ]
  },
  {
    "objectID": "chapter_7.html#statistical-testing",
    "href": "chapter_7.html#statistical-testing",
    "title": "7  RNA-seq - Part 2",
    "section": "7.2 Statistical testing",
    "text": "7.2 Statistical testing\nTo actually test if the values are significantly different from 0, we use the eBayes() function to compute moderated t-statistics, moderated F-statistics and log-odds of differential expression for each gene, given a fitted linear model. ‘Moderated’ refers to empirical Bayes moderation, which borrows information across genes to obtain more accurate measures of variability for each gene. This also increases our power to detect differentially expressed genes.\n\nefit &lt;- eBayes(vfit)\n\nWe can now look at the number of differentially expressed genes using the decideTests() function. The output of this function is a matrix where each column is a contrast (comparison of interest) and each row is a gene. The numbers 1, -1 and 0 mean up-regulated, down-regulated or not significantly differentially expressed, respectively.\nNote that decideTests() also accounts for multiple testing. The default method is Benjamini and Hochberg1 but several others are also available.\n\ndt &lt;- decideTests(efit)\ndt\n\nTestResults matrix\n        Contrasts\n         BasalvsLP BasalvsML LPvsML\n  497097         1         1      0\n  20671          1         1      0\n  27395          0         0      0\n  18777          0        -1     -1\n  21399          0         1      0\n16619 more rows ...\n\n\nTo obtain the total number of differentially expressed genes for each comparison, we can add the function summary():\n\nsummary(dt)\n\n       BasalvsLP BasalvsML LPvsML\nDown        4500      4850   2701\nNotSig      7307      6996  11821\nUp          4817      4778   2102\n\n\nThe function topTable() can be used to obtain more information on the differentially expressed genes for each contrast. topTable() takes as arguments the MArrayLM object output by eBayes() (efit), the contrast name of interest, and the number of top differentially expressed genes to output. Note that the contrast name must be given in quotes and must be exactly as written in the contrast matrix contr_matrix.\nIt outputs a data frame with the following information:\n\nGene details - gene information, from the gene element of the MArrayLM object (efit).\nlogFC - the log2 fold change of the contrast.\nAveExpr - the average log2 expression of that gene.\nt - moderated t-statistic.\nP.Value - p value.\nadj.P.Val - adjusted p value.\nB - log-odds that the gene is differentially expressed.\n\n\ntop_bvl &lt;- topTable(efit, coef = \"BasalvsLP\", n = Inf) %&gt;% \n  as_tibble() %&gt;% \n  mutate(contr = 'BasalvsLP')\n\nhead(top_bvl)\n\n# A tibble: 6 × 10\n  ENTREZID SYMBOL   TXCHROM logFC AveExpr     t  P.Value   adj.P.Val     B contr\n     &lt;dbl&gt; &lt;chr&gt;    &lt;chr&gt;   &lt;dbl&gt;   &lt;dbl&gt; &lt;dbl&gt;    &lt;dbl&gt;       &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt;\n1    12521 Cd82     chr2    -4.10    7.07 -35.5 3.38e-12     4.66e-8  18.4 Basa…\n2    22249 Unc13b   chr4    -4.35    5.66 -32.4 8.65e-12     4.66e-8  17.4 Basa…\n3    16324 Inhbb    chr1    -4.72    6.46 -30.8 1.45e-11     4.66e-8  17.1 Basa…\n4    14245 Lpin1    chr12   -3.77    6.29 -29.9 1.94e-11     4.66e-8  16.9 Basa…\n5   218518 Marveld2 chr13   -5.22    4.93 -30.9 1.41e-11     4.66e-8  16.8 Basa…\n6    12759 Clu      chr14   -5.31    8.86 -29.6 2.22e-11     4.66e-8  16.7 Basa…",
    "crumbs": [
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>RNA-seq - Part 2</span>"
    ]
  },
  {
    "objectID": "chapter_7.html#plotting-results",
    "href": "chapter_7.html#plotting-results",
    "title": "7  RNA-seq - Part 2",
    "section": "7.3 Plotting Results",
    "text": "7.3 Plotting Results\nIn this section we will make plots of both the summary statistics (topTable output), and the gene expression levels per sample, using log(counts per million) together with sample metadata from dge$samples.\n\n7.3.1 Data extract\nTo start with we extract all the data required to make any of the the common RNAseq results plots.\nThe experimental sample metadata and log(CPM) values were extracted to samples_tbl and log_cpm_tbl respectively, in the previous chapter.\nHere we will also extract the summary statistics for the remaining two pair-wise contrasts into separate tables.\n\n7.3.1.1 Extract summary tables\nVolcano plots and MA plots require differential expression summary statistics. We have the summary table for BasalvsLP already extracted to top_bvl, now for BasalvsML and LPvsML:\n\ntop_bvm &lt;- topTable(efit, coef = \"BasalvsML\", n = Inf) %&gt;% \n  as_tibble() %&gt;% \n  mutate(contr = 'BasalvsML')\n\n\ntop_lvm &lt;- topTable(efit, coef = \"LPvsML\", n = Inf) %&gt;% \n  as_tibble() %&gt;% \n  mutate(contr = 'LPvsML')\n\n\n\n\n7.3.2 Volcano Plot\nVolcano plots are very popular for visually summarizing results from RNA-seq analysis. The volcano plot is a scatter plot of the negative log10 p-value (y) against the log2 fold-change (x). This plot is useful for visualising the significance of the differentially expressed genes, as the more significant results are at the top left and right of the plot.\nTo make a volcano plot for a single experimental contrast (BasalvsLP), we must first categorize the summary statistics for each gene with ‘Up’ ‘Down’ or ‘Not DE’, according to the adj.P.Val and logFC. The case_when() function is a good choice for binning continuous data (adj.P.Val) into categories.\n\ntop_bvl_cat &lt;- top_bvl %&gt;% \n  mutate(status = case_when(adj.P.Val &lt; 0.05 & logFC &gt; 0 ~ 'Up',\n                            adj.P.Val &lt; 0.05 & logFC &lt; 0 ~ 'Down',\n                            .default='Non DE'))\n\nNow to render the plot…\n\nvolcano_bvl &lt;- top_bvl_cat %&gt;%\n  ggplot(aes(x = logFC, y = -log10(P.Value), col = status)) +\n  geom_point(size=0.5) +\n  scale_colour_manual(values = c(\"blue\", \"#595959\", \"red\")) +\n  ggtitle('Basal vs LP')\n\n\nvolcano_bvl\n\n\n\n\n\n\n\n\nLastly we can label the gene names for the top-most DEGs by extracting the top 20 genes using dplyr::slice() and feeding them into geom_label_repel() from the ggrepel library. Here instead of rewriting code, we just keep adding geoms to the volcano_plot ggplot object created above!\n\nlibrary(ggrepel)\n\n\ntop_deg_bvl &lt;- top_bvl_cat %&gt;% group_by(status) %&gt;% arrange(P.Value) %&gt;% \n  slice_head(n = 10) %&gt;% \n  filter(status!='Non DE')\n\nvolcano_bvl +\n  geom_label_repel(\n    data = top_deg_bvl,\n    aes(label = SYMBOL, col = status),\n    max.overlaps = 20,\n    show.legend = FALSE\n  ) \n\n\n\n\n\n\n\n\n\n\n\n\n\n\nNext steps\n\n\n\nCan you now make the labelled volcano plots for the BasalvsML and LPvsML contrasts?\n\n\n\n\n7.3.3 Boxplots\nIt’s important to create boxplots for a few differentially-expressed genes. This is a way of confirming that the results in our summary statistics tables and the underlying data agree, and that that our contrasts are set up correctly!\nIn this case we’ll make boxplots from the log(CPM) values of individual samples, for the first 6 differentially-expressed genes in the BasalvsLP topTable top_bvl_cat. We will extract the first 6 rows of the tibble using slice_head(), then join the logCPM values per sample\n\n\ntop_bvl_cat %&gt;% slice_head(n=6) %&gt;% \n  left_join(logcpm_tbl, by= join_by(ENTREZID == gene))\n\nError in `left_join()`:\n! Can't join `x$ENTREZID` with `y$gene` due to incompatible types.\nℹ `x$ENTREZID` is a &lt;double&gt;.\nℹ `y$gene` is a &lt;character&gt;.\n\n\nGreat! An error! …it seems that the ENTREZID and gene columns are not the same data type between the top_bvl_cat and the logcpm_tbl tibbles. We can fix this by creating a new column logcpm_tbl$ENTREZID containing the genes converted to numeric data:\n\nlogcpm_tbl &lt;- logcpm_tbl %&gt;% \n  mutate(ENTREZID = as.numeric(gene)) %&gt;% \n  relocate(ENTREZID)\n\nNow we can rerun the left_join() and reshape the data to long form as required for ggplot2.\n\ntop_gene_long &lt;- top_bvl_cat %&gt;%\n  slice_head(n=6) %&gt;% \n  left_join(logcpm_tbl, by='ENTREZID') %&gt;% \n  select(SYMBOL, '10_6_5_11' : 'JMS9-P8c') %&gt;% \n  pivot_longer(cols = -SYMBOL, \n               names_to = 'sample_id', values_to = 'logCPM')\n\nNext, we join the sample groupings to this reshaped data:\n\ntop_gene_long_samples &lt;- left_join(top_gene_long, samples_tbl,\n                                   by=join_by(sample_id == id))\n\n…and plot the results\n\nboxplots &lt;- top_gene_long_samples %&gt;% \n  ggplot(aes(x=group,y=logCPM, colour = group)) + \n  geom_boxplot() +\n  geom_jitter() +\n  facet_wrap(~SYMBOL, scales='free')\n\nboxplots\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCross-check!\n\n\n\nTo confirm your statistical contrasts are working as expected, note the gene names that are down-regulated in the Basal vs LP conditions in these boxplots. Are they labelled as expected in the volcano plot?\n\n\n\n\n7.3.4 Heatmap\nNext, we can create a heatmap of the differentially expressed genes. The heatmap is a useful way to visualise the expression of the differentially expressed genes in individual samples, especially when more than two conditions are being tested. We can use the tidyheatmaps package to create the heatmap.\nFirst we need to install the package if you haven’t already\n\ninstall.packages(\"tidyheatmaps\")\n\nThe data we will use for the heatmap is going to be the log2 cpm expression values of the top differentially expressed genes, within the logcpm_tbl data, and the first 50 rows from each of the three top tables.\n\n\n\n\n\n\nNote\n\n\n\nBecause genes may be differentially expressed in more than one contrast, the total number of unique genes may be less than 150.\n\n\nFor more interpretable labels, we will use the gene symbols as the row names of the expression matrix.\n\ntop_genes_all &lt;- bind_rows(\n  top_bvl %&gt;% slice_head(n = 50),\n  top_bvm %&gt;% slice_head(n = 50),\n  top_lvm %&gt;% slice_head(n = 50)) %&gt;% \n  select(ENTREZID, SYMBOL) %&gt;% \n  distinct() \n\nWe now join the logCPM values for the top_genes:\n\ntop_genes_lcpm &lt;- left_join(top_genes_all, logcpm_tbl,\n                            by = \"ENTREZID\" )\n\n…and reshape the data to long format before joining in the sample group labels. This is very similar to how the data was prepared for our boxplots.\n\ntop_genes_lcpm_long &lt;- top_genes_lcpm %&gt;% \n  pivot_longer(cols = -c(ENTREZID,SYMBOL,gene),\n              names_to = \"id\", \n              values_to = \"logcpm\")\n\n\ntop_genes_lcpm_gp &lt;- left_join(top_genes_lcpm_long, samples_tbl)\n\nJoining with `by = join_by(id)`\n\n\nNotice that if we do not specify the join key column, left_join() will try to detect it automatically. Use this shortcut only when you are confident and very familiar with the tibbles you are working with.\nTo create the heatmap we will use the tidyheatmaps() function with the logCPM values. We will add in arguments to scale the data colours along the rows with a z-score, adding in sample annotation, and using a dendrogram (tree-based clustering) to order the data by rows and columns. We will also add in the option to show the row names and column names, and set the font size.\nYou can experiment with removing each of these options to see how they affect the heatmap, as well as investigate additional options in the tidyheatmaps() documentation.\n\nlibrary(tidyheatmaps)\n\n\nheatmap &lt;- tidyheatmap(\n  df = top_genes_lcpm_gp,\n  rows = SYMBOL,\n  columns = id,\n  values = logcpm,\n  color_legend_n = 100,\n  annotation_col = group,\n  scale = 'row',\n  border_color = NA,\n  cluster_rows = TRUE,\n  cluster_cols = TRUE,\n  show_rownames = TRUE,\n  show_colnames = TRUE,\n  fontsize_row = 6,\n  fontsize_col = 10\n)\n\nheatmap",
    "crumbs": [
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>RNA-seq - Part 2</span>"
    ]
  },
  {
    "objectID": "chapter_7.html#saving-the-results",
    "href": "chapter_7.html#saving-the-results",
    "title": "7  RNA-seq - Part 2",
    "section": "7.4 Saving the results",
    "text": "7.4 Saving the results\nNow that we have produced a series of plots and the top genes table, we can save these files to a directory. These figures may form the basis for publication figures, and the results table can partially presented as a result, or the full table can be included as a supplementary file.\n\ndir.create(\"output\")\n\nwrite_csv(top_bvl_cat, \"output/top_genes_BasalvsLP.csv\")\n\nggsave(\"output/volcano_plot_BasalvsLP.png\", volcano_bvl)\n\nSaving 10 x 5 in image\n\nggsave(\"output/heatmap.png\", heatmap, width=9, height=9)\n\nggsave(\"output/boxplots.png\", boxplots)\n\nSaving 10 x 5 in image\n\n\nWith that we have come to the conclusion of the RNA-seq analysis and this course. You have now learned how to use various tidyverse packages to operate on data and create publication quality figures. You have also learned how to use the limma and edgeR packages to perform differential expression analysis on RNA-seq data. You should now be able to apply these skills to perform analysis on your own data.",
    "crumbs": [
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>RNA-seq - Part 2</span>"
    ]
  },
  {
    "objectID": "chapter_7.html#extension",
    "href": "chapter_7.html#extension",
    "title": "7  RNA-seq - Part 2",
    "section": "7.5 Extension",
    "text": "7.5 Extension\n\n7.5.1 MA Plot\nThe MA plot is a plot of log-fold-change (M-values) against log-expression averages (A-values), this is a common plot in RNA sequencing analysis to visualise the result of differential expression tests. It can be created using the plotMA() from the limma package. Creating this plot requires 3 pieces of information:\n\nobject = efit: The the fitted object containing the log-fold-change and log-expression averages\ncoef = 1: The column number of the contrast to plot since there are 3 different contrasts fitted within the object.\nstatus = dt[, 1]: A vector of numerics denoting whether a gene is up-regulated or down-regulated.\n\n\nplotMA(efit, coef = 1, status = dt[, \"BasalvsLP\"])\n\n\n\n\n\n\n\n#If you get an error with the above code, try:\nlimma::plotMA(efit, coef = 1, status = dt[, \"BasalvsLP\"])\n\nAs before, we can try to re-create this plot using ggplot2 to give us more flexibility in plotting. The information we’ll need is in the top_bvl_cat tibble that we extracted for the volcano plot.\n\ntop_bvl_cat %&gt;%\n  ggplot(aes(x = AveExpr, y = logFC, col = status)) +\n  geom_point()\n\n\n\n\n\n\n\n\nWhile the coordinates of the points are the same, there is still quite a bit of work to do to make this plot look like the one produced by plotMA(). First we have the fix up the colours of the points. We also have to make it such that the non-significant points are plotted below the other points. To do this we would need to make it so that the non-significant points are plotted first. We can do this by reordering the levels of the status factor so that the non-significant points are plotted first. Labels can also be added using ggrepel for the top 10 DE genes in each direction.\n\ntop_bvl_cat_fct &lt;- top_bvl_cat %&gt;%\n  mutate(status = fct_relevel(status,'Non DE')) \n\nscale_cols &lt;- c(\n  \"Not DE\" = \"#595959\",\n  \"Down\" = \"blue\",\n  \"Up\" = \"red\"\n)\n\nma_bvl &lt;- top_bvl_cat_fct %&gt;%\n  ggplot(aes(x = AveExpr, y = logFC, col = status)) +\n  geom_point(data = top_bvl_cat_fct %&gt;% filter(status == \"Non DE\"), size = 0.1) +\n  geom_point(data = top_bvl_cat_fct %&gt;% filter(status != \"Non DE\"), size = 1) +\n  geom_label_repel(\n    data = top_deg_bvl,\n    aes(label = SYMBOL, col = NULL),\n    max.overlaps = 20,\n    show.legend = FALSE\n  ) +\n  scale_colour_manual(values = scale_cols) +\n  ggtitle('Basal vs LP')\n\nma_bvl\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nNext steps\n\n\n\nCan you now make the labelled MA plots for the BasalvsML and LPvsML contrasts?\n\n\nNow we can save the MA plot to our output:\n\nggsave(\"output/ma_plot_BasalvsLP.png\", ma_bvl)\n\nSaving 10 x 5 in image\n\n\n\n\n7.5.2 Gene set testing\nAlthough beyond the scope of this subject, researchers are often interested in discovering biological trends in differential gene expression results such as we have generated above. To do this, genes can be grouped according to their involvement in similar biological processes, molecular functions or cellular components, for example. A single gene can be involved in multiple biological processes, and have multiple ‘terms’ or ‘labels’. Genes with the same assigned term are called a ‘gene set’.\n‘Gene set enrichment analysis’ is the science of identifying terms that are over-represented among differentially expressed genes. There are many methods for doing this, and ensemble methods (aggregating results from multiple enrichment testing methods), is an optimal approach, as detailed here.",
    "crumbs": [
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>RNA-seq - Part 2</span>"
    ]
  },
  {
    "objectID": "chapter_7.html#references",
    "href": "chapter_7.html#references",
    "title": "7  RNA-seq - Part 2",
    "section": "7.6 References",
    "text": "7.6 References\n\n\n\n\n\n\n1. Benjamini Y, Hochberg Y. Controlling the False Discovery Rate: A Practical and Powerful Approach to Multiple Testing. Journal of the Royal Statistical Society Series B: Statistical Methodology [Internet]. 1995 Jan 1;57(1):289–300. Available from: http://dx.doi.org/10.1111/j.2517-6161.1995.tb02031.x",
    "crumbs": [
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>RNA-seq - Part 2</span>"
    ]
  },
  {
    "objectID": "chapter_8.html",
    "href": "chapter_8.html",
    "title": "8 Machine learning",
    "section": "",
    "text": "Background\n‘Machine learning’ (ML) is an umbrella term that encompasses classical statistical methods, linear models (both simple and generalized), and non-parametric techniques such as decision trees, support vector machines, autoencoders, and neural networks. Each of these methods are called machine learning ‘engines’ when used to train a model.\nML forms the foundation of artificial intelligence. For instance, large language models such as chatGPT, are trained using deep neural networks.\nMachine learning refers to the use of computers (machines) to identify statistical trends in data and store those trends/relationships in a ‘model’. The process of identifying trends (‘learning’) and then predicting features of newly provided data (‘predicting’) is common to all ML workflows.",
    "crumbs": [
      "8 Machine learning"
    ]
  },
  {
    "objectID": "chapter_8.html#terminology",
    "href": "chapter_8.html#terminology",
    "title": "8 Machine learning",
    "section": "Terminology",
    "text": "Terminology\nIn training ML models, the machine ‘learns from the training data set’ and ‘predicts the validation data set’. The accuracy of the predictions on the validation data is used to update the model (known as ‘reinforcement learning’).\nOnce the model has been trained, it is tested on a ‘hold-out’ or ‘test’ dataset, which has not been used at any point in training or validation. The accuracy of performance on the test set is the ultimate test of the ‘predictive value’ of a model, that is, how valuable it is for informing real-world decisions.",
    "crumbs": [
      "8 Machine learning"
    ]
  },
  {
    "objectID": "ch8_section_1.html",
    "href": "ch8_section_1.html",
    "title": "Part 1",
    "section": "",
    "text": "Setup\nlibrary(tidyverse)\nlibrary(readxl)\nlibrary(broom)\nlibrary(ggridges)\n\nlibrary(tidyrstats)\n\ntheme_set(theme_minimal())",
    "crumbs": [
      "8 Machine learning",
      "Part 1"
    ]
  },
  {
    "objectID": "ch8_section_1.html#read-data",
    "href": "ch8_section_1.html#read-data",
    "title": "Part 1",
    "section": "Read data",
    "text": "Read data\n\ntumor_data &lt;- readxl::read_xlsx('data/tumor_data.xlsx')\n\ntumor_data\n\n# A tibble: 300 × 42\n   donorid status    cell_size cell_density nuclear_area membrane_curvature\n   &lt;chr&gt;   &lt;chr&gt;         &lt;dbl&gt;        &lt;dbl&gt;        &lt;dbl&gt;              &lt;dbl&gt;\n 1 d001    malignant     0.170        0.654        0.877              2.50 \n 2 d002    malignant     2.95         1.42         0.677              4.78 \n 3 d003    malignant     4.79         4.66         0.593              6.96 \n 4 d004    benign        4.67         1.74         0.423              0.928\n 5 d005    malignant    13.0          0.887        0.489              3.01 \n 6 d006    benign        3.78         1.02         0.486              0.580\n 7 d007    malignant     0.663        8.53         1.03               2.17 \n 8 d008    benign        0.950        1.09         0.581              5.10 \n 9 d009    malignant     8.39         3.64         0.955              8.78 \n10 d010    benign        9.82         7.39         0.403             15.3  \n# ℹ 290 more rows\n# ℹ 36 more variables: granularity &lt;dbl&gt;, border_diffuseness &lt;dbl&gt;,\n#   vascular_density &lt;dbl&gt;, necrosis_extent &lt;dbl&gt;, stromal_thickness &lt;dbl&gt;,\n#   mitotic_count &lt;dbl&gt;, texture_1 &lt;dbl&gt;, texture_2 &lt;dbl&gt;, texture_3 &lt;dbl&gt;,\n#   texture_4 &lt;dbl&gt;, texture_5 &lt;dbl&gt;, texture_6 &lt;dbl&gt;, texture_7 &lt;dbl&gt;,\n#   texture_8 &lt;dbl&gt;, texture_9 &lt;dbl&gt;, texture_10 &lt;dbl&gt;, intensity_1 &lt;dbl&gt;,\n#   intensity_2 &lt;dbl&gt;, intensity_3 &lt;dbl&gt;, intensity_4 &lt;dbl&gt;, …\n\n\nThe data contains 300 tissue samples which have been imaged in a histology lab, as referenced in this chapter Background. Each sample has the anonymized donor id and malignancy status determined by a trained pathologist (benign or malignant).\nAutomatic quantification of image features produces 40 ‘features’ including cell shapes, edge (plasma membrane) definition, cytosolic texture, staining intensity, necrosis, vascularity etc.",
    "crumbs": [
      "8 Machine learning",
      "Part 1"
    ]
  },
  {
    "objectID": "ch8_section_1.html#explore-the-data",
    "href": "ch8_section_1.html#explore-the-data",
    "title": "Part 1",
    "section": "Explore the data",
    "text": "Explore the data\n\nReshape for plotting\n\ndat_long &lt;- tumor_data |&gt; \n  pivot_longer(names_to = \"key\", values_to = \"value\", \n               cols = -c(donorid, status))\n\n\n\nCheck distributions\n\ndat_long |&gt;   ggplot(aes(x=value,group=key)) + geom_density()\n\n\n\n\n\n\n\n\nThe data doesnt look normally distributed, but there is a big over-plotting problem here. Let’s use the ggridges package to produce a single density plot for each feature:\n\ndat_long |&gt;  ggplot(aes(x=value)) + \n  geom_density_ridges(aes(y=key))\n\nPicking joint bandwidth of 0.646\n\n\n\n\n\n\n\n\n\nThe measurements in the dataset have a positive skew, meaning they are non-normal. For best results in machine learning (and data analysis more generally) its usually best to transform the data into a normal distribution where possible.\n\n\nLog transform\n\ndat_long_log &lt;- dat_long |&gt;\n  mutate(value=log10(value))\n\nPlot transformed data\n\ndat_long_log |&gt;  ggplot(aes(x=value)) + \n  geom_density_ridges(aes(y=key))\n\nPicking joint bandwidth of 0.0993\n\n\n\n\n\n\n\n\n\nThe data looks more normal now. Note that the mean values are different. This can be addressed by scaling data, which we return to later.\n\n\nCluster analysis\nLet’s run an unsupervised machine learning method to explore how the samples group together using a ‘data-driven’ approach. pr_comp() gives us principal components analysis, and requires wide-format data.\nReshape log-transformed data to wide format, and calculate principal components using the quantitative features (i.e., everything except donorid and malignancy status).\n\ndat_wide_log &lt;- dat_long_log |&gt; \n  pivot_wider(names_from = \"key\", values_from=\"value\") \n  \npc_dat &lt;- dat_wide_log |&gt; select(-c(donorid,status)) |&gt; \n        #principal components function\n  prcomp()\n\nWe can access the principal components for each sample by using the broom::augment() function. The primary PCs (e.g. 1 thru 5) encode the majority of the variation between samples. As such we focus on primary PCs (or dimension in MDS), when clustering samples\nPlot first 2 PCs, coloured by tumor status\n\npcs_fitted &lt;- pc_dat |&gt; augment() \n  \n#Join the sample labels to the fitted PCs\npc_plot_dat &lt;- bind_cols(tumor_data |&gt; select(status), \n                         pcs_fitted) \n\n#Scatter plot\npc_plot_dat |&gt; \n  ggplot(aes(.fittedPC1, .fittedPC2)) + \n  geom_point(aes(col=status), size=2)\n\n\n\n\n\n\n\n\nThere is certainly not a clear separation between malignant and benign. This indicates we will need to try a more sensitive/advanced method to reliably predict the tissue status.\n\n\nLinear model\nLets try one of the simplest ML engines - the linear model, to see whether any of the imaging features are significantly associated with tissue status.\nIf we define a model where imaging feature is the outcome (y) and tumor status is the predictor (x) we can test for associations quite easily, using lm_test().\nOur experimental question is ‘Are any features (y) significantly different between benign (x = 0 ) and malignant (x=1)?’\n\n#marginal effects\ndat_long_log |&gt; group_by(key) |&gt; \n  lm_test( value ~  status  ) |&gt; filter(term!='intercept') \n\nResults for linear model: value ~ status\n\n\n# A tibble: 40 × 6\n   key                term            estimate std.error statistic       p.value\n   &lt;chr&gt;              &lt;chr&gt;              &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;         &lt;dbl&gt;\n 1 granularity        statusmalignant   0.280     0.0446      6.28 0.00000000121\n 2 intensity_8        statusmalignant   0.146     0.0240      6.10 0.00000000325\n 3 membrane_curvature statusmalignant   0.228     0.0481      4.75 0.00000317   \n 4 shape_metric_4     statusmalignant  -0.229     0.0486     -4.72 0.00000361   \n 5 vascular_density   statusmalignant   0.108     0.0244      4.43 0.0000133    \n 6 stromal_thickness  statusmalignant   0.172     0.0470      3.65 0.000305     \n 7 intensity_5        statusmalignant   0.0773    0.0247      3.13 0.00193      \n 8 intensity_4        statusmalignant   0.0691    0.0274      2.52 0.0123       \n 9 texture_2          statusmalignant  -0.0657    0.0350     -1.88 0.0617       \n10 texture_10         statusmalignant  -0.0791    0.0452     -1.75 0.0811       \n# ℹ 30 more rows\n\n\nWe can see several features do have significant associations with tissue status! This means that, although those feature associations are not large/strong enough to drive sample separation in PCA, the should be able to be combined to build a good predictive model.\n\n\nConfirm LM results graphically\n\n#features_of_interest (FOI)\nfoi &lt;- c('granularity','intensity_8','membrane_curvature')\n\ndat_long_log |&gt; \n  filter(key %in% foi) |&gt; \n  ggplot(aes(x=status , y=value)) + geom_boxplot() +\n  geom_jitter(aes(group=status), width=0.2,size=0.5) +\n  facet_wrap(~key)",
    "crumbs": [
      "8 Machine learning",
      "Part 1"
    ]
  },
  {
    "objectID": "ch8_section_1.html#save-output",
    "href": "ch8_section_1.html#save-output",
    "title": "Part 1",
    "section": "Save output",
    "text": "Save output\nFor the next steps, we will save the log-transformed, wide-format data (used for the PC analysis).\n\nwritexl::write_xlsx(dat_wide_log,\n                    'data_processed/tumor_data_log_wide.xlsx')",
    "crumbs": [
      "8 Machine learning",
      "Part 1"
    ]
  },
  {
    "objectID": "ch8_section_2.html",
    "href": "ch8_section_2.html",
    "title": "Part 2",
    "section": "",
    "text": "Background\nWe loaded and explored the histology imaging-derived data in ML Part 1. Through this process we found:\nGiven these findings, we have reason to believe that a machine learning algorithm may be successful in predicting malignant vs benign tumor status.\nBy contrast, if no differences are seen in PCA or simple testing of linear models, the chance of building a reliable classification model is much lower.",
    "crumbs": [
      "8 Machine learning",
      "Part 2"
    ]
  },
  {
    "objectID": "ch8_section_2.html#background",
    "href": "ch8_section_2.html#background",
    "title": "Part 2",
    "section": "",
    "text": "the data requires log-transformation\nthere is little separation in malignant vs benign samples when clustering via principal components analysis\nusing linear modeling, several imaging features show significant correlation with tumor status (benign vs malignant)",
    "crumbs": [
      "8 Machine learning",
      "Part 2"
    ]
  },
  {
    "objectID": "ch8_section_2.html#aim",
    "href": "ch8_section_2.html#aim",
    "title": "Part 2",
    "section": "Aim",
    "text": "Aim\nTo train a classification model using the ‘xgboost’ algorithm (extreme gradient boosting), which is a class of algorithms that uses decision trees (similar to ‘random forest’).\nNote, our primary aim here is not to understand the individual features that contribute to the benign vs malignant classification, but simply to build a robust classification tool.",
    "crumbs": [
      "8 Machine learning",
      "Part 2"
    ]
  },
  {
    "objectID": "ch8_section_2.html#load-libraries",
    "href": "ch8_section_2.html#load-libraries",
    "title": "Part 2",
    "section": "Load libraries",
    "text": "Load libraries\n\nlibrary(tidyverse)\nlibrary(readxl)\nlibrary(tidymodels)\nlibrary(xgboost)\n\ntheme_set(theme_minimal())",
    "crumbs": [
      "8 Machine learning",
      "Part 2"
    ]
  },
  {
    "objectID": "ch8_section_2.html#load-data",
    "href": "ch8_section_2.html#load-data",
    "title": "Part 2",
    "section": "Load data",
    "text": "Load data\nPreprocessed data from ML Part 1 is stored in data_processed/\n\ndat_wide_log &lt;- read_xlsx('data_processed/tumor_data_log_wide.xlsx')",
    "crumbs": [
      "8 Machine learning",
      "Part 2"
    ]
  },
  {
    "objectID": "ch8_section_2.html#set-seed",
    "href": "ch8_section_2.html#set-seed",
    "title": "Part 2",
    "section": "Set seed",
    "text": "Set seed\n‘Reproducible randomness’. This ensures everyone using this tutorial gets the same results.\n\nset.seed(42)",
    "crumbs": [
      "8 Machine learning",
      "Part 2"
    ]
  },
  {
    "objectID": "ch8_section_2.html#format-data",
    "href": "ch8_section_2.html#format-data",
    "title": "Part 2",
    "section": "Format data",
    "text": "Format data\nTraining the ML model requires the outcome (malignant status) encoded as a factor.\n\n\n\n\n\n\nData types and file types\n\n\n\nData types aren’t preserved in Excel, csv or tsv format files. They are however preserved in .Rdata and .Rds files.\n\n\n\ndat_wide_log %&gt;% select(1:5) %&gt;%  str()\n\ntibble [300 × 5] (S3: tbl_df/tbl/data.frame)\n $ donorid     : chr [1:300] \"d001\" \"d002\" \"d003\" \"d004\" ...\n $ status      : chr [1:300] \"malignant\" \"malignant\" \"malignant\" \"benign\" ...\n $ cell_size   : num [1:300] -0.769 0.469 0.68 0.669 1.113 ...\n $ cell_density: num [1:300] -0.1844 0.1517 0.6682 0.2399 -0.0523 ...\n $ nuclear_area: num [1:300] -0.0568 -0.1693 -0.2268 -0.3735 -0.3104 ...\n\n\nRe-establish status as a factor:\n\ndat_wide_log &lt;- dat_wide_log %&gt;% \n  mutate(status=factor(status))\n\nDrop donorid from the training data. It encodes no useful infromation for training a model.\n\ndata_final &lt;- dat_wide_log %&gt;% select(-c(donorid))",
    "crumbs": [
      "8 Machine learning",
      "Part 2"
    ]
  },
  {
    "objectID": "ch8_section_2.html#split-test-train",
    "href": "ch8_section_2.html#split-test-train",
    "title": "Part 2",
    "section": "Split test & train",
    "text": "Split test & train\nThe default is to split the data into training (75%) and test/hold-out (25%). We stratify by status, to ensure roughly equal numbers of benign and malignant samples in the test and training data\n\nsplit_cl &lt;- initial_split(data_final, strata = status)\n\nExtract the test and training data to separate objects\n\ntrain_cl &lt;- training(split_cl)\n\ntest_cl  &lt;- testing(split_cl)\n\nCheck the balance of the status classes (malignant vs benign), remembering that ROC curves are more reliable when classes are balanced.\n\ntrain_cl %&gt;% count(status)\n\n# A tibble: 2 × 2\n  status        n\n  &lt;fct&gt;     &lt;int&gt;\n1 benign      104\n2 malignant   120\n\ntest_cl  %&gt;% count(status)\n\n# A tibble: 2 × 2\n  status        n\n  &lt;fct&gt;     &lt;int&gt;\n1 benign       35\n2 malignant    41\n\n\nThis gives reasonably even splits.",
    "crumbs": [
      "8 Machine learning",
      "Part 2"
    ]
  },
  {
    "objectID": "ch8_section_2.html#recipe",
    "href": "ch8_section_2.html#recipe",
    "title": "Part 2",
    "section": "Recipe",
    "text": "Recipe\nThe data recipe stores the model parameters, and the data pre-processing steps. These steps will be performed on any data input to the ML training process.\n\nrec_cl &lt;- recipe(status ~ .  , data = train_cl ) %&gt;% \n  step_zv(all_numeric_predictors()) %&gt;% \n  step_normalize(all_numeric_predictors()) %&gt;% \n  step_dummy(all_nominal_predictors()) \n\nThe model algebra indicates we want to predict the status column (aka ‘y’ / ‘outcome’) using all available columns (denoted by . ). The data argument train_cl is provided to define the structure of the data (i.e., the colnames for all the features we have available).\nThe tidymodels package has a number of step_() functions that allow us to chain data transformation instructions together using the pipe %&gt;%, similar to a dplyr ‘chain’.\nstep_zv() - step_zero_variance removes any features that have 0 variance, and therefore encode no information that can help to predict the outcome (which is ‘status’, in this case).\nstep_normalize() performs a scaling normalization. First it centres the data each feature by subtracting the mean from every value, and then transforms the centred data into z scores (i.e., dividing each value by the standard deviation for that feature).\nstep_dummy() - converts nominal (character) data such as sex, into ‘dummy’ numeric variables, to allow their use in the ML training data, which is strictly numeric.\nNote we have already log-transformed the data in our exploratory data analysis steps in ML Part 1. However, if we had not done this, we could use step_log() before step_normalize().",
    "crumbs": [
      "8 Machine learning",
      "Part 2"
    ]
  },
  {
    "objectID": "ch8_section_2.html#hyper-parameters",
    "href": "ch8_section_2.html#hyper-parameters",
    "title": "Part 2",
    "section": "Hyper-parameters",
    "text": "Hyper-parameters\nHyper-parameters are pre-determined settings that govern how the model learns, and the model ‘architecture’ - akin to the depth and breadth of parameters that can be modified during training. Different model classes have different types of hyper-parameters. In this case for the xgboost algorithm, we pre-determine the number of decision trees that are ‘grown’ during the training steps, the depth ( = maximum number of branch-points) of those trees, and the ‘learning rate’ - which governs the magnitude of updates to the model during training.\nWe also determine the machine learning engine (‘xgboost’) and the mode (‘classification’) as opposed to ‘regression’.\n\nxgb_params &lt;- boost_tree(trees = 500, \n                           tree_depth = 20, \n                          learn_rate = 0.01) %&gt;%\n  set_engine(\"xgboost\") %&gt;%\n  set_mode(\"classification\")\n\nOne of the great features about tidymodels is the simplicity of using different model classes. All that is required is to edit the set_engine() command to your model of choice! The pre-processing and evaluation steps remain unchanged, and this removes the need to learn a separate R library for each ML engine!",
    "crumbs": [
      "8 Machine learning",
      "Part 2"
    ]
  },
  {
    "objectID": "ch8_section_2.html#workflow",
    "href": "ch8_section_2.html#workflow",
    "title": "Part 2",
    "section": "Workflow",
    "text": "Workflow\nNow we package the data pre-processing recipe and the hyper-parameters into a workflow, ready for training. This workflow construct ensures that all steps - data pre-processing, model specification and tuning, are pre-defined in a single object.\n\nwf_xgb &lt;- workflow() %&gt;%\n  # model outcome and features & pre-processing steps:\n  add_recipe(rec_cl) %&gt;%  \n  #hyper-parameters, machine learning model type, and mode:\n  add_model(xgb_params) \n\n\n\n\n\n\n\nHyper-parameter tuning\n\n\n\nEven though we are not tuning hyper-parameters in this simple workflow, the tuning process can be captured in the workflow object, as we will see later.\n\n\n\n\n\n\n\n\nModels within models?\n\n\n\nIn this tutorial ‘models’ appear in two contexts\n\nThe model algebra (similar to a linear model equation), that specifies what our outcome is (y), and the predictor features we want to use. This is specified in the recipe() step.\nThe machine learning model (in this case xgboost), which is specified in the workflow using add_model().",
    "crumbs": [
      "8 Machine learning",
      "Part 2"
    ]
  },
  {
    "objectID": "ch8_section_2.html#train-your-model",
    "href": "ch8_section_2.html#train-your-model",
    "title": "Part 2",
    "section": "Train your model!",
    "text": "Train your model!\nWe provide the workflow and the input data. fit() performs the model training steps. This should take ~30-60 seconds on a standard laptop.\n\nfit_cl &lt;- fit(wf_xgb, data = train_cl)",
    "crumbs": [
      "8 Machine learning",
      "Part 2"
    ]
  },
  {
    "objectID": "ch8_section_2.html#predict-the-test-set",
    "href": "ch8_section_2.html#predict-the-test-set",
    "title": "Part 2",
    "section": "Predict the test set!",
    "text": "Predict the test set!\nApply the newly trained model to predict the malignant status in the original train_cl training data, and the hold-out test_cl dataset. Here we set the type argument to ‘prob’, to generate probabilities of each class, rather than discrete labels (0 or 1).\nThese probabilities will be used directly for plotting ROC and PR curves (below), and rounded for other diagnostic values.\n\npred_train &lt;- predict(fit_cl, train_cl, type = 'prob') %&gt;%\n  bind_cols(train_cl)\n\npred_test &lt;- predict(fit_cl, test_cl, 'prob') %&gt;%\n  bind_cols(test_cl)",
    "crumbs": [
      "8 Machine learning",
      "Part 2"
    ]
  },
  {
    "objectID": "ch8_section_2.html#evaluate",
    "href": "ch8_section_2.html#evaluate",
    "title": "Part 2",
    "section": "Evaluate",
    "text": "Evaluate\n\nRound probabilities\nFirst a column of predicted class (discrete) values are generated by rounding the predicted probability of the malignant class\n\npred_train &lt;- pred_train |&gt; \n  mutate(.pred_class=if_else(round(.pred_malignant)==1,\n                             'malignant',\n                             'benign')) |&gt; \n  relocate(.pred_class, .before = status) |&gt; \n  mutate(.pred_class=factor(.pred_class))\n\n\npred_test &lt;- pred_test |&gt; \n  mutate(.pred_class=if_else(round(.pred_malignant)==1,\n                             'malignant',\n                             'benign')) |&gt; \n  relocate(.pred_class, .before = status) |&gt; \n  mutate(.pred_class=factor(.pred_class))\n\n\n\n\n\n\n\nThe rounding decision threshold\n\n\n\nCreating PR and ROC curves requires varying the probability threshold at which a sample is labelled as TRUE (malignant) or FALSE (benign). What is the default decision threshold for the round() function?\n\n\n\n\nBoxplot\nCompare the predicted probability of malignancy to the true sample labels\n\npred_train |&gt; \n  ggplot(aes(y=.pred_malignant, x=status)) + \n  geom_boxplot() + geom_jitter(width=0.2, height=0) +\n  ylab('Predicted probability of malignancy') +\n  xlab('True sample label') +\n  ggtitle('Training data')\n\n\n\n\n\n\n\npred_test |&gt; \n  ggplot(aes(y=.pred_malignant, x=status)) + \n  geom_boxplot() + geom_jitter(width=0.2, height=0) +\n  ylab('Predicted probability of malignancy') +\n  xlab('True sample label') +\n  ggtitle('Test data')\n\n\n\n\n\n\n\n\n\n\nConfusion matrix\n\npred_train %&gt;% conf_mat(truth = status, \n                        estimate = .pred_class, \n                        dnn = c('Predicted','Truth (TRAINING Data)')) \n\n           Truth (TRAINING Data)\nPredicted   benign malignant\n  benign       104         0\n  malignant      0       120\n\npred_test  %&gt;% conf_mat(truth=status, \n                        estimate = .pred_class, \n                        dnn = c('Predicted','Truth (TEST Data)'))\n\n           Truth (TEST Data)\nPredicted   benign malignant\n  benign        21         6\n  malignant     14        35\n\n\nWhat do you notice about the performance of the model on the training, vs the test data?\n\n\nAccuracy\nThe accuracy is the sum of the correct predictions divided by the total number of samples, where 1 = perfect accuracy.\n\npred_train %&gt;% metrics(truth = status, estimate = .pred_class)\n\n# A tibble: 2 × 3\n  .metric  .estimator .estimate\n  &lt;chr&gt;    &lt;chr&gt;          &lt;dbl&gt;\n1 accuracy binary             1\n2 kap      binary             1\n\npred_test  %&gt;% metrics(truth = status, estimate = .pred_class)\n\n# A tibble: 2 × 3\n  .metric  .estimator .estimate\n  &lt;chr&gt;    &lt;chr&gt;          &lt;dbl&gt;\n1 accuracy binary         0.737\n2 kap      binary         0.461\n\n\n\n\nCurves\nCreating ROC and PR curves require the predicted class probabilities rather than discrete labels.\nThe roc_curve() and pr_curve() functions from the yardstick package (part of the tidymodels stable) are very handy for calculating the true-positive and false-positive rates as the decision threshold decreases.\n\nroc_tbl &lt;- roc_curve(pred_test, truth = status, .pred_malignant, \n                     event_level = 'second')\n\npr_tbl &lt;- pr_curve(pred_test, truth = status, .pred_malignant, \n                     event_level = 'second')\n\nFor a quick look at performance, ROC and PR curves can be plotted using the autoplot() function (ggplot2 geoms can be added on for customization):\n\nroc_tbl %&gt;% autoplot() \n\n\n\n\n\n\n\npr_tbl %&gt;% autoplot() + geom_hline(yintercept = 0.5,lty=2)\n\n\n\n\n\n\n\n\n\n\nArea under the curve\nyardstick also contains roc_auc() and pr_auc to calculate the area under each curve type. Note that the ‘event_level’ argument is the category that we consider ‘TRUE’ (in this case ‘malignant’, which is the second level in the status factor).\n\n# AUROCC\nroc_auc(data = pred_test, truth = status,  .pred_malignant, event_level = 'second') \n\n# A tibble: 1 × 3\n  .metric .estimator .estimate\n  &lt;chr&gt;   &lt;chr&gt;          &lt;dbl&gt;\n1 roc_auc binary         0.804\n\n# AUPRC\npr_auc( data = pred_test, truth = status, .pred_malignant, event_level = 'second') \n\n# A tibble: 1 × 3\n  .metric .estimator .estimate\n  &lt;chr&gt;   &lt;chr&gt;          &lt;dbl&gt;\n1 pr_auc  binary         0.827\n\n\n\n\nFeature Gain\n‘Gain’ is a measure of the contribution of each feature to the accuracy of an xgboost model. Understanding the relative contribution of each feature is helpful if we want to create a smaller / lighter model using only the most important predictors, for example. This is also an important aspect of ‘explainable AI’ (xAI) /‘interpretable machine learning’. The vip package (‘variable importance plot’) has a vip() function for creating the characteristic horizontal bar charts:\n\n#Extract fitted xgboost model\nxgb_fit &lt;- extract_fit_parsnip(fit_cl)$fit\n\n# Plot Gain  ('variable importance plot' - vip)\nvip::vip(xgb_fit, num_features = 20)\n\n\n\n\n\n\n\n\nWhat do you notice about the most important features in this model, when compared to our original data exploration work in ML Part 1 using lm_test()?",
    "crumbs": [
      "8 Machine learning",
      "Part 2"
    ]
  },
  {
    "objectID": "ch8_section_2.html#save-output",
    "href": "ch8_section_2.html#save-output",
    "title": "Part 2",
    "section": "Save output",
    "text": "Save output\nLet’s save the recipe rec_cl, and pred_test output from the model, to compare with a ‘tuned’ model in the next step.\n\nsave(\n  #training & testing data:\n  train_cl, test_cl, \n     #recipe object:\n     rec_cl, \n     #predictions on test data:\n     pred_test, file='data_processed/ml_pt2_objects.Rda')",
    "crumbs": [
      "8 Machine learning",
      "Part 2"
    ]
  },
  {
    "objectID": "ch8_section_3.html",
    "href": "ch8_section_3.html",
    "title": "Part 3",
    "section": "",
    "text": "Background\nUsing a dataset containing imaging-derived histology features, and tumor status (benign vs malignant), so far we have run ML Part 1 to explore and transform the data, and ML Part 2 to build an XGBoost model with pre-defined hyper-parameters.",
    "crumbs": [
      "8 Machine learning",
      "Part 3"
    ]
  },
  {
    "objectID": "ch8_section_3.html#aim",
    "href": "ch8_section_3.html#aim",
    "title": "Part 3",
    "section": "Aim",
    "text": "Aim\nIn this final section, we will use the same input data to create an XGBoost classifier, but instead of pre-defining the model hyper-parameters, we will perform a ‘grid search’ to identify the combination of hyper-parameter values that produce the most accurate classifier.\nWe will then compare the tuned model to that created using pre-defined hyper-parameters in ML Part 2.",
    "crumbs": [
      "8 Machine learning",
      "Part 3"
    ]
  },
  {
    "objectID": "ch8_section_3.html#load-libraries",
    "href": "ch8_section_3.html#load-libraries",
    "title": "Part 3",
    "section": "Load libraries",
    "text": "Load libraries\n\nlibrary(tidyverse)\nlibrary(readxl)\nlibrary(tidymodels)\nlibrary(xgboost)\n\ntheme_set(theme_minimal())",
    "crumbs": [
      "8 Machine learning",
      "Part 3"
    ]
  },
  {
    "objectID": "ch8_section_3.html#load-data",
    "href": "ch8_section_3.html#load-data",
    "title": "Part 3",
    "section": "Load data",
    "text": "Load data\nFirst, we load the data created in ML Part 2\n\nload('data_processed/ml_pt2_objects.Rda')",
    "crumbs": [
      "8 Machine learning",
      "Part 3"
    ]
  },
  {
    "objectID": "ch8_section_3.html#set-seed",
    "href": "ch8_section_3.html#set-seed",
    "title": "Part 3",
    "section": "Set seed",
    "text": "Set seed\nReproducible ‘randomness’. This ensures everyone using this tutorial gets the same results.\n\n set.seed(42)",
    "crumbs": [
      "8 Machine learning",
      "Part 3"
    ]
  },
  {
    "objectID": "ch8_section_3.html#cross-training",
    "href": "ch8_section_3.html#cross-training",
    "title": "Part 3",
    "section": "Cross training",
    "text": "Cross training\nCross-fold validation requires the training data to be split into sub-sets of roughly equal size. The model is trained on N-1 sets and tested on the remaining ‘unseen’ data subset. Here we determine the folds for cross-validation during tuning, using vfold_cv().\n\nfolds &lt;- vfold_cv(train_cl, v = 5, strata = status)\nfolds\n\n#  5-fold cross-validation using stratification \n# A tibble: 5 × 2\n  splits           id   \n  &lt;list&gt;           &lt;chr&gt;\n1 &lt;split [179/45]&gt; Fold1\n2 &lt;split [179/45]&gt; Fold2\n3 &lt;split [179/45]&gt; Fold3\n4 &lt;split [179/45]&gt; Fold4\n5 &lt;split [180/44]&gt; Fold5",
    "crumbs": [
      "8 Machine learning",
      "Part 3"
    ]
  },
  {
    "objectID": "ch8_section_3.html#hyper-parameter-tuning",
    "href": "ch8_section_3.html#hyper-parameter-tuning",
    "title": "Part 3",
    "section": "Hyper-parameter tuning",
    "text": "Hyper-parameter tuning\nCompared with the single model with defined hyper-parameters in ML Part 2, here we allow the tree_depth and learn_rate to be tuned, using a range of values across a ‘grid’.\nIn the previous section we set the exact parameters for the boost_tree() function. Here we allow the tree depth and the learning rate to be tuned for optimal performance, by running multiple models across a range of tree depth and learning rate parameters. Note that these arguments are now set to tune().\n\nxgb_spec_tune_cl &lt;- boost_tree(trees = 500, \n                               tree_depth = tune(), \n                               learn_rate = tune()) %&gt;%\n  set_engine(\"xgboost\") %&gt;%\n  set_mode(\"classification\")",
    "crumbs": [
      "8 Machine learning",
      "Part 3"
    ]
  },
  {
    "objectID": "ch8_section_3.html#tuning-workflow",
    "href": "ch8_section_3.html#tuning-workflow",
    "title": "Part 3",
    "section": "Tuning workflow",
    "text": "Tuning workflow\nWe construct a workflow where the xgboost model now includes the original recipe from ML Part 2, and the tuning steps defined above.\n\nwf_xgb_tune  &lt;- workflow() |&gt; \n  # model outcome and features & pre-processing steps:\n  add_recipe(rec_cl) |&gt; \n  #hyper-parameters, machine learning model type, and mode:\n  add_model(xgb_spec_tune_cl)\n\nRunning the tune_grid() command iterates through the hyper-parameter values in grid, and determines the optimal combinations via cross-fold validation (using the folds object). We also set the evaluation metrics as area under the ROC curve, and mean log loss. Note that log-loss for classification tasks, is similar to RMSE for regression. It measures the accuracy by penalizing false predictions. The lower the log-loss the better.\n\ngrid &lt;- grid_regular(tree_depth(), learn_rate(), levels = 5)\n\n\nxgb_tune_res &lt;- tune_grid(\n  wf_xgb_tune,\n  resamples = folds,\n  grid = grid,\n  metrics = metric_set(roc_auc, mn_log_loss),\n  control = control_grid(save_pred = TRUE)\n)\n\nNB this step can take 30-60 seconds on a standard laptop with the current data.",
    "crumbs": [
      "8 Machine learning",
      "Part 3"
    ]
  },
  {
    "objectID": "ch8_section_3.html#train-your-model",
    "href": "ch8_section_3.html#train-your-model",
    "title": "Part 3",
    "section": "Train your model!",
    "text": "Train your model!\n\nfinal_fit &lt;- fit(final_wf, data = train_cl)",
    "crumbs": [
      "8 Machine learning",
      "Part 3"
    ]
  },
  {
    "objectID": "ch8_section_3.html#predict-the-test-set",
    "href": "ch8_section_3.html#predict-the-test-set",
    "title": "Part 3",
    "section": "Predict the test set!",
    "text": "Predict the test set!\nApply the model trained using optimal hyper-parameters, to predict the malignant status in the hold-out test_cl dataset.\n\npred_tuned &lt;- predict(final_fit, test_cl, type = \"prob\") %&gt;%\n  bind_cols(test_cl)",
    "crumbs": [
      "8 Machine learning",
      "Part 3"
    ]
  },
  {
    "objectID": "ch8_section_3.html#evaluate",
    "href": "ch8_section_3.html#evaluate",
    "title": "Part 3",
    "section": "Evaluate",
    "text": "Evaluate\nHere we generate performance curves and metrics for ROC and PR, for both the original and the tuned models.\n\nOriginal hyper-parameters\nAssign the original model results to pred_orig, then extract the ROC and PR data for the original model:\n\npred_orig &lt;- pred_test\n\n\nroc_orig &lt;- roc_curve(pred_orig, truth = status, .pred_malignant, \n                      event_level = \"second\") %&gt;%\n  mutate(model = \"Original\") \n\n\npr_orig &lt;- pr_curve(pred_orig, truth = status, .pred_malignant, \n                    event_level = \"second\") %&gt;%\n  mutate(model = \"Original\") \n\n\n\nTuned hyper-parameters\nExtract the ROC and PR results for the tuned model\n\nroc_tuned &lt;- roc_curve(pred_tuned, truth = status, .pred_malignant, \n                       event_level = \"second\") %&gt;%\n  mutate(model = \"Tuned\") \n\n\npr_tuned &lt;- pr_curve(pred_tuned, truth = status, .pred_malignant, \n                     event_level = \"second\") %&gt;%\n  mutate(model = \"Tuned\")",
    "crumbs": [
      "8 Machine learning",
      "Part 3"
    ]
  },
  {
    "objectID": "ch8_section_3.html#statistics",
    "href": "ch8_section_3.html#statistics",
    "title": "Part 3",
    "section": "Statistics",
    "text": "Statistics\n\nOriginal hyper-parameters\nCalculate the AUC for the original model:\n\naurocc_orig &lt;- roc_auc(pred_orig,  truth = status, .pred_malignant, \n                       event_level = \"second\") |&gt; \n  pull(.estimate) |&gt; round(3)\n\nauprc_orig &lt;- pr_auc(pred_orig,  truth = status, .pred_malignant, \n                     event_level = \"second\") |&gt; \n  pull(.estimate) |&gt; round(3)\n\n\n\nTuned parameters\n\naurocc_tuned &lt;- roc_auc(pred_tuned, truth = status, .pred_malignant,\n                        event_level = \"second\") |&gt; \n  pull(.estimate) |&gt; round(3)\n\n\nauprc_tuned &lt;- pr_auc(pred_tuned, truth = status, .pred_malignant, \n                      event_level = \"second\") |&gt; \n  pull(.estimate) |&gt; round(3)",
    "crumbs": [
      "8 Machine learning",
      "Part 3"
    ]
  },
  {
    "objectID": "ch8_section_3.html#plots",
    "href": "ch8_section_3.html#plots",
    "title": "Part 3",
    "section": "Plots",
    "text": "Plots\nHere we create ROC and PR curves using ggplot, to directly compare the performance of the original vs the tuned classifiers. (We sort the data by sensitivity, and precision respectively, to avoid unwanted extra lines in the geom_step() geom)\n\nROC\n\nroc_origVtuned &lt;- bind_rows(\n  roc_orig  |&gt; arrange(sensitivity), \n  roc_tuned |&gt; arrange(sensitivity) ) \n  \nroc_origVtuned |&gt; ggplot(aes(x = 1-specificity, y = sensitivity)) +\n  geom_step(aes(color=model), lwd=1.5) +\n  geom_abline(linetype = \"dashed\", color = \"grey\") +\n  annotate(\"text\", x = 0.6, y = 0.2, \n           label = paste0(\"AUROC (orig): \",  aurocc_orig) ) +\n  annotate(\"text\", x = 0.6, y = 0.1, \n           label = paste0(\"AUROC (tuned): \", aurocc_tuned)) +\n  labs(title = \"ROC Curve Comparison\",\n       x = \"False Positive Rate\",\n       y = \"True Positive Rate\",\n       color = \"Model\") +\n  theme_minimal()\n\n\n\n\n\n\n\n\n\n\nPR\n\npr_origVtuned &lt;- bind_rows(\n  pr_orig  |&gt; arrange(desc(precision)),\n  pr_tuned |&gt; arrange(desc(precision)))\n  \npr_origVtuned |&gt; \n  ggplot(aes(x = recall, y = precision)) +\n  geom_step(aes(color=model), lwd=1.5) +\n  geom_hline(linetype = \"dashed\", color = \"grey\",yintercept = 0.5) +\n  annotate(\"text\", x = 0.6, y = 0.2, \n           label = paste0(\"AUROC (orig): \",  auprc_orig) ) +\n  annotate(\"text\", x = 0.6, y = 0.1, \n           label = paste0(\"AUROC (tuned): \", auprc_tuned)) +\n  labs(title = \"PR Curve Comparison\",\n       x = \"Recall\",\n       y = \"Precision\",\n       color = \"Model\") +\n  theme_minimal()",
    "crumbs": [
      "8 Machine learning",
      "Part 3"
    ]
  },
  {
    "objectID": "further_reading.html",
    "href": "further_reading.html",
    "title": "Further reading",
    "section": "",
    "text": "Useful references",
    "crumbs": [
      "Further reading"
    ]
  },
  {
    "objectID": "further_reading.html#sec-useful-references",
    "href": "further_reading.html#sec-useful-references",
    "title": "Further reading",
    "section": "",
    "text": "R for Data Science: this is a great online book that teaches you to do data science with R. Covering a wide range of topics using the tidyverse packages.\nModernDive into R: this is an excellent book covering linear modelling and inferential statistics using tidyverse style code.\nThe R Gallery: this shows a range of plots that can be created in R using ggplot2 with associated code for each plot.\nR-bloggers: this is a blog that aggregates posts from a wide range of R bloggers. It is a great resource for finding out about new packages and techniques in R.\nDatacamp R documentation: this provides a reference to a lot of programming and data analysis in R using base R functionality.\nRNA-seq analysis is easy as 1-2-3: the original workflow from which chapter 6 and 7 was adapted.\nLimma user’s guide: this is a comprehensive guide to using the limma package for differential expression analysis.\nA guide to creating design matrices for gene expression experiments: this article explains design matrices for gene expression experiments in great detail and is written to be highly accessible to readers without a mathematical background.",
    "crumbs": [
      "Further reading"
    ]
  },
  {
    "objectID": "further_reading.html#paths",
    "href": "further_reading.html#paths",
    "title": "Further reading",
    "section": "Paths",
    "text": "Paths\nWe briefly touched on paths in the first chapter, but it is an important and complex topic that with worth digging into further. Paths are a way to specify the location of a file or directory on your computer, they are important whenever data needs to be read from or written to a file. This makes it a crucial concept for data analysis in R.\n\nAbsolute paths\nAn absolute path is defined as the full path from the root directory of the computer. These paths start with the root directory, which is / on Unix-based systems (like Linux and MacOS) and C:\\ on Windows systems. For example, the absolute path to the home directory on a Unix-based system would be /home/my_username/analysis/data/file.txt. These paths should be used when the location of the file is not going to change and is in some shared location external to the project.\n\n\nRelative paths\nRelative paths are defined as a path relative to the current working directory. If you are already in the directory /home/users/my_username/analysis/, the relative path to the file data/file.txt would be have the same meaning as the absolute path /home/users/my_username/analysis/data/file.txt. Relative paths are useful when the location of the file is likely to change, for example if the whole analysis folder might be moved around with its included data.\nUsers tend to have a home directory, which is the private directory each user is assigned. This directory is often located at /home/my_username/ on Unix-based systems and C:\\Users\\my_username\\ on Windows systems. This directory commonly acts as the starting point for many paths local to the user, and can be referred to using the shortcut ~ (tilde). For example, the path ~/analysis/data/file.txt would be equivalent to /home/my_username/analysis/data/file.txt on a Unix-based system. The exact path that is referred to by ~ can be found by running the command Sys.getenv(\"HOME\") in R, and is relative to the user running the R session.\n\n\nThe here package\nThere are situations where you want to organise your scripts into folders, if you navigate to these folders and run the scripts, they will run within the folder they are in. But often you will want to run the script from the root folder of the project. For example if you have a script in ~/analysis/scripts/plot.R and inside you use data/file.txt to reference ~/analysis/data/file.txt, if you run the script from ~/analysis/scripts/ it will not find the file. The here package solved this problem by anchoring your paths relative to the root folder of the project. Details about the package can be found here.",
    "crumbs": [
      "Further reading"
    ]
  },
  {
    "objectID": "further_reading.html#using-ai-helpers",
    "href": "further_reading.html#using-ai-helpers",
    "title": "Further reading",
    "section": "Using AI helpers",
    "text": "Using AI helpers\nThere are a range of useful AI helpers available that can help solve problems with R. These include ChatGPT, Claude and more. These can be useful for debugging, finding solutions to problems, and more. However, they it is important to remember that they are not perfect and do not always provide the correct answer. This can have serious consequences if code provided by an AI helper contains a mistake that ends up affecting the analysis. It is therefore very important to both check the code provided by an AI as before you run it and inspect the result it produces to ensure it is reliable.\nYou should avoid:\n\nRunning code from an AI helper without checking it first\nRunning code from an AI helper without understanding the result it produces\nCopy and pasting large amounts of code from an AI helper without understanding it\nUsing an AI helper as a substitute for learning how to code\nUsing an AI helper as a substitute for understanding the problem you are trying to solve\n\nBecause of the way AI helpers work, if you don’t understand a particular bit of code it produces, you can simply ask it to explain what it’s doing. If you don’t understand the explanation, or disagree with it, you should confront the AI helper with your concerns. Only run the code once you are sufficiently convinced that it’s doing what you want.\nTo use AI effectively, it helps to provide as much context as possible. This includes but is not limited to:\n\nThe problem you are trying to solve\nThe data you are working with\nThe output you are expecting\nThe code you have already tried\nThe error messages you are getting\n\nWhen asking questions of the AI, you should be as specific as possible while providing room for flexibility in the answer. It often helps to start with a broader question before narrowing in on the specific problem you are facing. For example a poor question would be too vague without enough context, such as “How do I plot differential expression data?” A better question could be “What plots are commonly used to visualise differential expression data in RNA-seq analysis?”. Followed by “How do I create a volcano plot in R using ggplot2?”. If you have differential expression data ready, you can also describe it to the AI helper to get more specific advice. For example “I have a a data frame with the columns gene, log2FoldChange and pvalue, how can I create a volcano plot from this data?”.\nThe more information you provide the AI, the more likely it is to provide a useful answer. If you are confused about how to use a specific function, instead of asking the AI “How do I use the … function from the … package?”, you can copy and paste the entire help page for the function into the AI chat along with a description of what you’re trying to do.",
    "crumbs": [
      "Further reading"
    ]
  }
]